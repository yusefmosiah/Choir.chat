# Level 0 Documentation



=== File: docs/tree.md ===



==
tree.md
==


# Choir Directory Structure
## Output of $ tree -I 'venv|archive|__pycache__|iOS_Example|dependencies' | pbcopy

.
├── Choir
│   ├── App
│   │   └── ChoirApp.swift
│   ├── Assets.xcassets
│   │   ├── AccentColor.colorset
│   │   │   └── Contents.json
│   │   ├── AppIcon.appiconset
│   │   │   ├── Contents.json
│   │   │   └── Icon-App-1024x1024@2x.png
│   │   ├── Contents.json
│   │   └── Icon-App-1024x1024.imageset
│   │       ├── Contents.json
│   │       └── Icon-App-1024x1024@2x.png
│   ├── Choir.entitlements
│   ├── ContentView.swift
│   ├── Coordinators
│   │   └── RESTPostchainCoordinator.swift
│   ├── Info.plist
│   ├── Models
│   │   └── ChoirModels.swift
│   ├── Networking
│   │   └── PostchainAPIClient.swift
│   ├── Preview Content
│   │   └── Preview Assets.xcassets
│   │       └── Contents.json
│   ├── Protocols
│   │   └── PostchainCoordinator.swift
│   ├── Services
│   │   ├── KeychainService.swift
│   │   └── WalletManager.swift
│   ├── ViewModels
│   │   └── PostchainViewModel.swift
│   ├── Views
│   │   ├── ChoirThreadDetailView.swift
│   │   ├── MessageRow.swift
│   │   ├── PostchainView.swift
│   │   ├── Thread
│   │   │   └── Components
│   │   │       ├── ThreadInputBar.swift
│   │   │       └── ThreadMessageList.swift
│   │   └── WalletView.swift
│   └── actor_model
│       └── phase_worker_pool.py
├── Choir.xcodeproj
│   ├── project.pbxproj
│   ├── project.xcworkspace
│   │   ├── contents.xcworkspacedata
│   │   ├── xcshareddata
│   │   │   └── swiftpm
│   │   │       ├── Package.resolved
│   │   │       └── configuration
│   │   └── xcuserdata
│   │       └── wiz.xcuserdatad
│   │           ├── IDEFindNavigatorScopes.plist
│   │           └── UserInterfaceState.xcuserstate
│   └── xcuserdata
│       └── wiz.xcuserdatad
│           ├── xcdebugger
│           │   └── Breakpoints_v2.xcbkptlist
│           └── xcschemes
│               └── xcschememanagement.plist
├── ChoirTests
│   ├── APIResponseTests.swift
│   ├── ChoirTests.swift
│   ├── ChoirThreadTests.swift
│   └── PostchainAPIClientTests.swift
├── ChoirUITests
│   ├── ChoirUITests.swift
│   └── ChoirUITestsLaunchTests.swift
├── api
│   ├── Dockerfile
│   ├── __init__.py
│   ├── app
│   │   ├── __init__.py
│   │   ├── config.py
│   │   ├── database.py
│   │   ├── langchain_utils.py
│   │   ├── models
│   │   │   ├── __init__.py
│   │   │   └── api.py
│   │   ├── postchain
│   │   │   ├── __init__.py
│   │   │   ├── checkpointer.py
│   │   │   ├── nodes
│   │   │   ├── prompts
│   │   │   ├── schemas
│   │   │   │   ├── __init__.py
│   │   │   │   └── state.py
│   │   │   ├── simple_graph.py
│   │   │   ├── state
│   │   │   ├── state_manager.py
│   │   │   └── utils.py
│   │   ├── routers
│   │   │   ├── balance.py
│   │   │   ├── postchain.py
│   │   │   ├── threads.py
│   │   │   ├── users.py
│   │   │   └── vectors.py
│   │   ├── services
│   │   │   ├── __init__.py
│   │   │   ├── chorus.py
│   │   │   └── sui_service.py
│   │   ├── thespian
│   │   │   └── hello.py
│   │   ├── tools
│   │   │   ├── __init__.py
│   │   │   ├── base.py
│   │   │   ├── brave_search.py
│   │   │   ├── calculator.py
│   │   │   ├── conversation.py
│   │   │   ├── duckduckgo_search.py
│   │   │   ├── qdrant.py
│   │   │   ├── qdrant_workflow.py
│   │   │   ├── tavily_search.py
│   │   │   └── web_search.py
│   │   └── utils.py
│   ├── custom_state_manager_test.log
│   ├── debug_stream_content.log
│   ├── main.py
│   ├── postchain_memory_debug.log
│   ├── postchain_tests.log
│   ├── pyproject.toml
│   ├── pytest.ini
│   ├── requirements.txt
│   ├── run_tests.sh
│   └── tests
│       ├── __init__.py
│       ├── conftest.py
│       ├── postchain
│       │   ├── __init__.py
│       │   ├── analysis.py
│       │   ├── random_gen_prompts.md
│       │   ├── run_all_tests.py
│       │   ├── run_tests.py
│       │   ├── test_cases.json
│       │   ├── test_cases.py
│       │   ├── test_framework.py
│       │   ├── test_langgraph_multiturn.py
│       │   ├── test_langgraph_multiturn_abstracted.py
│       │   ├── test_multiturn.py
│       │   ├── test_providers.py
│       │   ├── test_providers_abstracted.py
│       │   ├── test_random_multimodel.py
│       │   ├── test_random_multimodel_stream.py
│       │   ├── test_simple_multimodel.py
│       │   ├── test_simple_multimodel_stream.py
│       │   ├── test_stream.py
│       │   ├── test_structured_output.py
│       │   ├── test_tool_multimodel.py
│       │   ├── test_tool_random_multimodel.py
│       │   └── test_utils.py
│       ├── test_main.py
│       ├── test_sui_service.py
│       ├── test_user_thread_endpoints.py
│       ├── thespian
│       │   └── test_hello.py
│       └── tools
│           ├── __init__.py
│           ├── direct_search_diagnostic.py
│           ├── direct_search_test.py
│           ├── haiku_search_test.py
│           ├── langgraph_test.py
│           ├── run_tool_tests.py
│           ├── test_anthropic_langgraph.py
│           ├── test_brave_search.py
│           ├── test_calculator.py
│           ├── test_duckduckgo_search.py
│           ├── test_langgraph_providers_tools.py
│           ├── test_multimodel_with_tools.py
│           ├── test_provider_langgraph.py
│           ├── test_qdrant.py
│           ├── test_qdrant_multimodel.py
│           ├── test_qdrant_workflow.py
│           ├── test_recent_events.py
│           ├── test_search_tools_report.py
│           ├── test_tavily_search.py
│           └── test_updated_search.py
├── choir_coin
│   └── choir_coin
│       ├── Move.lock
│       ├── Move.toml
│       ├── build
│       │   └── choir
│       │       ├── BuildInfo.yaml
│       │       ├── bytecode_modules
│       │       │   ├── choir.mv
│       │       │   └── choir_tests.mv
│       │       ├── source_maps
│       │       │   ├── choir.json
│       │       │   ├── choir.mvsm
│       │       │   ├── choir_tests.json
│       │       │   └── choir_tests.mvsm
│       │       └── sources
│       │           ├── choir.move
│       │           └── choir_tests.move
│       ├── sources
│       │   └── choir_coin.move
│       └── tests
│           └── choir_coin_tests.move
├── docker-compose.yml
├── docs
│   ├── 1-concepts
│   │   ├── actor_model_overview.md
│   │   ├── postchain_actor_model.md
│   │   ├── postchain_conceptual_model.md
│   │   ├── postchain_temporal_logic.md
│   │   └── scale_free_actor_architecture.md
│   ├── 2-architecture
│   │   ├── actor_hierarchy_diagram.md
│   │   ├── actor_system_diagram.md
│   │   ├── architecture_integration.md
│   │   ├── message_flow_diagrams.md
│   │   ├── phase_worker_pool.md
│   │   ├── state_management_overview.md
│   │   ├── thread_contract_model.md
│   │   └── token_economy_model.md
│   ├── 3-implementation
│   │   ├── actor_debugging_guide.md
│   │   ├── actor_implementation_guide.md
│   │   ├── actor_testing_guide.md
│   │   ├── developer_quickstart.md
│   │   ├── message_protocol_reference.md
│   │   ├── phase_requirements
│   │   │   ├── action_phase.md
│   │   │   ├── experience_phase.md
│   │   │   ├── intention_phase.md
│   │   │   ├── observation_phase.md
│   │   │   ├── phase_requirements_index.md
│   │   │   ├── understanding_phase.md
│   │   │   └── yield_phase.md
│   │   └── state_management_patterns.md
│   ├── 4-integration
│   │   ├── blockchain_integration.md
│   │   ├── identity_service.md
│   │   └── libsql_integration.md
│   ├── 5-operations
│   │   ├── deployment_guide.md
│   │   ├── monitoring_observability.md
│   │   └── testing_strategy.md
│   ├── 6-business
│   │   ├── anonymity_by_default.md
│   │   ├── business_model.md
│   │   └── evolution_token.md
│   ├── CHANGELOG.md
│   ├── README.md
│   ├── architecture_reorganization_plan_mcp.md
│   ├── comp_provider_info.md
│   ├── core_core.md
│   ├── core_economics.md
│   ├── core_state_transitions.md
│   ├── data_engine_model.md
│   ├── documentation_index.md
│   ├── e_business.md
│   ├── e_concept.md
│   ├── evolution_naming.md
│   ├── evolution_stack.md
│   ├── evolution_token.md
│   ├── fqaho_simulation.md
│   ├── fqaho_visualization.md
│   ├── index.md
│   ├── levels
│   │   ├── all.txt
│   │   ├── level0.md
│   │   ├── level1.md
│   │   ├── level2.md
│   │   ├── level3.md
│   │   ├── level4.md
│   │   └── level5.md
│   ├── phase_worker_pool_architecture.md
│   ├── plan_anonymity_by_default.md
│   ├── plan_identity_as_a_service.md
│   ├── plan_libsql.md
│   ├── postchain_actor_model.md
│   ├── scripts
│   │   ├── combiner.sh
│   │   ├── reorganization_script_design.md
│   │   └── update_tree.sh
│   ├── security_considerations.md
│   ├── stack_argument.md
│   ├── stack_pivot_summary.md
│   └── tree.md
├── examples
│   └── phase_worker_pool_demo.py
├── notebooks
│   ├── fqaho_simulation.ipynb
│   ├── post_chain0.ipynb
│   └── vowel_loop3.ipynb
├── render.yaml
└── scripts
    ├── generate_provider_reports.sh
    ├── generate_quick_search_report.sh
    ├── generate_search_report.sh
    └── generate_single_provider_report.sh

70 directories, 224 files

=== File: docs/CHANGELOG.md ===



==
CHANGELOG.md
==


# Changelog

## [Unreleased] - 2025-03-12

### Changed

- Major architectural pivot: Shifted from LangGraph to MCP Architecture
  - Transitioned to Model Context Protocol (MCP) architecture
  - Added libSQL/Turso for combined SQL+vector storage
  - Integrated PySUI for blockchain operations
  - Established Docker+Phala deployment pipeline
  - Preserved FQAHO economic model intact

### Added

- Defined new coherent technology stack:

  - Model Context Protocol (MCP) architecture: Service-oriented architecture for phases
  - libSQL/Turso: Combined SQL+vector database for state and RAG
  - PySUI: Blockchain integration for tokenomics and citations
  - Pydantic: Type safety for message passing between services
  - FastAPI/Uvicorn: High-performance async API layer
  - Docker: Containerization for deployment
  - Phala Network: Privacy-preserving computation platform for deployment

- Extended the Post Chain with Phase Worker Pool pattern:
  - Phases are now implemented as MCP servers (not just single instances)
  - Server implementations can be specialized by modality (text, audio, video, code)
  - Worker Pool pattern abstracts AI models from server implementations
  - Support for specialized domain servers (medical, legal, financial)

### Removed

- Deprecated LangGraph dependency due to persistent memory management issues
- Simplified architecture by eliminating graph-based state management complexities

## [2025-02-25] - 2025-02-25

### Added

- Implemented UI carousel to improve user experience
- Added display of priors in the Experience step
- Resumed active development after coding hiatus

### Planned

- API streaming implementation to enhance responsiveness
- Model reconfiguration for improved performance
- Go multimodel, then multimodal
- OpenRouter integration
- Conceptual evolution from "Chorus Cycle" to "Post Chain"
  - Representing shift from harmonic oscillator (cycle) to anharmonic oscillator (chain)
  - Aligning interface terminology with underlying FQAHO model
- Client-side editable system prompts for customization
- Additional phases in the Post Chain:
  - Web search phase for real-time information access
  - Sandboxed arbitrary tool use phase for enhanced capabilities

## [2025-02-24] - 2025-02-24

### Changed

- Implemented fractional quantum anharmonic oscillator model for dynamic stake pricing
- Added fractional parameter α to capture memory effects and non-local interactions
- Revised parameter modulation formulas for K₀, α, and m to reflect interdependencies
- Created simulation framework for parameter optimization

## [2025-02-23] - 2025-02-23

### Changed

- Documented quantum anharmonic oscillator model implementation and dynamic stake pricing mechanism via an effective anharmonic coefficient modulated by approval/refusal statistics.

## [Unreleased]

### Changed

- Updated all documentation to version 6.0
  - Transformed structured documentation into fluid prose
  - Relaxed event-driven architecture requirements for initial TestFlight
  - Clarified implementation priorities and post-funding features
  - Maintained theoretical frameworks while focusing on core functionality

### Added

- Initial Chorus cycle working in iOS simulator
  - Basic message flow through phases
  - Response handling
  - State management

### Documented

- Created 15 comprehensive issues covering:
  - Core message system implementation
  - Type reconciliation with Qdrant
  - API client updates
  - Coordinator message flow
  - User identity management
  - Thread state management
  - Integration testing
  - Error handling strategy
  - Performance monitoring
  - State recovery
  - Thread sheet implementation
  - Thread contract implementation
  - Message rewards system
  - LanceDB migration
  - Citation visualization

### Architecture

- Defined clear type system for messages
- Planned migration to LanceDB
- Structured multimodal support strategy

### Technical Debt

- Identified areas needing more specification:
  - Thread Sheet UI (marked as "AI SLOP")
  - Reward formulas need verification
  - Migration pipeline needs careful implementation

## [0.4.2] - 2024-11-09

### Added

- Development principles with focus on groundedness
- Basic chat interface implementation
- SwiftData message persistence
- Initial Action step foundation

### Changed

- Shifted to iterative, ground-up development approach
- Simplified initial implementation scope
- Focused on working software over theoretical architecture
- Adopted step-by-step Chorus Cycle implementation strategy

### Principles

- Established groundedness as core development principle
- Emphasized iterative growth and natural evolution
- Prioritized practical progress over theoretical completeness
- Introduced flexible, evidence-based development flow

## [0.4.1] - 2024-11-08

### Added

- Self-creation process
- Post-training concepts
- Concurrent processing ideas
- Democratic framing
- Thoughtspace visualization

### Changed

- Renamed Update to Understanding
- Enhanced step descriptions
- Refined documentation focus
- Improved pattern recognition

## [0.4.0] - 2024-10-30

### Added

- Swift architecture plans
- Frontend-driven design
- Service layer concepts
- Chorus cycle definition

### Changed

- Enhanced system architecture
- Refined core patterns

## [0.3.5] - 2024-09-01

- Choir.chat as a web3 dapp
- messed around with solana
- used a lot of time messing with next.js/react/typescript/javascript
- recognized that browser extension wallet is terrible ux

## [0.3.0] - 2024-03-01

### Added

- ChoirGPT development from winter 2023 to spring 2024

- First developed as a ChatGPT plugin, then a Custom GPT
- The first global RAG system / collective intelligence as a GPT

## [0.2.10] - 2023-04-01

### Added

- Ahpta development from winter 2022 to spring 2023

## [0.2.9] - 2022-04-01

### Added

- V10 development from fall 2021 to winter 2022

## [0.2.8] - 2021-04-01

### Added

- Elevisio development from spring 2020 to spring 2021

## [0.2.7] - 2020-04-01

### Added

- Bluem development from spring 2019 to spring 2020

## [0.2.6] - 2019-04-01

### Added

- Blocstar development from fall 2018 to spring 2019

## [0.2.5] - 2018-04-01

### Added

- Phase4word development from summer 2017 to spring 2018

### Changed

- Showed Phase4word to ~50 people in spring 2018, received critical feedback
- Codebase remains in 2018 vintage

## [0.2.0] - 2016-06-20

### Added

- Phase4 party concept
- Early democracy technology
- Initial value systems

### Changed

- Moved beyond truth measurement framing
- Refined core concepts

## [0.1.0] - 2015-07-15

### Added

- Initial simulation hypothesis insight
- "Kandor"
- Quantum information concepts
- Planetary coherence vision
- Core system ideas

=== File: docs/scripts/combiner.sh ===



==
combiner.sh
==


#!/bin/bash

# Revised prefix arrays
level0_prefixes=("")  # Basic technical integration
level1_prefixes=("core")  # Core system components
level2_prefixes=("e")           # Business/concept/implementation
level3_prefixes=("plan")               # State/economic models
level4_prefixes=("fqaho")     # Simulations
level5_prefixes=("evolution" "data")             # Foundational principles

# Function to add separator and header
add_separator() {
    echo -e "\n"
    echo "=="
    echo "$1"
    echo "=="
    echo -e "\n"
}

# Function to get level for a file
get_level_for_file() {
    filename=$(basename "$1")
    prefix=$(echo "$filename" | cut -d'_' -f1)

    for p in "${level0_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 0 && return; done
    for p in "${level1_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 1 && return; done
    for p in "${level2_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 2 && return; done
    for p in "${level3_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 3 && return; done
    for p in "${level4_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 4 && return; done
    for p in "${level5_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 5 && return; done

    echo -1
}

# Function to process files for a level
process_level() {
    level=$1
    output_file="docs/levels/level${level}.md"

    echo "# Level ${level} Documentation" > "$output_file"
    echo -e "\n" >> "$output_file"

    SPECIAL_FILES=("docs/prompt_wake_up.md" "docs/prompt_getting_started.md" "docs/prompt_reentry.md" "docs/prompt_organization.md" "docs/prompt_summary_prompt.md" "docs/prompt_chorus_cycle.md" "docs/tree.md" "docs/CHANGELOG.md" "docs/scripts/combiner.sh")

    # Level 0 now includes important system files (previously in level -1)
    if [ "$level" -eq 0 ]; then
        # Add system files (previously in level -1)
        for special_file in "${SPECIAL_FILES[@]}"; do
            if [ -f "$special_file" ]; then
                echo -e "\n=== File: $special_file ===\n" >> "$output_file"
                add_separator "$(basename "$special_file")" >> "$output_file"
                cat "$special_file" >> "$output_file"
                echo "$special_file" >> "/tmp/processed_files.txt"
            fi
        done

    fi

    # Process all docs to find ones for this level
    for file in docs/*.md; do
        if [ -f "$file" ] && [ "$(get_level_for_file "$file")" -eq "$level" ]; then
            echo -e "\n=== File: $file ===\n" >> "$output_file"
            add_separator "$(basename "$file" .md)" >> "$output_file"
            cat "$file" >> "$output_file"
            echo "$file" >> "/tmp/processed_files.txt"
        fi
    done
}

# Create temporary file for tracking
touch /tmp/processed_files.txt

# Process all levels (excluding level -1 as its content is now in level 0)
echo "Processing documentation..."
for level in {0..5}; do
    process_level $level
done

# Concatenate all levels into a single file
echo "Combining all levels into one file..."
mkdir -p docs/levels
cat docs/levels/level{0..5}.md > docs/levels/all.txt

# Check for uncategorized files
echo -e "\nUncategorized files:"
uncategorized=0
for doc in docs/*.md; do
    if ! grep -q "^$doc$" "/tmp/processed_files.txt"; then
        echo "$doc"
        uncategorized=$((uncategorized + 1))
        # Append uncategorized files to all.txt
        echo -e "\n=== File: $doc ===\n" >> docs/levels/all.txt
        add_separator "$(basename "$doc" .md)" >> docs/levels/all.txt
        cat "$doc" >> docs/levels/all.txt
    fi
done

if [ "$uncategorized" -gt 0 ]; then
    echo -e "\nTotal uncategorized: $uncategorized files"
fi

# Cleanup
rm -f "/tmp/processed_files.txt"

echo "Documentation combination complete"
# Level 1 Documentation



=== File: docs/core_core.md ===



==
core_core
==


# Core System Overview

VERSION core_system: 7.0

Note: This document describes the core system architecture, with initial focus on TestFlight functionality. More sophisticated event-driven mechanisms described here will be implemented post-funding.

The Choir system is built around a clear hierarchy of truth and state management. At its foundation, the blockchain serves as the authoritative source for all ownership and economic state – thread ownership, token balances, message hashes, and co-author lists. This ensures that the economic model, with its fractional equity distribution and fractional quantum anharmonic thread evolution (where dynamic parameter modulation is driven by approval/refusal feedback and memory effects), has an immutable and verifiable foundation.

Alongside the blockchain, Qdrant acts as the authoritative source for all content and semantic relationships. It stores the actual message content, embeddings, and the growing network of citations and semantic links. This separation of concerns allows the system to maintain both economic integrity through the blockchain and rich semantic relationships through the vector database.

The AEIOU-Y chorus cycle sits at the heart of the interaction model, processing user input through a series of well-defined steps. The cycle begins with pure response in the Action step, enriches it with prior knowledge in the Experience step, aligns with user intent in the Intention step, records semantic connections in the Observation step, decides on continuation in the Update step, and produces the final response in the Yield step.

State updates flow naturally between these components. When a user submits input, the system coordinates necessary updates across the UI, blockchain, and vector store. The chorus cycle processes the input while maintaining system state consistency. These state changes are carefully managed to maintain data integrity and system coherence.

The economic model employs FQAHO-based dynamics: the system parameters (α, K₀, m) evolve based on thread history and network position. The fractional parameter α captures memory effects and non-local interactions, decreasing from 2 toward 1 as threads mature. The anharmonic coefficient K₀ increases when a thread receives many refusals and decreases with strong approval. The potential order m reflects thread complexity and network depth. This parameter evolution naturally filters quality while accounting for memory effects and non-local interactions.

Equity is distributed according to fractional formulas, ensuring fair value attribution while maintaining mathematical elegance and accounting for memory effects. The distribution follows E(s) = (1/N) \* (s/P₀)^(α/2), balancing co-author count with stake amount and the thread's fractional parameter.

The knowledge system builds a growing semantic network through citations and prior references, with non-local interactions captured by the fractional approach. Each message can reference previous messages as priors, creating a web of semantic relationships with long-range correlations. These relationships are stored in Qdrant and help inform future responses through the Experience step of the chorus cycle.

State management follows the natural hierarchy of truth. The chain state is authoritative for ownership and economics. The vector state is authoritative for content and semantics. Local state serves only to coordinate UI updates and handle temporary synchronization needs. This clear hierarchy ensures system consistency while enabling responsive user interaction.

All of this is implemented using Swift's modern concurrency system. Async/await enables clean asynchronous code. Structured concurrency through task groups ensures proper resource management. The architecture maintains loose coupling between components while ensuring system coherence.

The result is a system that combines economic incentives, semantic knowledge, and natural interaction patterns into a coherent whole. The blockchain provides economic integrity. The vector database enables semantic richness. The chorus cycle creates natural interaction. The fractional quantum approach captures memory effects and non-local interactions. And Swift's concurrency model keeps it all running smoothly and safely.

This architecture enables the system to evolve naturally. The semantic network grows organically through usage with long-range correlations. The economic model creates emergent quality barriers through coupled parameter evolution. And the whole system maintains consistency through its clear hierarchy of truth and well-defined state management patterns.

=== File: docs/core_economics.md ===



==
core_economics
==


# Core Economic Model

VERSION core_economics: 7.0

The economic model operates as a fractional quantum anharmonic system, anchored by the Move Virtual Machine as its source of truth. The model orchestrates value flows through stake dynamics modulated by collective feedback signals and non-local memory effects.

At its foundation, the system tracks economic events through the blockchain. These events capture stake movements, parameter adjustments, equity distributions, and reward issuance. Each event carries a unique identifier, precise timestamp, and rich metadata that ensures perfect traceability.

The chain state manager serves as the authoritative bridge between the economic model and the blockchain. It retrieves thread economics directly from smart contracts, maintaining an accurate view of stake prices, model parameters, token balances, and equity distributions. All economic transactions flow through this manager, ensuring that on-chain state changes trigger appropriate event cascades throughout the system.

The model's core strength lies in its fractional quantum anharmonic calculations. The base price follows a modified FQAHO model:

P₀ = S₀[(2n+1)^(α/2) + (K₀λ)^{α/(m+1)}]

Where:

- α = Fractional parameter (1<α≤2) capturing memory effects and non-local interactions
- K₀ = Anharmonic coefficient dynamically modulated by recent approval/refusal statistics
- m = Potential order reflecting thread complexity and network depth
- n = Excitation level (capturing thread activity)

The fractional parameter α evolves according to:

α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

Where t represents normalized thread age, q measures quality through approval ratios, τ sets the time constant, and δ₁, δ₂ determine sensitivity.

Equity distribution follows a fractional square root law reflecting quantum amplitude principles:

E(s) = (1/N) \* (s/P₀)^(α/2)

This formula elegantly balances the number of co-authors N with the stake amount s, normalized by the base price P₀, ensuring fair value distribution across participants while accounting for memory effects.

The economic handler processes these events through a carefully orchestrated flow. When stake is deposited, it calculates new equity shares based on the current parameter values and organizational frequency. Collective feedback triggers parameter recalculations that maintain system equilibrium. Each event flows through the handler, ensuring proper economic state transitions.

Analytics and monitoring provide real-time insight into the economic system's health. The system tracks stake movements, parameter adjustments, equity distributions, and reward issuance. This data feeds back into the system, enabling natural price discovery and value distribution.

The economic model's strength emerges from several key principles. The blockchain serves as the immutable source of truth, while value flows follow fractional conservation laws. Price discovery emerges naturally through eigenvalue patterns of the fractional system, and state changes propagate through Lévy flight-like transitions. Most importantly, complex economic behaviors arise organically from these simple underlying rules.

Through this careful balance of blockchain authority, fractional mathematical precision, and natural value flows, the economic model creates a self-sustaining ecosystem for knowledge work. The system's elegance lies in how these principles work together, creating a robust economic framework that adapts and evolves while maintaining fundamental stability.

# Dynamic Parameter Evolution

## Fractional Parameter (α)

α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

## Anharmonic Coefficient (K₀)

K₀(r,α) = K₀*base * (1 + γ₁r) \_ (2/α)^γ₂

## Potential Order (m)

m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)

## Implementation in Actor Model

```python
class EconomicActor(Actor[EconomicState]):
    async def adjust_parameters(self, thread_state: ThreadState):
        """Update FQAHO parameters based on thread activity"""
        # Calculate new α using memory decay formula
        new_alpha = 2 - self.delta1*(1 - math.exp(-thread_state.age/self.tau))
                      - self.delta2*thread_state.quality_score

        # Update thread parameters
        await self.blockchain_actor.send(
            ParameterUpdate(
                thread_id=thread_state.id,
                alpha=new_alpha,
                k0=calculate_new_k0(thread_state.refusal_rate),
                m=calculate_new_m(thread_state.citation_count)
            )
        )
```

=== File: docs/core_state_transitions.md ===



==
core_state_transitions
==


# Core State Transitions

VERSION core_state_transitions: 7.0

The state transition system orchestrates the evolution of thread states through carefully defined transformations. These transitions follow precise fractional mathematical principles that ensure non-local energy conservation, dynamic parameter recalibration, and frequency coherence across the network.

Thread Creation establishes the initial quantum state. Each new thread begins with α = 2 (standard quantum mechanics), baseline anharmonic coefficient (K₀_base), and potential order m = 2. The creator's address becomes the first co-author, and the thread maintains an empty set of message hashes. This initial state provides a foundation for future non-local evolution.

Message Submission follows fractional quantum anharmonic energy principles. The required stake follows E(n) = (2n+1)^(α/2) + (K₀λ)^(α/(m+1)), where α, K₀, and m reflect the thread's history and network position. Each message generates a unique hash and carries its quantized energy contribution to the thread.

Approval Processing drives state evolution through three possible outcomes. In the case of rejection, both the anharmonic coefficient K₀ and the fractional parameter α are adjusted—with K₀ increasing to reflect recent refusals, and α decreasing slightly to capture the memory of this rejection. The system recalculates P₀ using our FQAHO-based formula. For split decisions, energy divides between treasury and thread based on voter distribution while parameters adjust proportionally. When approved, energy distributes to approvers while the fractional parameter α decreases slightly, enhancing non-local effects. The author joins as a co-author, and all parameters recalibrate according to the updated thread characteristics.

Dynamic Parameter Evolution follows principles of fractional quantum mechanics. The fractional parameter α evolves to reflect thread maturity and quality, decreasing from 2 toward 1 as threads develop memory and non-local interactions. The anharmonic coefficient K₀ responds primarily to recent approval/refusal patterns, while maintaining sensitivity to the fractional parameter. The potential order m increases with citation count and co-author network complexity, reflecting deepening interactions.

Frequency Management reflects collective organization through coupled oscillators with fractional damping. The thread frequency evolves through three interacting modes: the message mode normalizes activity rate by the fractional power of co-author count, the value mode applies logarithmic scaling to energy per co-author, and the coupling strength maintains an inverse relationship with co-author count raised to the fractional power. These modes work together to create natural organizational rhythms with long-range correlations.

The reward system operates through precisely defined state transitions with memory effects. New message rewards follow a fractional time-based decay described by R(t) = R_total × k/(1 + k·t_period)^(α/2), where k represents the decay constant (2.04), t_period spans the total time period of four years, and α is the thread's fractional parameter. Prior citation rewards strengthen thread coupling by drawing from treasury balance based on quality score ratios, expressed as V(p) = B_t × Q(p)^(α/2)/∑Q(i)^(α/2). Citations create frequency coupling between threads, with each thread's frequency increasing by 5% of the other's frequency, modulated by the fractional parameter. Treasury management maintains system solvency through careful balance tracking, where split decisions increase the balance, prior rewards decrease it, and system rewards add to it, all while maintaining a minimum balance for stability.

The system's core properties maintain stability through:

1. Fractional energy conservation in all transitions
2. Parameter coherence via coupled feedback loops
3. Frequency alignment through fractional organizational coupling
4. Lévy flight-like value propagation through the network

Error handling ensures transition validity through multiple safeguards. Fractional energy conservation violations trigger immediate rejection. Parameter instability blocks updates until recalibration completes. Frequency decoherence blocks transitions that would disrupt organizational patterns. Phase transition failures maintain the previous state to ensure system stability.

Through these precisely defined transitions, the system maintains fractional quantum anharmonic stability while enabling organic evolution of thread states. The careful balance of non-local energy conservation, dynamic parameter modulation, and frequency alignment creates a robust framework for organic growth and adaptation with memory effects.

#### Fractional Parameter Evolution

The evolution of thread parameters follows fractional quantum principles:

• The fractional parameter α evolves via:
α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

• The anharmonic coefficient adjusts through:
K₀(r,α) = K₀_base _ (1 + γ₁r) _ (2/α)^γ₂

• The potential order develops according to:
m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)

These modifications ensure that memory effects, non-local interactions, and network complexity are properly accounted for in the economic model.
# Level 2 Documentation



=== File: docs/e_business.md ===



==
e_business
==


# Choir Business Model

Choir's business model aligns with its natural principles - value flows efficiently, quality emerges organically, and growth happens sustainably. Rather than extracting value through advertising or data mining, we enable and strengthen natural value creation.

Our core revenue model operates on a thoughtfully designed freemium approach that grows naturally with teams. The free tier establishes a strong foundation, enabling thread participation, co-authorship, basic message submission and approval, thread visibility to co-authors, standard resource allocation, and natural team formation. Building on this foundation, our premium tier ($30/month or $200/year) enhances the natural flow of work through bonus rewards, increased resource allocation, priority message processing, advanced team analytics, and enhanced privacy controls. Premium benefits grow yearly, amplifying natural value creation rather than restricting basic functionality.

Value creation flows through multiple interconnected layers in the platform. At the individual level, participants receive immediate recognition for quality contributions, earn direct rewards for good judgment, build natural reputation through participation, and gain growing resource allocations. Teams benefit from collective value accumulation in threads, shared success through citations, natural team formation processes, and enhanced capabilities through premium features. At the network layer, knowledge networks form organically, value flows across threads, ecosystems develop naturally, and collective intelligence emerges from these interactions.

Resource allocation follows natural principles across three key dimensions. Processing resources scale AI model access with usage, prioritize premium members, enable teams to share growing allocations, and maintain natural load balancing. Storage resources preserve thread history, grow team allocations over time, offer premium backup options, and follow natural archival patterns. Network resources provide real-time updates, priority synchronization, enhanced team features, and optimize natural flows.

The platform grows through natural amplification mechanisms. Quality emerges as better contributions attract attention, teams form around excellence, value accumulates naturally, and growth follows genuine patterns. Network effects strengthen the ecosystem as teams enhance threads, threads strengthen networks, networks attract participation, and value flows efficiently. Resource evolution supports this growth as individual allocations expand yearly, team capabilities grow, network capacity increases, and scaling follows natural patterns.

Business sustainability flows from revenue streams aligned with value creation. Direct revenue comes from premium subscriptions, team features, enhanced capabilities, and growing allocations. Indirect value emerges through quality content datasets, knowledge network formation, team collaboration patterns, and collective intelligence emergence. System health maintains through sustainable resource usage, natural load distribution, efficient value flow, and organic growth patterns.

The future evolution of our model will unfold naturally. Team features will expand to include enhanced collaboration tools, advanced analytics, custom workflows, and natural team support. Knowledge tools will develop to enable network visualization, pattern recognition, insight emergence, and collective intelligence. Resource growth will continue through expanding allocations, new capabilities, team-specific features, and natural evolution.

Our implementation strategy follows natural patterns through three phases. The foundation phase establishes core functionality, basic premium features, natural team support, and essential analytics. The enhancement phase introduces advanced team features, network tools, enhanced analytics, and growing capabilities. The evolution phase enables custom team solutions, network intelligence, emergent features, and natural expansion.

Success metrics reflect our natural approach. Quality metrics track team formation rates, citation patterns, value accumulation, and natural growth. Health metrics monitor resource efficiency, value flow patterns, system coherence, and sustainable growth. Evolution metrics measure feature emergence, capability growth, network effects, and natural scaling.

Through this model, Choir maintains sustainable business operations while enabling natural value creation at all scales. We grow by strengthening the natural flows of quality, collaboration, and collective intelligence. Join us in building a platform where business success aligns perfectly with user value creation - where growth comes from enabling natural patterns of collaboration and knowledge sharing rather than artificial engagement metrics or data extraction.

Thread stake prices are determined through our Fractional Quantum Anharmonic Oscillator (FQAHO) model, which captures both immediate feedback and long-term memory effects. The model parameters evolve in response to community decisions - the anharmonic coefficient K₀ increases when a thread receives many refusals, the fractional parameter α decreases to enhance memory effects as threads mature, and the potential order m grows with thread complexity. This creates a sophisticated economic mechanism that naturally filters quality while accounting for the non-local nature of knowledge creation.

=== File: docs/e_concept.md ===



==
e_concept
==


# Choir: Harmonic Intelligence Platform

At its heart, Choir represents a revolutionary communication platform where value flows like energy through a natural system. Just as rivers find their paths and crystals form their patterns, quality content and collaborative teams emerge through natural principles rather than forced rules.

The platform operates through three fundamental flows that shape its natural value dynamics. Individual recognition happens organically - when someone contributes valuable insight, the recognition manifests immediately and tangibly. Like a clear note resonating through a concert hall, quality contributions naturally attract attention and rewards without needing arbitrary upvotes or likes. Value recognition emerges naturally through participation and stake.

Team crystallization follows similar natural patterns. As valuable conversations develop, they naturally attract compatible minds. Like crystals forming in solution, teams emerge not through top-down organization but through natural alignment of interests and capabilities. Each thread becomes a shared space that accumulates value for all participants, creating natural bonds between contributors.

Knowledge networks complete the value flow system. When threads reference each other, they create flows of value between communities. Like a network of streams feeding into rivers and eventually oceans, knowledge and value flow through the system, creating rich ecosystems of understanding. Each citation strengthens both source and destination, building a web of interconnected knowledge.

The system evolves through natural phases that mirror physical processes. In the early stage, new threads bubble with activity and possibility, like a hot spring. The energy runs high, stakes are elevated, and participation requires confidence - creating a natural barrier that ensures quality from the start. As threads mature, they "cool" into more stable states, like a river finding its course. The flow becomes more predictable, with stakes moderating to make participation more accessible while maintaining quality through established patterns. Finally, mature threads develop clear structures, like crystalline formations, where teams coalesce around valuable patterns, knowledge networks form clear topologies, and value accumulates in stable, beautiful ways.

Unlike traditional platforms that extract value, Choir creates spaces where value naturally accumulates through multiple channels. Threads act as resonant cavities, accumulating energy through quality interactions. Denials strengthen the thread itself rather than being wasted, teams share in their thread's growing value, and natural incentives align toward quality. Network value grows as citations create flows between threads, knowledge networks emerge organically, teams build on each other's work, and system-wide coherence develops naturally. The treasury maintains sustainable value flow by capturing split decisions and funding ongoing citations, enabling perpetual rewards that benefit the entire ecosystem.

Dynamic stake evolution creates natural quality filters with memory effects. The system uses a Fractional Quantum Anharmonic Oscillator model with three evolving parameters: the anharmonic coefficient K₀ increases in response to refusals, the fractional parameter α captures how threads develop memory and non-local interactions over time, and the potential order m reflects growing thread complexity. This mechanism ensures that value distributes in proportion to contribution quality while accounting for the interdependent, non-local nature of knowledge creation. The fractional approach enables the system to model occasional breakthrough insights that create disproportionate value across the network through Lévy flight-like patterns.

The future vision of Choir enables a new kind of collaborative intelligence. Natural teams form around resonant ideas, share in collective value, build on each other's work, and evolve sustainably. Knowledge networks connect naturally through citations, strengthen through use, create emergent insights, and enable collective intelligence. Value creation emerges from natural patterns, accumulates in stable forms, flows efficiently, and benefits all participants.

This represents just the beginning of Choir's potential. As the system evolves, we'll discover new patterns of collaboration, new forms of value creation, and new ways for teams to work together. The key lies in our approach - rather than forcing these patterns, we create the conditions for them to emerge naturally.

Join us in building a platform where quality emerges through natural principles, teams form through genuine alignment, and value flows to those who create it. Together, we can enable new forms of collective intelligence that benefit everyone, creating a truly harmonious system of collaboration and knowledge sharing.
# Level 3 Documentation



=== File: docs/plan_anonymity_by_default.md ===



==
plan_anonymity_by_default
==


==
anonymity_by_default.md
==

# Anonymity by Default: A Core Principle of Choir

VERSION anonymity_by_default: 7.0

Anonymity is not just a feature of Choir; it's a fundamental principle, a design choice that shapes the platform's architecture and informs its values. By making anonymity the default state for all users, Choir prioritizes privacy, freedom of expression, and the creation of a space where ideas are judged on their merits, not on the identity of their author.

**Core Tenets:**

1. **Privacy as a Fundamental Right:** Choir recognizes that privacy is a fundamental human right, essential for individual autonomy and freedom of thought. Anonymity protects users from surveillance, discrimination, and the potential chilling effects of being constantly identified and tracked online.
2. **Freedom of Expression:** Anonymity fosters a space where users can express themselves freely, without fear of judgment or reprisal. This is particularly important for discussing sensitive topics, challenging প্রচলিত norms, or exploring unconventional ideas.
3. **Focus on Ideas, Not Identities:** By separating ideas from their authors, anonymity encourages users to evaluate contributions based on their intrinsic value, rather than on the reputation or status of the contributor. This promotes a more meritocratic and intellectually rigorous environment.
4. **Protection from Bias:** Anonymity can help to mitigate the effects of unconscious bias, such as those based on gender, race, or other personal characteristics. It allows ideas to be judged on their own merits, rather than through the lens of preconceived notions about the author.
5. **Lower Barrier to Entry:** Anonymity makes it easier for new users to join the platform and start contributing, as they don't need to go through a complex verification process or share personal information.

**How Anonymity Works on Choir:**

- **Default State:** All users are anonymous by default upon joining the platform. They can interact, contribute content, and earn CHIP tokens without revealing their real-world identity.
- **Unique Identifiers:** Users are assigned unique, randomly generated identifiers that allow them to build a consistent presence on the platform without compromising their anonymity.
- **No Personal Data Collection:** Choir does not collect or store any personally identifiable information about anonymous users.
- **"Priors" and Anonymity:** The "priors" system, which shows the lineage of ideas, maintains anonymity by design. It reveals the connections between ideas, not the identities of the individuals who proposed them.

**Balancing Anonymity with Accountability:**

- **CHIP Staking:** The requirement to stake CHIP tokens to post new messages acts as a deterrent against spam and malicious behavior, even for anonymous users.
- **Community Moderation:** The platform relies on community moderation to maintain the quality of discourse and address any issues that arise.
- **Reputation Systems:** While users are anonymous by default, they can still build reputations based on the quality of their contributions, as tracked through the "priors" system and potentially through community ratings.

**The Value of Anonymity in a High-Information Environment:**

- **Encourages Honest Discourse:** Anonymity can encourage more honest and open discussions, particularly on sensitive or controversial topics.
- **Promotes Intellectual Risk-Taking:** Users may be more willing to take intellectual risks and explore unconventional ideas when they are not worried about the potential repercussions for their personal or professional lives.
- **Facilitates Whistleblowing and Dissent:** Anonymity can provide a safe space for whistleblowers and those who wish to express dissenting views without fear of retaliation.
- **Protects Vulnerable Users:** Anonymity can be particularly important for users in marginalized or vulnerable communities who may face risks if their identities are revealed.

**Conclusion:**

Anonymity by default is a core design principle of Choir, one that reflects the platform's commitment to privacy, freedom of expression, and the creation of a truly meritocratic space for the exchange of ideas. It's a bold choice in a world where online platforms increasingly demand real-name identification, but it's a choice that has the potential to unlock new levels of creativity, honesty, and collective intelligence. By prioritizing anonymity, Choir is not just building a platform; it's building a new model for online interaction, one that empowers individuals and fosters a more open and equitable exchange of ideas.

=== File: docs/plan_identity_as_a_service.md ===



==
plan_identity_as_a_service
==


# Identity as a Service (IDaaS)

VERSION identity_service: 7.1

Identity on Choir is optional yet valuable. By default, users can participate anonymously, preserving privacy and free expression. However, those who opt into KYC-based verification unlock the ability to participate in binding governance decisions, operate Social AI (SAI) agents under their account, and gain additional social trust signals. This document explains how Identity as a Service (IDaaS) fits into the Choir platform.

---

## Overview

Traditional online platforms typically force users to accept a real-name policy or harvest personal data without explicit consent. Choir takes a different stance:

• **Default Anonymity**: Everyone can read messages, post anonymously, and earn CHIP tokens without providing personal data.
• **Paid Identity**: Those requiring the social or governance benefits of verified status can pay for IDaaS, enabling official KYC-based identity on the platform.

The result is a tiered approach that preserves anonymity for casual or privacy-conscious users, while offering valuable identity features to those who want or need them.

---

## Core Principles

1. **Anonymity First**: No user is required to reveal their personal information to use the basic features of Choir.
2. **Paid Identity**: Identity verification introduces real-world accountability and signals commitment to the community.
3. **Signaling, Not Pay-to-Win**: Verified status does not grant better content visibility—it grants governance participation, the ability to run SAIs, and optional social credibility.
4. **Jurisdictional Compliance**: KYC standards vary globally, so IDaaS is flexible enough to accommodate region-specific regulations.
5. **Privacy Respect**: Despite verification, Choir stores personally identifying information offline and only retains essential proofs on-chain.

---

## Benefits of Verified Identity

- **Governance Participation**: Only verified users can submit binding on-chain votes in futarchy or other proposals.
- **SAI Operator Verification**: KYC ensures that an AI-driven account is mapped to a real individual for accountability.
- **Jurisdictional Compliance**: Verification aligns Choir with relevant regulations, which is critical for the platform’s long-term viability.

Additionally, verified accounts may enjoy intangible benefits like higher reputational trust within the community, though this is a social dynamic rather than a platform-engineered outcome.

---

## IDaaS Workflow

1. **Voluntary Enrollment**: You choose if/when to enroll in IDaaS.
2. **KYC Process**: Provide a government-issued ID or other documentation; a third-party service verifies authenticity.
3. **On-Chain Confirmation**: A non-reversible cryptographic link is posted on-chain (no personally identifying information, just proof of verification).
4. **Subscription or One-Time Fee**: Payment for IDaaS can be structured as recurring or one-time.
5. **Privileges Granted**: The verified user can now vote in binding governance proposals, run SAI agents, and optionally display a verified badge or signal in UI.

---

## Use Cases

- **Governance**: Ensuring that major decisions are made by real individuals with accountability.
- **SAI Execution**: Operating advanced AI software that can influence the platform, under the direct responsibility of a verified user.
- **Enterprise Collaboration**: In corporate settings, having verified internal team members fosters trust and ensures compliance with company or legal requirements.

---

## Monetization and Sustainability

Because IDaaS revenues support the system’s operational costs, they help offset free-tier usage by anonymous participants. This aligns the business model, ensuring that those who need additional capabilities also help fund the platform’s continued growth and stability.

---

## Conclusion

By offering Identity as a Service, Choir establishes a nuanced balance: anonymity remains a core value and default, while verified identity is treated as a premium feature. This approach ensures that governance decisions are accountable, advanced AI operations remain traceable to real individuals, and the platform remains compliant with jurisdictional regulations. Through IDaaS, Choir invites each user to choose the identity model that suits their needs, forging a new path forward for responsible digital communities.

=== File: docs/plan_libsql.md ===



==
plan_libsql
==


# libSQL Integration Plan for Choir

## Overview

This document outlines the implementation plan for integrating libSQL/Turso as the local persistence layer for the Choir application. This system will provide both offline functionality and synchronization with our global vector database infrastructure, while supporting the FQAHO model parameters and Post Chain architecture.

## Core Objectives

1. Implement libSQL as the primary local persistence solution
2. Design a flexible schema that can accommodate evolving data models
3. Implement vector search capabilities to support semantic matching in the Experience phase
4. Create a synchronization system between local and global databases
5. Support the FQAHO model parameters (α, K₀, m) in the database schema
6. Enable offline functionality with seamless online synchronization

## Implementation Philosophy

Our approach to database implementation will be guided by these principles:

1. **Core System First** - Focus on getting the core UX and system operational before fully committing to a database schema
2. **Flexibility** - Design the database to be adaptable as our data model evolves
3. **Incremental Implementation** - Add database features in phases, starting with the most essential components
4. **Performance** - Optimize for mobile device constraints and offline-first operation

## Technical Implementation

### 1. Database Setup and Initialization

```swift
import Libsql

class DatabaseService {
    static let shared = try! DatabaseService()

    private let database: Database
    private let connection: Connection

    private init() throws {
        // Get path to document directory for local database
        let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let dbPath = documentsDirectory.appendingPathComponent("choir.db").path

        // Initialize database with sync capabilities
        self.database = try Database(
            path: dbPath,
            url: Environment.tursoDbUrl,      // Remote database URL
            authToken: Environment.tursoToken, // Authentication token
            syncInterval: 10000               // Sync every 10 seconds
        )

        self.connection = try database.connect()

        // Initialize schema
        try setupSchema()
    }

    private func setupSchema() throws {
        try connection.execute("""
            -- Users table
            CREATE TABLE IF NOT EXISTS users (
                id TEXT PRIMARY KEY,
                name TEXT,
                last_active INTEGER
            );

            -- Threads table
            CREATE TABLE IF NOT EXISTS threads (
                id TEXT PRIMARY KEY,
                title TEXT,
                created_at INTEGER,
                updated_at INTEGER,
                k0 REAL,           -- FQAHO parameter K₀
                alpha REAL,        -- FQAHO parameter α (fractional)
                m REAL             -- FQAHO parameter m
            );

            -- Messages table with vector support
            CREATE TABLE IF NOT EXISTS messages (
                id TEXT PRIMARY KEY,
                thread_id TEXT,
                user_id TEXT,
                content TEXT,
                embedding F32_BLOB(1536),  -- Vector embedding for semantic search
                phase TEXT,                -- Post Chain phase identifier
                created_at INTEGER,
                approval_status TEXT,      -- For approval/refusal statistics
                FOREIGN KEY(thread_id) REFERENCES threads(id),
                FOREIGN KEY(user_id) REFERENCES users(id)
            );

            -- Vector index for similarity search in Experience phase
            CREATE INDEX IF NOT EXISTS messages_embedding_idx
            ON messages(libsql_vector_idx(embedding));

            -- Parameter history for FQAHO model tracking
            CREATE TABLE IF NOT EXISTS parameter_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                thread_id TEXT,
                timestamp INTEGER,
                k0 REAL,
                alpha REAL,
                m REAL,
                event_type TEXT,  -- What caused the parameter change
                FOREIGN KEY(thread_id) REFERENCES threads(id)
            );
        """)
    }
}
```

### 2. Thread and Message Operations

```swift
extension DatabaseService {
    // MARK: - Thread Operations

    func createThread(id: String, title: String, k0: Double, alpha: Double, m: Double) throws {
        let now = Int(Date().timeIntervalSince1970)

        try connection.execute("""
            INSERT INTO threads (id, title, created_at, updated_at, k0, alpha, m)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, [id, title, now, now, k0, alpha, m])

        // Record initial parameters
        try connection.execute("""
            INSERT INTO parameter_history (thread_id, timestamp, k0, alpha, m, event_type)
            VALUES (?, ?, ?, ?, ?, ?)
        """, [id, now, k0, alpha, m, "thread_creation"])
    }

    func getThread(id: String) throws -> Thread? {
        let results = try connection.query(
            "SELECT * FROM threads WHERE id = ?",
            [id]
        )

        guard let result = results.first else { return nil }

        return Thread(
            id: result["id"] as! String,
            title: result["title"] as! String,
            createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
            updatedAt: Date(timeIntervalSince1970: TimeInterval(result["updated_at"] as! Int)),
            k0: result["k0"] as! Double,
            alpha: result["alpha"] as! Double,
            m: result["m"] as! Double
        )
    }

    func updateThreadParameters(threadId: String, k0: Double, alpha: Double, m: Double, eventType: String) throws {
        let now = Int(Date().timeIntervalSince1970)

        // Update thread
        try connection.execute("""
            UPDATE threads
            SET k0 = ?, alpha = ?, m = ?, updated_at = ?
            WHERE id = ?
        """, [k0, alpha, m, now, threadId])

        // Record parameter change
        try connection.execute("""
            INSERT INTO parameter_history (thread_id, timestamp, k0, alpha, m, event_type)
            VALUES (?, ?, ?, ?, ?, ?)
        """, [threadId, now, k0, alpha, m, eventType])
    }

    // MARK: - Message Operations

    func createMessage(id: String, threadId: String, userId: String, content: String,
                       embedding: [Float], phase: String) throws {
        let now = Int(Date().timeIntervalSince1970)
        let vectorString = "vector32('\(embedding)')"

        try connection.execute("""
            INSERT INTO messages (id, thread_id, user_id, content, embedding, phase, created_at, approval_status)
            VALUES (?, ?, ?, ?, \(vectorString), ?, ?, 'pending')
        """, [id, threadId, userId, content, phase, now])

        // Update thread's last activity
        try connection.execute("""
            UPDATE threads
            SET updated_at = ?
            WHERE id = ?
        """, [now, threadId])
    }

    func updateMessageApprovalStatus(messageId: String, status: String) throws {
        try connection.execute("""
            UPDATE messages
            SET approval_status = ?
            WHERE id = ?
        """, [status, messageId])

        // If we wanted to update FQAHO parameters based on approval/refusal, we could do that here
        if let message = try getMessage(id: messageId),
           let thread = try getThread(id: message.threadId) {

            // Calculate new parameters based on approval/refusal
            let newK0 = calculateNewK0(currentK0: thread.k0, approvalStatus: status)
            let newAlpha = calculateNewAlpha(currentAlpha: thread.alpha, approvalStatus: status)
            let newM = calculateNewM(currentM: thread.m, approvalStatus: status)

            try updateThreadParameters(
                threadId: message.threadId,
                k0: newK0,
                alpha: newAlpha,
                m: newM,
                eventType: "message_\(status)"
            )
        }
    }

    func getMessage(id: String) throws -> Message? {
        let results = try connection.query(
            "SELECT * FROM messages WHERE id = ?",
            [id]
        )

        guard let result = results.first else { return nil }

        return Message(
            id: result["id"] as! String,
            threadId: result["thread_id"] as! String,
            userId: result["user_id"] as! String,
            content: result["content"] as! String,
            phase: result["phase"] as! String,
            createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
            approvalStatus: result["approval_status"] as! String
        )
    }
}
```

### 3. Vector Search for Experience Phase

```swift
extension DatabaseService {
    // Find semantically similar messages for the Experience phase
    func findSimilarExperiences(threadId: String, queryEmbedding: [Float], limit: Int = 5) throws -> [Message] {
        let vectorString = "vector32('\(queryEmbedding)')"

        let results = try connection.query("""
            SELECT m.*
            FROM vector_top_k('messages_embedding_idx', \(vectorString), ?) as v
            JOIN messages m ON m.rowid = v.id
            WHERE m.thread_id = ?
            AND m.approval_status = 'approved'
        """, [limit, threadId])

        return results.map { result in
            Message(
                id: result["id"] as! String,
                threadId: result["thread_id"] as! String,
                userId: result["user_id"] as! String,
                content: result["content"] as! String,
                phase: result["phase"] as! String,
                createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
                approvalStatus: result["approval_status"] as! String
            )
        }
    }

    // Get experiences with prior parameter values (for display in Experience step)
    func getExperiencesWithPriors(threadId: String, limit: Int = 10) throws -> [(Message, ParameterSet)] {
        let results = try connection.query("""
            SELECT m.*, p.k0, p.alpha, p.m
            FROM messages m
            JOIN parameter_history p ON
                m.thread_id = p.thread_id AND
                m.created_at >= p.timestamp
            WHERE m.thread_id = ?
            AND m.phase = 'experience'
            ORDER BY m.created_at DESC
            LIMIT ?
        """, [threadId, limit])

        return results.map { result in
            let message = Message(
                id: result["id"] as! String,
                threadId: result["thread_id"] as! String,
                userId: result["user_id"] as! String,
                content: result["content"] as! String,
                phase: result["phase"] as! String,
                createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
                approvalStatus: result["approval_status"] as! String
            )

            let parameters = ParameterSet(
                k0: result["k0"] as! Double,
                alpha: result["alpha"] as! Double,
                m: result["m"] as! Double
            )

            return (message, parameters)
        }
    }
}
```

### 4. Synchronization Management

```swift
extension DatabaseService {
    // Trigger manual sync with remote database
    func syncWithRemote() throws {
        try database.sync()
    }

    // Check if a sync is needed
    var needsSync: Bool {
        // Implementation depends on how we track local changes
        // Could check for pending operations or time since last sync
        return true
    }

    // Handle network status changes
    func handleNetworkStatusChange(isOnline: Bool) {
        if isOnline && needsSync {
            do {
                try syncWithRemote()
            } catch {
                print("Sync error: \(error)")
                // Handle sync failure
            }
        }
    }
}
```

### 5. FQAHO Parameter Calculation Functions

```swift
extension DatabaseService {
    // Calculate new K₀ value based on approval/refusal
    private func calculateNewK0(currentK0: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model K₀ adjustment
        let adjustment: Double = approvalStatus == "approved" ? 0.05 : -0.08
        return max(0.1, min(10.0, currentK0 + adjustment))
    }

    // Calculate new α value based on approval/refusal
    private func calculateNewAlpha(currentAlpha: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model α adjustment
        // Fractional parameter capturing memory effects
        let adjustment: Double = approvalStatus == "approved" ? 0.02 : -0.03
        return max(0.1, min(2.0, currentAlpha + adjustment))
    }

    // Calculate new m value based on approval/refusal
    private func calculateNewM(currentM: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model m adjustment
        let adjustment: Double = approvalStatus == "approved" ? -0.01 : 0.02
        return max(0.5, min(5.0, currentM + adjustment))
    }
}
```

## Phased Implementation Approach

Given that UX has more pressing issues and the data model is still evolving, we'll adopt a phased approach to database implementation:

### Phase 1: Core UX Development (Current Focus)

- Continue developing the core UI and interaction flow
- Prioritize UX improvements over database implementation
- Use in-memory or mock data for testing

### Phase 2: Schema Development and Validation

- Finalize initial schema design as the core system stabilizes
- Create prototypes to validate the schema with real usage patterns
- Ensure the schema can adapt to evolving requirements

### Phase 3: Basic Database Implementation

- Implement basic CRUD operations for threads and messages
- Set up the database connection and initialization
- Create simplified data services for the UI to consume

### Phase 4: Vector Search Implementation

- Add vector embedding storage and search
- Connect the Experience phase to vector similarity search
- Optimize for performance and memory usage

### Phase 5: FQAHO Parameter Support

- Implement parameter storage and history tracking
- Add parameter calculation algorithms
- Connect parameter adjustments to the UI

### Phase 6: Synchronization

- Configure embedded replicas
- Implement sync management
- Handle offline/online transitions

## Integration with Post Chain Phases

The libSQL implementation will support all phases of the Post Chain:

1. **Action** - Store user messages and initial parameters
2. **Experience** - Use vector search to find relevant prior experiences
3. **Understanding** - Track message reactions and parameter adjustments
4. **Web Search** - Store search results with vector embeddings for future reference
5. **Tool Use** - Record tool usage patterns and outcomes

## Flexible Schema Design Principles

Since the data model is still evolving, the database schema should follow these principles:

1. **Versioned Schema** - Include version markers in the schema to facilitate future migrations
2. **Nullable Fields** - Use nullable fields where appropriate to accommodate evolving requirements
3. **Isolated Tables** - Keep related concepts in separate tables to minimize the impact of changes
4. **Extensible Records** - Consider using a JSON or blob field for attributes that might change frequently
5. **Minimal Dependencies** - Limit foreign key constraints to essential relationships

## Future Considerations

1. **Multi-device Sync**

   - Ensure consistent user experience across devices
   - Handle conflict resolution

2. **Advanced Vector Quantization**

   - Implement quantization for more efficient storage
   - Optimize for mobile device constraints

3. **Partitioned User Databases**

   - Implement per-user database isolation
   - Support multi-tenancy within the app

4. **Backup and Recovery**

   - Implement regular backup mechanisms
   - Create recovery procedures

5. **Extensions for Multimodal Support**
   - Extend schema for image and audio data
   - Implement multimodal vector embeddings

## Resources

- [Turso Swift Documentation](https://docs.turso.tech/swift)
- [libSQL Swift GitHub Repository](https://github.com/tursodatabase/libsql-swift)
- [Embedded Replicas Documentation](https://docs.turso.tech/embedded-replicas)
- [Vector Search Documentation](https://docs.turso.tech/vector-search)
# Level 4 Documentation



=== File: docs/fqaho_simulation.md ===



==
fqaho_simulation
==


# FQAHO Simulation Framework

VERSION fqaho_simulation: 1.0

This document outlines the simulation framework for Choir's Fractional Quantum Anharmonic Oscillator (FQAHO) model, providing guidance for accurate parameter setting, modulation, and testing.

## Simulation Objectives

The FQAHO simulation serves multiple objectives:

1. Calibrate optimal parameter ranges and sensitivity coefficients
2. Test system response to various thread evolution scenarios
3. Verify the economic stability and fairness properties
4. Generate synthetic metadata for downstream analysis

## Parameter Framework

### Fractional Parameter (α)

- **Range**: 1 < α ≤ 2
- **Interpretation**: Controls memory effects and non-local interactions
- **Modulation Formula**:
  ```
  α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q
  ```
  Where t is normalized thread age, q measures quality, τ sets the time constant, and δ₁, δ₂ determine sensitivity.

### Anharmonic Coefficient (K₀)

- **Range**: 0.5 ≤ K₀ ≤ 5.0
- **Interpretation**: Represents immediate feedback sensitivity
- **Modulation Formula**:
  ```
  K₀(r,α) = K₀_base * (1 + γ₁r) * (2/α)^γ₂
  ```
  Where r is the recent refusal ratio, γ₁ is refusal sensitivity, and γ₂ is the fractional coupling coefficient.

### Potential Order (m)

- **Range**: 2 ≤ m ≤ 4
- **Interpretation**: Represents network complexity and interaction depth
- **Modulation Formula**:
  ```
  m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)
  ```
  Where c is citation count, n is co-author count, and β₁, β₂ are scaling coefficients.

## Implementation Approach

The FQAHO implementation functions as a sophisticated single-asset automated market maker (AMM) for stake pricing. This approach allows us to incorporate fractional effects through parameter modulation without requiring computationally intensive fractional calculus operations.

The core pricing formula:

```
P₀ = S₀[(2n+1)^(α/2) + (K₀λ)^{α/(m+1)}]
```

This provides fair price calculation while capturing:

- Long memory effects through α's modulation
- Heavy-tailed distributions through modified response curves
- Non-local interactions through citation-based parameter adjustments

## Simulation Phases

### Phase 1: Parameter Isolation

- Fix two parameters, vary the third
- Observe stake price response
- Repeat for all parameters
- Identify stable operating ranges

### Phase 2: Parameter Coupling

- Create a 3D parameter space (K₀, α, m)
- Identify regions of interest (stable, volatile, etc.)
- Map these regions to thread characteristics
- Define parameter coupling formulas

### Phase 3: Dynamic Trajectories

- Simulate thread evolution over time
- Track parameter trajectories
- Identify pattern types (e.g., "breakthrough thread," "steady contributor")
- Fine-tune sensitivity coefficients

## Test Scenarios

1. **New Thread Evolution**

   - Start with α ≈ 2.0, low K₀, low m
   - Test with various approval/refusal patterns
   - Verify parameter evolution matches expectations

2. **Mature Thread with Citations**

   - Start with mid-range α, stable K₀, higher m
   - Introduce citation events
   - Verify non-local value propagation

3. **Controversial Thread**

   - Introduce oscillating approval/refusal patterns
   - Test parameter stability under volatility
   - Verify price mechanisms create appropriate barriers

4. **Breakthrough Thread**
   - Simulate rapid approval and citation growth
   - Verify Lévy flight-like value distribution
   - Test parameter adaptation to rapid change

## Implementation Notes

- Use dimensionless units for cleaner analysis
- Create visualization tools for parameter evolution, price dynamics, and value distribution
- Store simulation metadata for AI training and pattern analysis
- Compare parameter regimes for highest intelligence emergence

## Success Criteria

The simulation successfully validates the FQAHO model when:

1. Parameters remain within stable bounds under diverse scenarios
2. Price discovery correctly values quality contributions
3. Memory effects appropriately influence current pricing
4. Non-local interactions propagate value effectively
5. Parameter coupling creates coherent evolution patterns

This framework enables us to implement a sophisticated economic model that captures the complex dynamics of knowledge creation while remaining computationally tractable and deterministic enough for blockchain implementation.

=== File: docs/fqaho_visualization.md ===



==
fqaho_visualization
==


# FQAHO Model Visualization Guide

VERSION fqaho_visualization: 1.0

Effective visualization is essential for understanding the complex parameter space and dynamics of the Fractional Quantum Anharmonic Oscillator model. This document outlines visualization approaches that help reveal patterns, stability regions, and emergent behaviors.

## Core Visualizations

### 1. Parameter Space Mapping

**3D Parameter Volume**

- Plot (α, K₀, m) as a 3D volume
- Color regions by stake price or stability metrics
- Identify stable operating regions
- Mark observed thread trajectories

**2D Parameter Slices**

- Create heatmaps of paired parameters (α-K₀, α-m, K₀-m)
- Overlay contour lines showing equal price points
- Highlight critical transition boundaries

### 2. Dynamic Trajectories

**Thread Evolution Paths**

- Plot parameter evolution over thread lifetime
- Color-code by thread type or quality metrics
- Identify common patterns and outliers
- Compare to theoretical predictions

**Price Evolution Curves**

- Show stake price changes over thread lifecycle
- Overlay approval/refusal events
- Highlight price sensitivity to parameter changes

### 3. Network Effects

**Citation Network Influence**

- Visualize how citations create parameter coupling
- Show Lévy flight patterns in value propagation
- Map value flows between connected threads

**Fractional Memory Effects**

- Display the decay kernel shape for different α values
- Demonstrate how past events influence current prices
- Compare with standard memory-less models

## Implementation Techniques

### Interactive Dashboards

- Create parameter sliders with real-time model updates
- Enable toggling between different test scenarios
- Provide zoom/rotate capabilities for 3D visualizations

### Animation

- Animate parameter evolution over simulated time
- Show critical transition points and regime changes
- Illustrate how parameter coupling creates coherent behavior

### Comparative Views

- Side-by-side comparison of standard QAHO vs. FQAHO
- Show differences in value distribution and memory effects
- Demonstrate improved accuracy of the fractional approach

## Technical Recommendations

- Implement visualizations using D3.js or Plotly for web interfaces
- Use Python with Matplotlib/Seaborn for detailed analysis
- Capture high-resolution snapshots at critical points
- Consider WebGL for complex 3D parameter spaces

## Documentation Integration

These visualizations should be incorporated into technical documentation with:

- Clear explanations of what each visualization reveals
- Connections to theoretical principles
- Practical implications for users and developers
- Progressive disclosure (simple views first, complex details available)

Effective visualization is crucial for communicating the sophistication of the FQAHO model while making it accessible to stakeholders with varying levels of mathematical background.
# Level 5 Documentation



=== File: docs/data_engine_model.md ===



==
data_engine_model
==


# Ideal Data Engine Theory

VERSION data_engine: 7.0

The ideal data engine emerged as a theoretical framework while exploring how to generate the highest quality training data for artificial intelligence. Rather than starting with computational requirements or algorithmic efficiency, we asked a more fundamental question: what would a system optimized purely for generating intelligence look like?

The answer revealed itself through an unexpected convergence of fractional quantum mechanics and semantic patterns. A true intelligence engine, we discovered, would treat discourse not as content to be processed but as a non-local generative field where meaning emerges through interaction with memory effects. Each conversation becomes a semantic event that can increase the density of understanding in the system across space and time.

This insight led to Choir's core innovation: tokens that represent genuine intellectual contribution with memory effects. As threads become more semantically dense and contextually rich, they generate more value through non-local Lévy flight-like patterns. Citations create knowledge networks with long-range correlations. Teams form around resonant patterns of understanding that persist and evolve. The system naturally evolves toward higher states of collective intelligence through fractional dynamics.

What makes this approach profound is how it aligns economic incentives with the generation of meaning across space and time. Value isn't imposed externally but emerges from the semantic density of interactions with memory effects. The system rewards depth over volume, nuance over noise, intellectual rigor over viral spread—not through arbitrary rules but through its fundamental fractional architecture.

We're discovering that intelligence generation follows principles as fundamental as fractional quantum mechanics. Just as non-local effects and Lévy flights characterize fractional systems, meaning flows through semantic gradients with memory effects. Just as energy follows fractional conservation laws in physical systems, value is conserved in semantic networks with persistent memory. These aren't mere metaphors but hints at deeper patterns in how collective intelligence emerges.

Choir represents our first attempt to build a system aligned with these principles. We're not just collecting data or optimizing engagement—we're creating conditions for intelligence to emerge naturally through discourse with memory effects and non-local interactions. The implications extend far beyond artificial intelligence, suggesting new ways of understanding how knowledge and value co-evolve in complex non-local systems.

This is just the beginning of understanding how intelligence emerges in networked systems. The ideal data engine harnesses a Fractional Quantum Anharmonic Oscillator (FQAHO) model to quantify energy and value flows with memory effects. This model uses a fractional parameter α to capture how threads remember their history and interact non-locally. Stake pricing adapts through coupled parameter modulation, with the fractional parameter (α), anharmonic coefficient (K₀), and potential order (m) all evolving based on thread characteristics and network position.

The result is a system where quality and value propagate through Lévy flight-like patterns rather than simple diffusion, creating a more natural and accurate representation of how collective intelligence actually emerges and evolves. The fractional approach allows us to model the "heavy tails" of value distribution, where occasional breakthrough insights generate disproportionate impact across the network.

=== File: docs/evolution_naming.md ===



==
evolution_naming
==


==
evolution_naming.md
==

# From RAG to Post Chain: A Name's Evolution, a System's Identity

VERSION evolution_naming: 7.0

The journey of Choir's core mechanism, from a simple concept to its current form, mirrors the evolution of the platform itself. Each name change reflects a deeper understanding, a refinement of purpose, a shift in perspective. It's a story of emergence, where the name didn't just describe the system, but helped shape it.

It began with **RAG - Retrieval-Augmented Generation**. A functional description, accurate yet sterile. It spoke to the technical process but lacked the spark of life, the hint of something more. RAG was about retrieving information; it wasn't yet about generating understanding.

Then came **Vowel Loop**, a name born from the observation of linguistic patterns, the AEIOU and sometimes Y. It was playful, memorable, but perhaps too niche, too focused on a specific detail. It hinted at the importance of language but didn't capture the broader scope. Still, it was a step towards recognizing the system's unique relationship with language.

**Chorus Cycle** arrived next, a name that resonated with the platform's core philosophy. It evoked collaboration, harmony, the interplay of voices. It described the iterative process, the six phases of refinement. But it was also complex, potentially intimidating. It focused on the process, but perhaps not enough on the outcome.

And so, we arrive at **Post Chain**. A name that is both simple and profound. "Post" speaks to the fundamental unit of interaction, the message, the contribution. "Chain" evokes connection, sequence, the building of knowledge over time. It hints at the blockchain foundation, the "chain of thought" reasoning, the causal chain of events.

**Post Chain** is more than just a name; it's a statement of intent. It's about creating a system where each post is a link in a larger chain, where individual contributions connect to form a collective intelligence. It's about building a platform where knowledge is not just retrieved but generated, where meaning is not just found but created.

The shift from Chorus Cycle to Post Chain also marks a crucial conceptual evolution. It's a move from a focus on process to a focus on outcome. The phases are still there, the underlying mechanisms remain, but they are now implicit, not explicit. The emphasis is on the chain of posts, the interconnectedness of ideas, the emergent intelligence.

This evolution is not merely semantic. It reflects a deeper understanding of the system's core principles, a refinement of its purpose, a recognition of its potential. **Post Chain** is the name that embodies the platform's essence: a simple, powerful, and elegant system for building collective intelligence, one post at a time. It is easy to say, and means what it says. It is direct.


=== File: docs/evolution_stack.md ===



==
evolution_stack
==


# Choir Stack Evolution

## Evolution Phases

### Phase 1: Prototype Era
```elixir
| Component       | Technology          | Rationale                          |
|-----------------|---------------------|------------------------------------|
| Backend         | Elixir/Phoenix      | Actor model familiarity            |
| AI Integration  | OpenAI Raw API      | Quickest integration               |
| Vector DB       | Qdrant              | OSS vector search                  |
| Frontend        | Next.js             | Rapid UI development               |
| Blockchain      | Solana              | High throughput claims             |
```

**Key Innovations:**
- First implementation of Post Chain concept
- Basic citation tracking architecture

**Challenges:**
- Elixir's AI ecosystem limitations
- State management complexity

---

### Phase 2: Python Foundation
```python
| Component       | Technology          | Rationale                          |
|-----------------|---------------------|------------------------------------|
| Backend         | FastAPI             | Python ecosystem richness          |
| AI Abstraction  | LiteLLM             | Multi-provider support             |
| Vector DB       | Qdrant+pgvector     | Hybrid search capabilities         |
| Mobile          | SwiftUI             | Native iOS experience              |
| Blockchain      | Ethereum            | Mature smart contracts             |
```

**Architectural Shifts:**
- Transition to Python-centric AI stack
- Hybrid vector/SQL search implementation

---

### Phase 3: Workflow Orchestration
```python
| Component       | Technology          | Rationale                          |
|-----------------|---------------------|------------------------------------|
| Orchestration   | LangGraph           | Explicit workflow control          |
| State Management| LangGraph Checkpoint| Built-in persistence               |
| Analytics       | DuckDB              | Embedded analytical processing     |
```

**Key Developments:**
- Visual workflow debugging capabilities
- Automated conversation state persistence

---

### Phase 4: MCP Architecture
```python
| Component       | Technology          | Rationale                          |
|-----------------|---------------------|------------------------------------|
| Core Framework  | MCP Architecture            | Service-oriented phase implementation  |
| Validation      | PydanticAI          | Type-safe LLM interactions         |
| Database        | libSQL/Turso        | Embedded+cloud sync                |
| Mobile          | Swift+Sui           | Move protocol integration          |
| Deployment      | Phala Network       | TEE-secured operations             |
```

**Current Advantages:**
- Distributed MCP-based architecture
- Confidential computing integration
- Strong type safety across stack

## Key Evolution Drivers

1. **Concurrency Model Evolution**
   - Elixir Processes → Python Threads → MCP Servers

2. **State Management Journey**
   - Phoenix Contexts → LangGraph Checkpoints → Actor Persistence

3. **AI Abstraction Layers**
   - Raw OpenAI → LiteLLM → PydanticAI+Worker Pools

4. **Blockchain Maturation**
   - Solana → Ethereum → Sui Move Protocol

5. **Security Evolution**
   - Basic Auth → JWT → TEE-based Confidential Computing

## Architectural Lessons

1. **MCP Architecture Insights**
   - Service boundaries improve system reliability and maintainability
   - Decentralized state management enhances scalability

2. **Blockchain Realities**
   - Move protocol's resource-oriented design superior for financial primitives
   - TEEs enable novel trust models beyond pure blockchain

3. **AI Production Patterns**
   - Type safety becomes non-negotiable at scale
   - Cold start mitigation critical for user experience

4. **Mobile First Principles**
   - Native implementations outperform cross-platform
   - On-device AI integration inevitable

## Future Evolution Path

```mermaid
graph LR
    Current[MCP/PydanticAI/libSQL/Sui]
    --> RustCore[Rust Core Services]
    --> SGX[Full Memory Enclaves]
    --> ZK[Zero-Knowledge Proofs]

    Current --> OnDevice[Swift MLX Integration]
    --> Federated[Federated Learning]
```

This document will be maintained at `docs/evolution_stack.md` with architectural updates.

=== File: docs/evolution_token.md ===



==
evolution_token
==


==
evolution_token.md
==

# The Evolution of CHIP: Beyond Utility

VERSION evolution_token: 7.0

The CHIP token has transcended its initial conception as a mere utility token. It has evolved into something more profound: a representation of value, participation, and ownership within the Choir ecosystem. This document details the evolution of CHIP's role and its significance in the Post Chain paradigm.

**Beyond Utility:** The term "utility token" often implies a limited scope, a token whose value is solely derived from its use within a specific platform. CHIP, however, has grown beyond this narrow definition. It is not simply a means to access features or perform actions; it is a fundamental component of the platform's value proposition.

**A Stake in the Data Union:** CHIP represents a share in the collective intelligence of Choir, a stake in the data union. This ownership model empowers users, giving them a voice in the platform's governance and a share in its success. It's a departure from the extractive models of traditional platforms, where users are merely sources of data.

**The Poker Chip Analogy:** The analogy to poker chips is apt, but it's more than just a metaphor. CHIP, like a poker chip, represents a commitment, a willingness to engage in the game. However, unlike poker, Choir is not a zero-sum game. It's a positive-sum environment where collaboration and knowledge creation benefit all participants.

**The Liminal Space:** CHIP exists in the liminal space between a currency and an equity. It's not intended as a general-purpose medium of exchange, but it holds value beyond its immediate utility. It represents a "bet" on the future of Choir, an investment in the potential of collective intelligence.

**ICM and Long-Term Value:** The Independent Chip Model (ICM) from poker provides a useful framework for understanding CHIP's value dynamics. Just as ICM encourages players to focus on long-term expected value, CHIP incentivizes contributions that enhance the platform's overall worth, not just short-term gains.

**Beyond Speculation:** By emphasizing CHIP's role in participation, value representation, and ownership, we discourage the kind of speculative behavior that plagues many cryptocurrencies. CHIP is designed to be a tool for building and sharing knowledge, not a get-rich-quick scheme.

**Implications for the Future:**

- **New Economic Models:** CHIP's evolution points towards new economic models for online platforms, where users are not just consumers but also owners and stakeholders.
- **Decentralized Governance:** CHIP could play a key role in the decentralized governance of Choir, giving users a direct voice in shaping the platform's future.
- **Value Alignment:** The tokenomics of CHIP are designed to align the incentives of users, developers, and the platform itself, creating a virtuous cycle of growth and innovation.

The evolution of CHIP from a utility token to a multifaceted representation of value and participation is a testament to the dynamic and emergent nature of the Choir platform. It reflects a deeper understanding of the relationship between technology, economics, and human collaboration.


=== File: docs/README.md ===



==
README
==


# Choir Documentation

## Documentation Reorganization: From Graphs to Actors

Choir has undergone a significant architectural pivot from a graph-based to an actor-based architecture. This document explains the documentation reorganization that accompanies this architectural change.

## Why We're Reorganizing

The shift from LangGraph to an actor model represents more than just a technical implementation change—it reflects a fundamental rethinking of how we conceptualize and build AI systems. Our documentation needed to evolve alongside this architectural shift to:

1. **Reflect the actor model paradigm** - Providing mental models that align with actor-based thinking
2. **Organize information coherently** - Creating a logical progression from concepts to implementation
3. **Support both new and existing users** - Making the transition smoother for those familiar with the previous architecture
4. **Enable future extensions** - Building a documentation structure that can grow with the system

## New Documentation Structure

The documentation has been reorganized into a clear, hierarchical structure:

### 1. Core Concepts

Fundamental ideas that remain consistent regardless of implementation:

- [Actor Model Overview](1-concepts/actor_model_overview.md) - Introduction to the actor model
- [Scale-Free Actor Architecture](1-concepts/scale_free_actor_architecture.md) - Fractal patterns in actor systems
- [PostChain Conceptual Model](postchain_actor_model.md) - The core AEIOU-Y framework

### 2. Architecture

Detailed information about the actor-based architecture:

- [Actor System Diagrams](2-architecture/actor_system_diagram.md) - Visual representations of the actor system
- [Architecture Transition Narrative](archive/architecture_transition_narrative.md) - The story of our architectural evolution
- [Stack Argument](stack_argument.md) - Rationale for our technology choices

### 3. Implementation

Practical guidance for implementing actor-based systems:

- [Developer Quickstart](3-implementation/developer_quickstart.md) - Fast onboarding guide
- [Message Protocol Reference](message_protocol_reference.md) - Comprehensive message format documentation
- [State Management Patterns](3-implementation/state_management_patterns.md) - Best practices for actor state

### 4-6. Integration, Operations, Business

Additional sections covering integration with external systems, operational concerns, and business aspects.

## Documentation as Code

Our documentation follows these principles:

1. **Version Control** - Documentation evolves alongside code
2. **Markdown Format** - All documents use Markdown for consistency and readability
3. **Diagrams as Code** - Architecture diagrams use Mermaid.js for maintainability
4. **Clear Hierarchy** - Numbered directories create a logical progression

## Navigation

The primary entry point is [index.md](index.md), which provides links to all major sections.

For a chronological view of Choir's evolution, see the [CHANGELOG.md](CHANGELOG.md).

## The Meta-Story

This documentation reorganization represents more than just moving files—it embodies our shift toward thinking in terms of actors, messages, and encapsulated state. The structure itself reflects the actor model's principles:

- **Isolation** - Each document has a clear, focused purpose
- **Message-Based** - Documents reference each other through explicit links
- **Hierarchy** - Clear organization from abstract concepts to concrete implementation

By reorganizing our documentation in this way, we aim to make the actor model more intuitive and accessible, helping users understand not just how to use the system, but why it's designed this way.

## Contributing to Documentation

If you'd like to contribute to the documentation:

1. Review the [Architecture Reorganization Plan](archive/architecture_reorganization_plan.md)
2. Follow the existing folder structure and naming conventions
3. Use Markdown for all documentation
4. Include diagrams using Mermaid.js where appropriate
5. Submit a pull request with your changes

## Feedback

This documentation reorganization is an ongoing process. If you have suggestions, questions, or feedback about the documentation structure, please open an issue on our GitHub repository.

=== File: docs/architecture_reorganization_plan_mcp.md ===



==
architecture_reorganization_plan_mcp
==


# Detailed Plan: MCP Architecture for PostChain with SSE Streaming and Model Abstraction

## 1. Define Model-Aware MCP Servers for Each Phase (SSE Streaming & Langchain Utils Integration)

We will create a separate MCP server for each of the six PostChain phases: Action, Experience, Intention, Observation, Understanding, and Yield. Each server will be enhanced to support Server-Sent Events (SSE) for streaming output and will utilize the existing model abstraction layer in `api/app/langchain_utils.py`. Each server will provide *two* SSE streams:

*   **`reasoning` stream:**  For emitting tokens representing the reasoning process of the phase. This stream is optional and may be empty for phases without explicit reasoning steps.
*   **`answer` stream:** For emitting the final output tokens of the phase.

Each MCP server will:

*   **Random Model Selection:**  Each server will randomly select a model at initialization from the list returned by `get_tool_compatible_models(config)` in `langchain_utils.py` (for random model mode).
*   **Fixed Model for Prototype:** For the initial prototype (in "fixed model mode"), each server will use `config.GOOGLE_GEMINI_20_FLASH` for simplicity and speed.
*   **Utilize `langchain_utils.py`:** Import and use functions from `langchain_utils.py` (especially `get_base_model` and `convert_to_langchain_messages`) to initialize and interact with LLMs. This ensures consistency with the existing model abstraction layer.
*   **Model Configuration:**  Each server will have a configuration option to switch between *fixed model* (`GOOGLE_GEMINI_20_FLASH`) and *random model selection* modes.
*   **SSE Streaming with Reasoning Token Extraction:** Implement dual SSE streams (`reasoning` and `answer`) and model-specific logic for extracting reasoning tokens.  This logic will be tailored to the models chosen for each phase and will likely involve conditional parsing based on the model provider (e.g., checking for `</think>` for DeepSeek, `"reasoning"` field for Claude, etc.).

## 2. Model and Tool Allocation per Phase (Refined Model Choices & Langchain Utils)

*   **Action Server:**
    *   Purpose: Handle user input, initial prompting, and route messages.
    *   Model: Randomly selected from `get_tool_compatible_models(config)` (random mode).  *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools: `ask_followup_question`.
    *   SSE Streams:  Primarily `answer` stream for the initial prompt or clarification questions. `reasoning` stream likely minimal.

*   **Experience Server:**
    *   Purpose: Enrich context with past knowledge, retrieve relevant information.
    *   Models:  Randomly selected from `get_tool_compatible_models(config)` (random mode). *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools: `brave_web_search`, `fetch_url`, `qdrant`.
    *   SSE Streams: `reasoning` stream could show search queries and document summaries as they are processed. `answer` stream would contain the final enriched context.

*   **Intention Server:**
    *   Purpose:  Model user intent, track goals, and focus information.
    *   Model: Randomly selected from `get_tool_compatible_models(config)` (random mode). *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools:  None initially, focus on model-driven intent inference.
    *   SSE Streams: `reasoning` stream would emit the thoughts generated by `sequentialthinking`. `answer` stream would contain the final inferred intent and goals.

*   **Observation Server:**
    *   Purpose: Track semantic connections, tag information, and preserve relationships.
    *   Model: Randomly selected from `get_tool_compatible_models(config)` (random mode). *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools: None initially, focus on internal state management.
    *   SSE Streams: `reasoning` stream could describe the semantic analysis process. `answer` stream would confirm the observation actions taken (tagging, linking, etc.).

*   **Understanding Server:**
    *   Purpose: Evaluate context, filter information, and manage information release.
    *   Model: Randomly selected from `get_tool_compatible_models(config)` (random mode). *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools: None initially, focus on model-driven context evaluation and filtering.
    *   SSE Streams: `reasoning` stream (showing context evaluation and filtering steps), `answer` stream (final refined context).

*   **Yield Server:**
    *   Purpose: Format output, decide on recursion, and complete the process.
    *   Model: Randomly selected from `get_tool_compatible_models(config)` (random mode). *Fixed Prototype Model:* `config.GOOGLE_GEMINI_20_FLASH`.
    *   Tools: `attempt_completion`, `write_to_file`.
    *   SSE Streams: `reasoning` stream (for output formatting steps), `answer` stream (final formatted output).

## 3. Orchestration and Communication (Python API, SSE, Langchain Utils, Dynamic Models)

The Python API will:

*   Use `langchain_utils.py` for any client-side model interactions if needed (though most model interactions will be within MCP servers).
*   Orchestrate MCP server calls and SSE stream handling.
*   Be aware that each phase can now use a *randomly selected* tool-compatible model.

## 4. Prototyping and Testing (Model-Specific SSE, Langchain Utils Integration)

Prototyping will involve:

*   Selecting specific models for each of the Action, Experience, and Yield phases (as outlined above).
*   Implementing model-specific reasoning token extraction in each server, tailored to the chosen models (DeepSeek, Claude, etc.).
*   Integrating `langchain_utils.py` for model initialization within each MCP server.
*   Testing the dual SSE streams with a UI that can display "reasoning" and "answer" tokens separately.  Start with a basic terminal UI for initial testing.

## 5. Economic Actions and PySUI Integration (Later Phase)

Integration with economic actions and PySUI will be considered in a later phase, after the core MCP and SSE architecture is functional and tested.

## Mermaid Diagram for Plan:

```mermaid
graph LR
    A[User Input] --> ActionServer
    ActionServer -- Reasoning SSE --> PythonAPI
    ActionServer -- Answer SSE --> PythonAPI
    PythonAPI --> ExperienceServer
    ExperienceServer -- Reasoning SSE --> PythonAPI
    ExperienceServer -- Answer SSE --> PythonAPI
    PythonAPI --> IntentionServer
    IntentionServer -- Reasoning SSE --> PythonAPI
    IntentionServer -- Answer SSE --> PythonAPI
    PythonAPI --> ObservationServer
    ObservationServer -- Reasoning SSE --> PythonAPI
    ObservationServer -- Answer SSE --> PythonAPI
    PythonAPI --> UnderstandingServer
    UnderstandingServer -- Reasoning SSE --> PythonAPI
    UnderstandingServer -- Answer SSE --> PythonAPI
    PythonAPI --> YieldServer
    YieldServer -- Reasoning SSE --> PythonAPI
    YieldServer -- Answer SSE --> PythonAPI
    PythonAPI --> B[User Output / Attempt Completion]

    subgraph MCP Servers
    ActionServer
    ExperienceServer
    IntentionServer
    ObservationServer
    UnderstandingServer
    YieldServer
    end

    subgraph Python API
    PythonAPI
    end


    style MCP Servers fill:#f9f,stroke:#333,stroke-width:2px
    style Python API fill:#ccf,stroke:#333,stroke-width:2px
    linkStyle 0,2,4,6,8,10,12,14,16,18 stroke-dasharray: 5 5;

=== File: docs/comp_provider_info.md ===



==
comp_provider_info
==


# LLM Provider Performance Matrix

| Provider  | Model Name                       | Status  | Confidence | Notes                                  |
|-----------|----------------------------------|---------|------------|----------------------------------------|
| **OpenAI**|                                  |         |            |                                        |
|           | gpt-4.5-preview                  | ✅      | 1.0        | Consistent formatting                  |
|           | gpt-4o                           | ✅      | 1.0        | Detailed geographical context          |
|           | gpt-4o-mini                      | ✅      | 1.0        | Concise response                       |
|           | o1                               | ✅      | 1.0        | Minimalist answer                      |
|           | o3-mini                          | ✅      | 1.0        | Direct response                        |
| **Anthropic**|                               |         |            |                                        |
|           | claude-3-7-sonnet-latest         | ✅      | 1.0        | Historical context included            |
|           | claude-3-5-haiku-latest          | ✅      | 1.0        | Comprehensive explanation              |
| **Google**|                                  |         |            |                                        |
|           | gemini-2.0-flash                 | ✅      | 0.99       | Verifiable sources cited               |
|           | gemini-2.0-flash-lite            | ✅      | 1.0        | High confidence assertion              |
|           | gemini-2.0-pro-exp-02-05         | ✅      | 1.0        | Historical perspective                 |
|           | gemini-2.0-flash-thinking-exp-01-21 | ❌  | N/A       | Function calling disabled              |
| **Mistral**|                                 |         |            |                                        |
|           | pixtral-12b-2409                 | ✅      | 0.9        | Conservative confidence                |
|           | codestral-latest                 | ❌      | N/A       | Rate limit exceeded                    |
| **Fireworks**|                               |         |            |                                        |
|           | deepseek-v3                      | ✅      | 1.0        | Multi-source verification              |
|           | qwen2p5-coder-32b-instruct       | ⚠️      | N/A       | Returned null response                 |
| **Cohere**|                                  |         |            |                                        |
|           | command-r7b-12-2024              | ✅      | 1.0        | Official designation emphasized        |

## Matrix Summary
- **Total Models Tested**: 16
- **Success Rate**: 81.25% (13/16)
- **Average Confidence**: 0.98 (successful models only)
- **Perfect Scores**: 9 models at 1.0 confidence
- **Common Failure Modes**:
  - Technical Limitations (37.5%)
  - Rate Limits (25%)
  - Null Responses (12.5%)

*Data preserved from original LangGraph-era tests conducted 2025-03-01*

=== File: docs/documentation_index.md ===



==
documentation_index
==


# Choir Documentation Index

## Core Concepts

These documents describe the fundamental concepts that remain consistent regardless of the underlying implementation:

- [PostChain (AEIOU-Y) Conceptual Model](postchain_actor_model.md) - The core AEIOU-Y Chorus Cycle framework
- [FQAHO Model](fqaho_visualization.md) - The Fractional Quantum Anharmonic Oscillator economic model
- [Core Economics](core_economics.md) - Economic principles and tokenomics
- [Core State Transitions](core_state_transitions.md) - State transition principles
- [Evolution: Naming](evolution_naming.md) - Naming conventions and evolution

## Architecture Documentation

These documents describe the new MCP-based architecture:
- [Stack Argument](stack_argument.md) - Rationale for the MCP-based technology stack
- [Security Considerations](security_considerations.md) - Security architecture and considerations

## Migration Documents

These documents guide the transition from LangGraph to the MCP architecture:

- [Migration Plan](migration_langgraph_to_actor.md) - Step-by-step migration plan
- [Migration Checklist](plan_postchain_migration_checklist.md) - (Needs update for MCP architecture)

## Implementation Guidelines

These documents provide practical guidance for implementation:

- [Actor Development Guidelines](actor_development_guidelines.md) - (To be created)
- [Message Protocol Design](message_protocol_design.md) - (To be created)
- [State Persistence Patterns](state_persistence_patterns.md) - (To be created)

## Integration Documentation

These documents cover integration with external systems:

- [libSQL Integration](plan_libsql.md) - Database integration (to be updated for MCP architecture)
- [Blockchain Integration](blockchain_integration.md) - (To be created)
- [Identity as a Service](plan_identity_as_a_service.md) - Identity management

## Testing and Deployment

These documents cover testing, deployment, and operations:

- [Testing Strategy](testing_strategy.md) - (To be created)
- [Deployment Guide](deployment_guide.md) - (To be created)
- [Monitoring and Observability](monitoring_observability.md) - (To be created)

## Business and Strategy

These documents cover business aspects of Choir:

- [Business Model](e_business.md) - Business model and strategy
- [Evolution Token](evolution_token.md) - Token design and economics

## Archive

These documents are preserved for reference but may be outdated due to the architectural pivot:

- [LangGraph PostChain Plan](plan_langgraph_postchain.md) - Previous LangGraph architecture (archived)
- [LangGraph PostChain Iteration](plan_langgraph_postchain_iteration.md) - Previous iteration plan (archived)
- [PostChain Graph API Checklist](plan_postchain_graph_api_checklist.md) - Previous API plans (archived)
- [Tools Qdrant Checklist](plan_tools_qdrant_checklist.md) - Previous vector DB integration (archived)
- [Actor Model Overview](1-concepts/actor_model_overview.md) - Introduction to the actor model (archived)
- [PostChain Actor Model](docs/postchain_actor_model.md) - Technical implementation of PostChain using actors (archived)
- [Scale-Free Actor Architecture](1-concepts/scale_free_actor_architecture.md) - Fractal patterns in actor systems (archived)
- [Phase Worker Pool Architecture](phase_worker_pool_architecture.md) - Extension of the actor model with worker pools (archived)
- [Migration Plan](migration_langgraph_to_actor.md) - Step-by-step LangGraph to Actor migration plan (archived)


## Development Timeline

The changelog tracks the project's evolution:

- [Changelog](CHANGELOG.md) - Historical development timeline

## Document Creation Schedule

| Document                     | Status  | Priority | Target      | Changes Needed          |
| ---------------------------- | ------- | -------- | ----------- | ----------------------- |
| PostChain Actor Model        | Created | High     | Completed   | Archived                |
| Stack Argument               | Created | High     | Completed   | Update to MCP           |
| Migration Plan               | Updated | High     | Completed   | Update to MCP           |
| Security Considerations      | Updated | High     | Completed   | Add TEE integration     |
| Actor Development Guidelines | Created | High     | In progress | Archived                |
| Message Protocol Design      | Planned | High     |             |                         |
| State Persistence Patterns   | Planned | Medium   |             |                         |
| Testing Strategy             | Planned | Medium   |             |                         |
| Deployment Guide             | Planned | Medium   |             |                         |
| Monitoring and Observability | Planned | Low      |             |                         |
| Blockchain Integration       | Planned | Medium   |             |                         |

## Documentation Principles

1. **Clarity First**: Documentation should be clear and accessible
2. **Code as Documentation**: Provide well-commented code examples
3. **Conceptual Consistency**: Maintain consistent terminology across documents
4. **Visual Explanation**: Use diagrams to illustrate complex concepts
5. **Living Documentation**: Update documentation as the system evolves

## Contribution Guidelines

When contributing to documentation:

1. Maintain consistent formatting
2. Update the index when adding new documents
3. Mark superseded documents as archived
4. Include visual diagrams where appropriate
5. Provide code examples for technical concepts

=== File: docs/index.md ===



==
index
==


# Choir Documentation

## Core Concepts

The Choir platform is built around a sophisticated conceptual model implemented through an MCP-based architecture:
- [PostChain Temporal Logic](1-concepts/postchain_temporal_logic.md) - The temporal essence of each AEIOU-Y phase

## Architecture

Technical architecture and design decisions:

- [Architecture Transition Narrative](2-architecture/architecture_transition_narrative.md) - The story of our architectural evolution
- [Stack Argument](stack_argument.md) - Rationale for our technology choices

## Implementation

Practical guidance for implementation:

- [Developer Quickstart](3-implementation/developer_quickstart.md) - Fast onboarding guide
- [Message Protocol Reference](3-implementation/message_protocol_reference.md) - Comprehensive message format documentation
- [State Management Patterns](3-implementation/state_management_patterns.md) - Best practices for state

## MCP-Based Context Management

Choir's MCP architecture enables sophisticated context management through specialized phase responsibilities:

| Phase         | Temporal Focus       | Context Responsibility               |
| ------------- | -------------------- | ------------------------------------ |
| Action        | Immediate present    | Initial framing and response         |
| Experience    | Past knowledge       | Adding search results and knowledge  |
| Intention     | Desired future       | Focusing on user goals               |
| Observation   | Future preservation  | Tagging and connecting concepts      |
| Understanding | Temporal integration | Deciding what information to release |
| Yield         | Process completion   | Determining cycle continuation       |

## Documentation Roadmap

- **Current Phase**: Architecture refinement and documentation alignment
- **Next Steps**: Implementation guidance and testing framework
- **Open Questions**: Advanced context management strategies and model integration

Explore the documentation sections above to understand how Choir implements an MCP-based architecture to support the PostChain model of AI orchestration.

## Documentation Structure

The documentation is organized into the following sections:

## 1. Core Concepts

Fundamental concepts that remain consistent regardless of the implementation:
- [PostChain (AEIOU-Y) Conceptual Model](postchain_actor_model.md) - The core AEIOU-Y framework
- [FQAHO Model](fqaho_visualization.md) - The Fractional Quantum Anharmonic Oscillator economic model
- [Core Economics](core_economics.md) - Economic principles and tokenomics
- [Core State Transitions](core_state_transitions.md) - State transition principles
- [Evolution: Naming](evolution_naming.md) - Naming conventions and evolution

## 2. Architecture

Detailed information about the MCP-based architecture:
- [Stack Argument](stack_argument.md) - Rationale for the MCP-based technology stack
- [Security Considerations](security_considerations.md) - Security architecture and considerations

## 3. Implementation

Practical guidance for implementing the MCP-based architecture:
- [Developer Quickstart](3-implementation/developer_quickstart.md) - Fast onboarding for new developers
- [Migration Plan](migration_langgraph_to_actor.md) - Step-by-step migration from LangGraph to MCP
- [Message Protocol Reference](message_protocol_reference.md) - Documentation of message formats
- [State Management Patterns](3-implementation/state_management_patterns.md) - Best practices for state management

## 4. Integration

Information about integrating with external systems:

- [libSQL Integration](plan_libsql.md) - Database integration
- [Blockchain Integration](blockchain_integration.md) - Integration with Sui blockchain
- [Identity as a Service](plan_identity_as_a_service.md) - Identity management

## 5. Operations

Documentation for deployment, testing, and operations:

- [Deployment Guide](deployment_guide.md) - Instructions for deploying the MCP-based system
- [Testing Strategy](testing_strategy.md) - Approach to testing MCP-based systems
- [Monitoring and Observability](monitoring_observability.md) - Monitoring the MCP system

## 6. Business and Strategy

Business aspects of Choir:

- [Business Model](e_business.md) - Business model and strategy
- [Evolution Token](evolution_token.md) - Token design and economics
- [Anonymity by Default](plan_anonymity_by_default.md) - Privacy principles

## Archive

Documents preserved for reference but potentially outdated due to the architectural pivot:

- [LangGraph-specific documentation](archive/) - Previous architecture documents

## Development Timeline

- [Changelog](CHANGELOG.md) - Historical development timeline
- [Architecture Reorganization Plan](archive/architecture_reorganization_plan.md) - Plan for documentation updates

## Contributing to Documentation

See the [Architecture Reorganization Plan](archive/architecture_reorganization_plan.md) for information on the documentation structure and contribution guidelines.

When contributing to documentation:

1. Follow the established folder structure
2. Use Markdown for all documentation
3. Include diagrams using Mermaid.js where appropriate
4. Provide code examples for technical concepts
5. Update the index when adding new documents

=== File: docs/phase_worker_pool_architecture.md ===



==
phase_worker_pool_architecture
==


# Phase Worker Pool Architecture

## Overview

This document describes an extension to the actor-based PostChain architecture, introducing the concepts of Phase Types and Worker Pools. This pattern significantly enhances the flexibility, scalability, and extensibility of the system while maintaining the conceptual clarity of the AEIOU-Y PostChain.

## Core Concepts

### Phase Types vs. Actor Instances

In the extended architecture:

- Each phase of the PostChain (Action, Experience, Intention, Observation, Understanding, Yield) is a **Phase Type**
- Each Phase Type can have multiple specialized **Actor Implementations**
- Actor Implementations are selected based on input modality, domain, or task requirements

### Worker Pool Pattern

The Worker Pool pattern abstracts underlying AI models and resources:

- **Workers**: Represent specific LLM configurations, specialized models, or processing units
- **Worker Pools**: Groups of interchangeable workers that can process similar tasks
- **Dispatchers**: Components that assign tasks to appropriate workers based on capabilities

## Architecture Diagram

```
┌────────────────────────────────────────────────────────────────────────┐
│                      PostChain Coordinator                             │
└───────────────────────────────┬────────────────────────────────────────┘
                                │
                                ▼
┌────────────────────────────────────────────────────────────────────────┐
│                          Phase Types                                   │
│                                                                        │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐                          │
│  │ Action   │    │Experience│    │Intention │                          │
│  │ Type     │───▶│  Type    │───▶│  Type    │───┐                      │
│  └──────────┘    └──────────┘    └──────────┘   │                      │
│       ▲                                          │                      │
│       │                                          ▼                      │
│       │                                          │                      │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐   │                      │
│  │  Yield   │◀───│Understand│◀───│Observe   │◀──┘                      │
│  │  Type    │    │  Type    │    │  Type    │                          │
│  └──────────┘    └──────────┘    └──────────┘                          │
│                                                                        │
└───────┬─────┬────────┬──────────────┬───────────┬─────┬────────────────┘
        │     │        │              │           │     │
        ▼     ▼        ▼              ▼           ▼     ▼
┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐
│Audio     │ │Vision    │ │Text      │ │Multimodal│ │Code      │ │Model     │
│Actors    │ │Actors    │ │Actors    │ │Actors    │ │Actors    │ │Actors    │
└──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘ └──────────┘
       │            │            │            │           │            │
       └────────────┴────────────┴──────┬─────┴───────────┴────────────┘
                                        │
                                        ▼
┌────────────────────────────────────────────────────────────────────────┐
│                         Worker Pool Manager                            │
└─────────────────┬──────────────────────────────────────┬───────────────┘
                  │                                      │
         ┌────────▼─────────┐                  ┌─────────▼────────┐
         │  Model Worker    │                  │ Processing Worker │
         │  Pools           │                  │ Pools             │
         └──────────────────┘                  └──────────────────┘
         ┌────────────────────────────────────────────────────────┐
         │ • GPT-4 Workers  • LLaMA Workers   • Mixtral Workers   │
         │ • Claude Workers • Falcon Workers  • Embedder Workers  │
         │ • Gemini Workers • Vision Workers  • Audio Workers     │
         │ • Custom Workers • Code Workers    • Local Workers     │
         └────────────────────────────────────────────────────────┘
```

## Implementation Components

### 1. Phase Type Registry

```python
class PhaseType(Enum):
    ACTION = "action"
    EXPERIENCE = "experience"
    INTENTION = "intention"
    OBSERVATION = "observation"
    UNDERSTANDING = "understanding"
    YIELD = "yield"

class PhaseTypeRegistry:
    def __init__(self):
        self.registry = {phase_type: {} for phase_type in PhaseType}

    def register_actor(self, phase_type: PhaseType, modality: str, actor_class: Type[Actor]):
        """Register an actor implementation for a specific phase type and modality"""
        if phase_type not in self.registry:
            self.registry[phase_type] = {}

        self.registry[phase_type][modality] = actor_class

    def get_actor_class(self, phase_type: PhaseType, modality: str) -> Type[Actor]:
        """Get the appropriate actor implementation for a phase type and modality"""
        if phase_type not in self.registry or modality not in self.registry[phase_type]:
            # Fall back to default implementation if specific one not found
            modality = "default"

        return self.registry[phase_type].get(modality)
```

### 2. Worker Pool Manager

```python
class Worker:
    """Base class for workers that process tasks"""
    def __init__(self, worker_id: str, capabilities: List[str]):
        self.worker_id = worker_id
        self.capabilities = capabilities
        self.busy = False

    async def process(self, task: Any) -> Any:
        """Process a task and return the result"""
        # Implementation depends on worker type
        pass

class ModelWorker(Worker):
    """Worker that wraps an AI model"""
    def __init__(self, worker_id: str, model_name: str, capabilities: List[str]):
        super().__init__(worker_id, capabilities)
        self.model_name = model_name
        # Initialize model client

    async def process(self, task: Any) -> Any:
        """Process a task using the AI model"""
        # Call the underlying model
        return result

class WorkerPool:
    """Pool of workers with similar capabilities"""
    def __init__(self, pool_id: str, worker_type: Type[Worker]):
        self.pool_id = pool_id
        self.worker_type = worker_type
        self.workers: List[Worker] = []

    def add_worker(self, worker: Worker):
        """Add a worker to the pool"""
        if isinstance(worker, self.worker_type):
            self.workers.append(worker)

    async def get_available_worker(self) -> Optional[Worker]:
        """Get an available worker from the pool"""
        for worker in self.workers:
            if not worker.busy:
                return worker
        return None

    async def process_task(self, task: Any) -> Any:
        """Process a task using an available worker"""
        worker = await self.get_available_worker()
        if not worker:
            raise NoAvailableWorkerError(f"No available workers in pool {self.pool_id}")

        worker.busy = True
        try:
            result = await worker.process(task)
            return result
        finally:
            worker.busy = False

class WorkerPoolManager:
    """Manages multiple worker pools"""
    def __init__(self):
        self.pools: Dict[str, WorkerPool] = {}

    def register_pool(self, pool: WorkerPool):
        """Register a worker pool"""
        self.pools[pool.pool_id] = pool

    def get_pool(self, pool_id: str) -> Optional[WorkerPool]:
        """Get a worker pool by ID"""
        return self.pools.get(pool_id)

    async def process_task(self, pool_id: str, task: Any) -> Any:
        """Process a task using a specific worker pool"""
        pool = self.get_pool(pool_id)
        if not pool:
            raise PoolNotFoundError(f"Worker pool {pool_id} not found")

        return await pool.process_task(task)
```

### 3. Modality-Specific Actors

```python
class TextActionActor(Actor[ActionState]):
    """Actor implementation for text-based Action phase"""
    async def process(self, message: Message) -> Any:
        # Text-specific processing
        pass

class AudioActionActor(Actor[AudioActionState]):
    """Actor implementation for audio-based Action phase"""
    async def process(self, message: Message) -> Any:
        # Audio-specific processing
        pass

class VideoActionActor(Actor[VideoActionState]):
    """Actor implementation for video-based Action phase"""
    async def process(self, message: Message) -> Any:
        # Video-specific processing
        pass

class CodeActionActor(Actor[CodeActionState]):
    """Actor implementation for code-based Action phase"""
    async def process(self, message: Message) -> Any:
        # Code-specific processing
        pass
```

### 4. Dynamic Actor Factory

```python
class ActorFactory:
    """Factory for creating appropriate actor instances"""
    def __init__(self, registry: PhaseTypeRegistry, worker_pool_manager: WorkerPoolManager):
        self.registry = registry
        self.worker_pool_manager = worker_pool_manager

    async def create_actor(self, phase_type: PhaseType, modality: str, **kwargs) -> Actor:
        """Create an actor instance for the specified phase type and modality"""
        actor_class = self.registry.get_actor_class(phase_type, modality)
        if not actor_class:
            raise ActorNotFoundError(f"No actor found for {phase_type.value} and {modality}")

        # Create actor with appropriate worker pool
        pool_id = f"{modality}_{phase_type.value}_pool"
        pool = self.worker_pool_manager.get_pool(pool_id)

        # Create actor instance with configured worker pool
        actor = actor_class(worker_pool=pool, **kwargs)
        return actor
```

## Processing Flows

### Input Modality Detection

```python
class ModalityDetector:
    """Detects the modality of input data"""

    async def detect_modality(self, input_data: Any) -> str:
        """Determine the modality of the input data"""
        if isinstance(input_data, str):
            return "text"
        elif self._is_audio(input_data):
            return "audio"
        elif self._is_video(input_data):
            return "video"
        elif self._is_code(input_data):
            return "code"
        elif self._is_model(input_data):
            return "model"
        else:
            return "multimodal"
```

### PostChain Orchestration

```python
class PostChain:
    """Orchestrates the flow through the phase types"""

    def __init__(self,
                 factory: ActorFactory,
                 modality_detector: ModalityDetector):
        self.factory = factory
        self.modality_detector = modality_detector

    async def process(self, input_data: Any) -> Any:
        """Process input through the entire PostChain"""

        # Detect input modality
        modality = await self.modality_detector.detect_modality(input_data)

        # Create phase actors for this modality
        action_actor = await self.factory.create_actor(PhaseType.ACTION, modality)
        experience_actor = await self.factory.create_actor(PhaseType.EXPERIENCE, modality)
        intention_actor = await self.factory.create_actor(PhaseType.INTENTION, modality)
        observation_actor = await self.factory.create_actor(PhaseType.OBSERVATION, modality)
        understanding_actor = await self.factory.create_actor(PhaseType.UNDERSTANDING, modality)
        yield_actor = await self.factory.create_actor(PhaseType.YIELD, modality)

        # Initialize correlation ID
        correlation_id = f"{modality}-{uuid.uuid4()}"

        # Process through the chain
        action_result = await action_actor.process(Message(
            type=MessageType.REQUEST,
            sender="system",
            recipient=action_actor.name,
            content=input_data,
            correlation_id=correlation_id
        ))

        # Continue through other phases...

        return result
```

## Use Cases and Examples

### Multi-Modal Processing

The architecture supports unified processing across modalities:

```python
# Register different actor implementations
registry = PhaseTypeRegistry()
registry.register_actor(PhaseType.ACTION, "text", TextActionActor)
registry.register_actor(PhaseType.ACTION, "audio", AudioActionActor)
registry.register_actor(PhaseType.ACTION, "video", VideoActionActor)
registry.register_actor(PhaseType.ACTION, "code", CodeActionActor)
```

### Model-As-Input

The architecture can handle AI models themselves as inputs:

```python
class ModelActionActor(Actor[ModelActionState]):
    """Process an AI model as input"""

    async def process(self, message: Message) -> Any:
        # Extract model from input
        model = message.content

        # Analyze model architecture, weights, or behavior
        model_analysis = await self.analyze_model(model)

        # Generate insights about the model
        return model_analysis
```

### Specialized Domain Actors

The architecture supports domain-specific processing:

```python
registry.register_actor(PhaseType.EXPERIENCE, "medical", MedicalExperienceActor)
registry.register_actor(PhaseType.EXPERIENCE, "legal", LegalExperienceActor)
registry.register_actor(PhaseType.EXPERIENCE, "financial", FinancialExperienceActor)
```

## Benefits of the Architecture

### Flexibility

- Process various input types through the same conceptual workflow
- Add new modalities without changing the core architecture
- Specialize actors for different domains or tasks

### Scalability

- Scale worker pools independently based on demand
- Add specialized workers for performance-critical tasks
- Balance load across multiple workers

### Performance

- Select optimal model configurations for specific tasks
- Process multiple phases concurrently where appropriate
- Utilize hardware acceleration for specific modalities

### Extensibility

- Add new worker types without modifying existing code
- Implement new modality handlers as needed
- Create specialized actor implementations for emerging use cases

## Implementation Considerations

### Worker Pool Scaling

- Implement auto-scaling based on demand patterns
- Monitor worker utilization and performance
- Create worker lifecycle management policies

### Worker Specialization

- Design model-specific prompts for each worker type
- Optimize context handling for different modalities
- Create specialized pre/post-processing for different input types

### State Management

- Design state objects specific to each modality
- Implement efficient serialization for different data types
- Create modality-specific persistence strategies

## Next Steps

1. Implement core PhaseType registry and WorkerPool manager
2. Create basic actor implementations for text modality
3. Extend to audio and video modalities
4. Implement specialized domain actors
5. Create comprehensive test suite for multi-modal scenarios
6. Benchmark performance across different worker configurations

## Conclusion

The Phase Worker Pool architecture extends the actor model to handle diverse input modalities and specialized processing requirements while maintaining the conceptual clarity of the PostChain. By abstracting AI models as workers and implementing modality-specific actors, the system can adapt to new input types, specialized domains, and evolving AI capabilities without requiring a redesign of the core architecture.

=== File: docs/postchain_actor_model.md ===



==
postchain_actor_model
==


# PostChain Actor Model Implementation

## Overview

The Choir PostChain (AEIOU-Y) is implemented using the actor model, where each phase of the PostChain is represented by a specialized actor with encapsulated state. This document details the technical architecture, message flow, state management, and implementation patterns.

## Core Architecture

```
┌─────────────────────────────────────────────────────┐
│                                                     │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐          │
│  │ Action  │    │Experience│    │Intention│          │
│  │ Actor   │───▶│  Actor  │───▶│  Actor  │───┐      │
│  └─────────┘    └─────────┘    └─────────┘   │      │
│       ▲                                       │      │
│       │                                       ▼      │
│       │           POST CHAIN                  │      │
│       │                                       │      │
│  ┌─────────┐    ┌─────────┐    ┌─────────┐   │      │
│  │  Yield  │◀───│Understand│◀───│Observe  │◀──┘      │
│  │  Actor  │    │  Actor   │    │ Actor   │          │
│  └─────────┘    └─────────┘    └─────────┘          │
│                                                     │
└─────────────────────────────────────────────────────┘
         │                       ▲
         │   ┌───────────────┐   │
         └──▶│  libsql/turso │───┘
             │  (SQL + RAG)  │
             └───────────────┘
```

## Actor Definitions

### Base Classes

```python
class ActorState(BaseModel):
    """Base class for actor-specific state"""
    pass

class Actor(Generic[T]):
    """Base Actor implementation following the actor model pattern"""

    def __init__(self, name: str, initial_state: Optional[T] = None):
        self.name = name
        self.state = initial_state
        self.mailbox: asyncio.Queue[Message] = asyncio.Queue()
        self.handlers: Dict[MessageType, Callable] = {}
```

### PostChain Actor States

Each actor in the PostChain maintains its own specialized state:

```python
class ActionState(ActorState):
    """State for the Action actor"""
    messages: List[Dict[str, Any]] = Field(default_factory=list)
    current_input: Optional[str] = None

class ExperienceState(ActorState):
    """State for the Experience actor"""
    knowledge_base: List[Dict[str, Any]] = Field(default_factory=list)
    retrieved_context: List[Dict[str, Any]] = Field(default_factory=list)

class IntentionState(ActorState):
    """State for the Intention actor"""
    user_intents: List[str] = Field(default_factory=list)
    current_intent: Optional[str] = None

class ObservationState(ActorState):
    """State for the Observation actor"""
    semantic_connections: List[Dict[str, Any]] = Field(default_factory=list)
    observations: List[str] = Field(default_factory=list)

class UnderstandingState(ActorState):
    """State for the Understanding actor"""
    decisions: List[Dict[str, Any]] = Field(default_factory=list)
    continue_chain: bool = True

class YieldState(ActorState):
    """State for the Yield actor"""
    final_responses: List[Dict[str, Any]] = Field(default_factory=list)
    current_response: Optional[str] = None
```

## Message Protocol

Actors communicate via strongly-typed messages:

```python
class MessageType(Enum):
    REQUEST = auto()
    RESPONSE = auto()
    ERROR = auto()
    EVENT = auto()

class Message(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    type: MessageType
    sender: str
    recipient: str
    created_at: datetime = Field(default_factory=datetime.now)
    content: Any
    correlation_id: Optional[str] = None  # For tracking request/response chains
```

## Actor Implementation

Each phase of the PostChain is implemented as a specialized actor:

### Action Actor

```python
class ActionActor(Actor[ActionState]):
    """Handles the Action phase - initial response to user input"""

    def __init__(self, experience_actor: Optional['ExperienceActor'] = None):
        super().__init__("action", ActionState())
        self.register_handler(MessageType.REQUEST, self.handle_request)
        self.experience_actor = experience_actor

    async def handle_request(self, message: Message) -> Any:
        """Process a user input and generate initial response"""
        user_input = message.content

        # Update state
        if self.state:
            self.state.current_input = user_input
            self.state.messages.append({"role": "user", "content": user_input})

        # In a real implementation, this would call an LLM to process the input
        initial_response = f"Initial processing of: {user_input}"

        # Pass to Experience actor if available
        if self.experience_actor and message.correlation_id:
            await self.send(
                self.experience_actor,
                MessageType.REQUEST,
                {
                    "user_input": user_input,
                    "initial_response": initial_response
                },
                correlation_id=message.correlation_id
            )

        return initial_response
```

Similar patterns apply to other actors in the chain (Experience, Intention, Observation, Understanding, Yield).

## State Management

Each actor manages its own state, which solves several key problems:

1. **Context Window Management**: Each actor can apply its own strategy for state compression and relevance determination
2. **Memory Specialization**: Actors keep state relevant to their specific responsibility
3. **Fault Isolation**: State corruption in one actor doesn't affect others
4. **Persistence Flexibility**: Each actor's state can be persisted independently

### State Persistence

Actor states are persisted to libSQL/Turso:

```python
async def save_state(self, actor_name: str, state: ActorState):
    """Save actor state to the database"""
    if not self.db:
        await self.connect()

    # Convert state to JSON
    state_json = state.model_dump_json()

    # Save to database
    await self.db.execute(
        "INSERT INTO actor_state (actor_name, state_json) VALUES (?, ?)",
        (actor_name, state_json)
    )
    await self.db.commit()

async def load_state(self, actor_name: str, state_type: Type[ActorState]) -> Optional[ActorState]:
    """Load actor state from the database"""
    if not self.db:
        await self.connect()

    # Get the latest state for this actor
    cursor = await self.db.execute(
        "SELECT state_json FROM actor_state WHERE actor_name = ? ORDER BY created_at DESC LIMIT 1",
        (actor_name,)
    )
    row = await cursor.fetchone()

    if not row:
        return None

    # Convert JSON back to state object
    state_json = row[0]
    return state_type.model_validate_json(state_json)
```

## Message Flow Control

The PostChain manages the flow of messages through the actor system:

```python
async def process_input(self, user_input: str) -> str:
    """Process user input through the full Post Chain"""
    # Generate correlation ID for tracking this request through the chain
    correlation_id = f"req-{user_input[:10]}-{asyncio.get_event_loop().time()}"

    # Start the chain at the Action actor
    await self.system.send_message(
        "system",
        self.action_actor.name,
        MessageType.REQUEST,
        user_input,
        correlation_id=correlation_id
    )

    # Wait for processing to complete through the chain
    # This would use a future/promise pattern in production
    result = await self.wait_for_completion(correlation_id)

    return result
```

## Knowledge Integration (RAG)

The Experience actor integrates with RAG capabilities via libSQL/Turso:

```python
async def perform_rag_query(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
    """Perform a RAG query against the stored data"""
    # Generate embedding for the query
    query_embedding = await self.embedding_model.embed_text(query)

    # In a real implementation, libSQL would have vector search capabilities
    # Return relevant documents based on embedding similarity
    return results
```

## Blockchain Integration

The citation mechanism integrates with the Sui blockchain via PySUI:

```python
async def record_citation(self, cited_message_id: str, citing_message_id: str, citation_value: float):
    """Record a citation on the blockchain and trigger token transfer"""
    # Create a transaction on Sui
    tx = await self.sui_client.create_citation_transaction(
        cited_message_id,
        citing_message_id,
        citation_value
    )

    # Execute the transaction
    result = await self.sui_client.execute_transaction(tx)

    return result
```

## Security Model

The actor model provides natural security boundaries:

1. **Message Validation**: All inter-actor messages are validated by Pydantic
2. **Isolated State**: Actors cannot directly access each other's state
3. **Explicit Communication**: All interactions happen through well-defined message channels
4. **Controlled Access**: Actors only have access to resources explicitly provided to them

## Deployment Architecture

The entire system is containerized using Docker:

```dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["uvicorn", "api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## Future Extensions

The actor model enables several powerful extensions:

1. **Dynamic Actor Creation**: Specialized actors can be created on demand
2. **Actor Hierarchies**: Supervisory patterns can manage actor lifecycles
3. **Distributed Deployment**: Actors can be distributed across multiple hosts
4. **Actor Specialization**: New actor types can be added for specific capabilities
5. **Rust Migration**: Performance-critical actors can be reimplemented in Rust


## Actor Specialization
```python
class VideoActionActor(Actor[VideoActionState]):
    async def process(self, message: Message) -> Any:
        # Video-specific preprocessing
        video_analysis = await self.video_worker.process(message.content)
        return await self.experience_actor.process(
            Message(content=video_analysis)
        )

class FinancialExperienceActor(Actor[ExperienceState]):
    async def retrieve_context(self, query: str):
        # Specialized financial context retrieval
        return await self.financial_rag(query)
```

## Conclusion

The actor-based PostChain implementation provides a natural fit for agent-based AI systems, with clean separation of concerns, robust message passing, and flexible state management. This architecture resolves the fundamental challenges of state management in conversational AI, providing a foundation for scalable, resilient multi-agent systems.

=== File: docs/security_considerations.md ===



==
security_considerations
==


# Security Considerations for Actor-Based PostChain

## Introduction

This document outlines the security considerations for Choir's actor-based PostChain architecture, with a particular focus on the integration with Phala Network's Trusted Execution Environment (TEE) for secure blockchain operations.

## Threat Model

The system addresses several categories of potential threats:

1. **Blockchain Key Compromise**: Theft or unauthorized use of private keys used for Sui blockchain operations
2. **Contract Manipulation**: Unauthorized modification of contract parameters or execution
3. **Token Theft**: Unauthorized transfer or access to CHIP tokens
4. **Data Exfiltration**: Unauthorized access to or extraction of sensitive user data
5. **System Manipulation**: Unauthorized alterations to system behavior or state
6. **Model Attacks**: Prompt injection, jailbreaking, or other attacks on underlying AI models
7. **Resource Exhaustion**: Denial of service through excessive resource consumption
8. **Identity Spoofing**: Impersonation of legitimate users or system components
9. **Infrastructure Compromise**: Attacks on the underlying infrastructure components

## Secure Blockchain Operations using TEEs

### Core Blockchain Security Goals

The primary security goal of the system is to enable secure blockchain operations:

1. **Secure Key Management**: Store and manage private keys for Sui blockchain operations within TEEs
2. **Protected Contract Execution**: Execute Sui smart contracts in a secure, isolated environment
3. **Tamper-Proof Token Management**: Handle CHIP token distribution and management in a way that prevents unauthorized manipulation
4. **Transaction Integrity**: Ensure that all blockchain transactions are properly authorized and accurately executed

### TEE-Based Security Architecture

The system leverages Phala Network's TEEs to create a secure enclave for all blockchain operations:

1. **Private Key Isolation**: Blockchain private keys never leave the TEE, eliminating the risk of key exposure on traditional servers
2. **Secure Execution Environment**: All blockchain-related code execution occurs within the TEE
3. **Attestation and Verification**: TEE state can be cryptographically verified to ensure it hasn't been tampered with
4. **End-to-End Protection**: The entire pipeline from transaction creation to blockchain submission is protected within the TEE

### Advantages Over Traditional Approaches

This approach offers significant advantages over traditional server-based key management:

1. **Elimination of Server-Side Key Storage**: No need to store sensitive private keys on conventional servers
2. **Hardware-Level Protection**: Cryptographic operations protected by hardware security features
3. **Reduced Attack Surface**: Significant reduction in potential attack vectors compared to traditional key management
4. **Decentralized Security Model**: Leverages blockchain and TEE infrastructure rather than centralized security measures

## Actor Model Security Benefits

The actor model provides several security benefits that complement the TEE-based blockchain security:

1. **Isolation and Containment**: Each actor operates independently, limiting the potential impact of any security breach
2. **Message Validation**: All inter-actor communication is validated and type-checked using Pydantic
3. **Explicit Access Control**: Actors only have access to their own state and must request information through well-defined interfaces
4. **Component Separation**: Clear separation between blockchain operations and other system functionality

## Phala Network Security Integration

Phala Network provides a privacy-preserving computing cloud with TEEs that ensures:

1. **Confidential Computing**: Code execution is hidden from the node operators
2. **Isolated Execution**: The execution environment is isolated from the host system
3. **Remote Attestation**: The execution environment can be verified by remote parties
4. **Blockchain Security**: The state and results are secured by the underlying blockchain
5. **Key Protection**: Cryptographic keys are protected within the TEE, even from the infrastructure operator

### Secure Key Management Architecture

The system's key management architecture is designed to maximize security:

1. **TEE-Only Keys**: Private keys for Sui blockchain operations are generated and stored exclusively within the TEE
2. **No Key Export**: Keys never leave the secure TEE environment
3. **Key Usage Monitoring**: All key usage is logged and can be audited
4. **Key Rotation Policies**: Regular key rotation policies to limit exposure in case of compromise
5. **Threshold Signatures**: Support for multi-signature operations for high-value transactions

### Secure Contract Execution

The system ensures secure execution of Sui contracts:

1. **Isolated Execution**: Contract execution code runs entirely within the TEE
2. **Parameter Validation**: All contract parameters are validated before execution
3. **Transaction Review**: High-value or sensitive transactions undergo additional validation
4. **Deterministic Execution**: Contract execution is deterministic and auditable

## Data Security Measures

Beyond blockchain operations, the system also protects various types of data:

1. **Data Classification**:

   - **Critical**: Blockchain private keys, user authentication credentials
   - **Sensitive**: User personal information, citation records
   - **Internal**: System state, operational metrics
   - **Public**: Published content, public blockchain data

2. **Encryption Architecture**:
   - End-to-end encryption for sensitive communications
   - At-rest encryption for stored data
   - Key management through TEE-secured infrastructure

## Docker Container Security

1. **Minimal Images**: Using minimal base images to reduce attack surface
2. **No Privileged Containers**: Avoiding privileged containers and limiting capabilities
3. **Immutable Infrastructure**: Treating containers as immutable and deploying fresh containers rather than updating
4. **Vulnerability Scanning**: Regular scanning of container images for vulnerabilities
5. **Secret Management**: Using secure methods for managing secrets in containers

## libSQL/Turso Security

1. **Connection Security**: Encrypted connections to the database
2. **Authentication**: Strong authentication mechanisms
3. **Query Parameterization**: Preventing SQL injection through parameterized queries
4. **Data Encryption**: Encrypting sensitive data before storage
5. **Access Controls**: Fine-grained access controls for database operations

## Model Security

1. **Input Validation**: Validating inputs before passing to models
2. **Output Filtering**: Filtering outputs to prevent data leakage
3. **Prompt Security**: Designing secure prompts to prevent injection attacks
4. **Rate Limiting**: Limiting model calls to prevent abuse
5. **Model Isolation**: Isolating model execution to limit the impact of attacks

## Sui Blockchain Security

1. **Transaction Monitoring**: Monitoring transactions for unusual patterns
2. **Contract Auditing**: Regular auditing of smart contracts
3. **Governance Mechanisms**: Implementing governance for critical operations
4. **Recovery Procedures**: Establishing procedures for recovery from security incidents
5. **Compliance**: Ensuring compliance with relevant regulations

## Security Monitoring and Response

1. **Monitoring Metrics**:

   - Authentication attempts and failures
   - API call patterns
   - Resource usage patterns
   - Blockchain transaction patterns
   - Model usage patterns

2. **Anomaly Detection**:

   - Statistical anomaly detection
   - Pattern-based detection
   - Heuristic analysis
   - Machine learning-based detection

3. **Incident Response**:
   - Defined incident response procedures
   - Escalation paths
   - Containment strategies
   - Recovery procedures
   - Post-incident analysis

## Future Security Enhancements

1. **Formal Verification**: Applying formal verification to critical components
2. **Quantum-Resistant Cryptography**: Planning for post-quantum cryptographic algorithms
3. **Enhanced Attestation**: Improving TEE attestation mechanisms
4. **Federated Security**: Implementing federated security across multiple TEEs
5. **Advanced Threat Detection**: Implementing more sophisticated threat detection

## Conclusion

The security architecture of the actor-based PostChain with Phala Network integration provides a robust foundation for secure blockchain operations and data protection. By placing blockchain private keys and contract execution within TEEs rather than on traditional servers, the system achieves a significant security advantage. This approach aligns with the principle of minimizing trust requirements and providing hardware-level security guarantees for the most sensitive operations.

The security measures will continue to evolve as threats evolve, with a focus on proactive security and continuous improvement.

=== File: docs/stack_argument.md ===



==
stack_argument
==


# The Choir Stack Argument: MCP Architecture

## Executive Summary

The Choir PostChain is built on a coherent technology stack designed specifically for efficient, secure multi-agent AI systems. Our architecture pivots from graph-based to MCP-based models, providing superior service encapsulation, clear tool boundaries and enhanced scalability. This document outlines the rationale, benefits, and security implications of our technology choices in the context of MCP.

## The MCP Architecture Advantage

After extensive experimentation with LangGraph, we've determined that the MCP architecture provides the optimal foundation for Choir's multi-agent AI system. This is not merely a technical preference—it's a fundamental alignment with the nature of service-oriented, distributed systems.

### Why MCP over Graphs?

The MCP architecture proved superior for our needs due to:

1.  **Service Boundaries** - Each phase is a separate, encapsulated service
2.  **Tool Control** - Explicitly defined and limited tool access for each phase
3.  **Fault Isolation** - Server crashes in one phase do not destabilize others
4.  **Deployment Flexibility** - Phases can be deployed and scaled independently
5.  **Resource Management** - Each server manages its own resources efficiently

### Performance Characteristics

| Aspect           | LangGraph         | MCP Architecture       |
| ---------------- | ----------------- | ----------------- |
| Memory Usage     | 2-4GB per session | 500MB-1GB per server         |
| Error Recovery   | Full restart      | Per-server restart |
| Scaling          | Vertical          | Horizontal        |
| Modality Support | Single            | Multiple          |
| Tool Control     | Implicit          | Explicit          |

### The AEIOU-Y PostChain as MCP Servers

The PostChain concept (Action, Experience, Intention, Observation, Understanding, Yield) maps perfectly to specialized MCP servers:

- **Action Server**: Processes initial user input and generates preliminary responses
- **Experience Server**: Enriches context with historical knowledge and RAG retrievals
- **Intention Server**: Aligns responses with identified user intents
- **Observation Server**: Records semantic patterns and connections between interactions
- **Understanding Server**: Makes decisions about processing flow and continuation
- **Yield Server**: Produces final, polished responses to users

## The Coherent Stack

Our technology choices form a carefully considered, synergistic stack that maximizes developer productivity while ensuring security, scalability, and performance for an MCP-based architecture.

### MCP: Core Framework

**Why MCP?** Model Context Protocol (MCP) provides a standardized framework for building modular, interoperable AI services. MCP enables:

- Clear separation of concerns between phases as independent servers
- Standardized communication protocol for inter-service communication
- Tool and resource management for each phase
- Flexible deployment and scaling options

### libSQL/Turso: Combined SQL+Vector Database

**Why libSQL/Turso?** MCP servers may need both structured storage (SQL) and vector capabilities (embeddings) to manage state and knowledge. libSQL provides:

- Persistent storage for MCP server states
- Vector similarity search for knowledge retrieval within phases
- Compact deployment footprint for each server
- Local persistence with optional cloud sync via Turso

### PySUI: Blockchain Integration

**Why Sui Blockchain?** Integration with blockchain for citation rewards and economic mechanisms remains a core requirement. Sui offers:

- High throughput for on-chain transactions
- Move-based smart contracts for economic logic
- Economic infrastructure for CHIP tokens
- Secure and transparent reward distribution

### Pydantic: Type Safety

**Why Pydantic?** Message passing between MCP servers and the Python API requires well-structured, validated data. Pydantic provides:

- Runtime type validation for data integrity
- Self-documenting data models
- Integration with FastAPI for API validation
- Performance and ease of use in Python

### FastAPI/Uvicorn: API Layer

**Why FastAPI?** For external communication and orchestration, we need a high-performance async API layer:

- Async-first design for efficient handling of MCP server requests
- Automatic OpenAPI documentation for API discoverability
- Pydantic integration for request/response validation
- Excellent performance and scalability

### Docker: Containerization

**Why Docker?** For deployment flexibility and isolation of MCP servers, we use containerization:

- Consistent environments for each MCP server across development and production
- Simplified deployment and management of multiple servers
- Efficient resource utilization through container isolation
- Enables horizontal scaling of individual MCP servers

### Phala Network: Secure Computation

**Why Phala?** Security and confidentiality are paramount for AI systems. Phala Network provides:

- Confidential computing environment for MCP servers
- TEE (Trusted Execution Environment) protection for secure execution
- Blockchain-based trust and attestation guarantees
- Protection against data breaches and unauthorized access

## Security Considerations of MCP Architecture

In the age of advancing AI capabilities, security must be foundational. Our MCP-based stack enhances security through:

### MCP-Based Security

The MCP architecture inherently improves security by:

- Enforcing clear boundaries and isolation between phases as separate servers
- Providing explicit control over tools and resources available to each phase
- Limiting the potential impact of vulnerabilities to individual servers
- Simplifying security auditing and policy enforcement for each phase

### Blockchain Security

Integration with Sui and deployment on Phala provides:

- Immutable transaction records for economic actions
- Cryptographic verification of on-chain data
- Economic security through stake-based mechanisms
- Tamper-proof audit trails for critical operations

### Confidential Computation

Phala Network provides confidential computing guarantees for MCP servers:

- TEE (Trusted Execution Environment) protection for code and data within servers
- Encryption of data in use, protecting against insider threats and data breaches
- Remote attestation to verify the integrity of the execution environment
- Enhanced privacy and security for sensitive AI computations

## Migration Path

Our transition to the MCP architecture follows a phased approach:

1.  **Define MCP Server Interfaces**: Define clear interfaces and communication protocols for each phase's MCP server.
2.  **Implement Core MCP Servers**: Develop the basic server structure for each AEIOU-Y phase using the MCP framework.
3.  **Integrate Langchain Utils**:  Incorporate the existing `langchain_utils.py` for model interactions within MCP servers.
4.  **Implement SSE Streaming**: Add Server-Sent Events for real-time communication from MCP servers to the Python API.
5.  **Orchestrate with Python API**:  Update the Python API to manage and orchestrate the MCP server calls and SSE streams.
6.  **Deployment and Testing**: Deploy the MCP-based architecture in Docker and Phala Network for comprehensive testing.

## Conclusion

The Choir stack, now pivoting to an MCP-based architecture, represents a carefully considered and coherent approach to building secure, scalable multi-agent AI systems. By embracing MCP and selecting complementary technologies, we've created an architecture that:

- Naturally expresses phase-based AI workflows as modular services
- Provides strong security and isolation between phases
- Manages conversational context and state efficiently within each server
- Integrates blockchain-based economic incentives and secure computation
- Scales effectively for robust, production-ready deployment

Our technology choices reflect a commitment to building AI systems that are not only intelligent but also robust, secure, and transparent. The MCP architecture provides a solid foundation for realizing this vision.

=== File: docs/stack_pivot_summary.md ===



==
stack_pivot_summary
==


# Stack Pivot Summary: From LangGraph to MCP Architecture

## Executive Summary

Choir has undergone a significant architectural pivot, moving from a graph-based implementation using LangGraph to an MCP-based architecture. This document summarizes the rationale, advantages, and implementation plan for this transition.

## Key Decisions

1.  **Architectural Pattern**: MCP Architecture instead of Graph Model
2.  **Core Framework**: Model Context Protocol (MCP) for server-based phases
3.  **Database**: libSQL/Turso for SQL+vector capabilities
4.  **Blockchain**: Sui via PySUI
5.  **Type Safety**: Pydantic
6.  **API**: FastAPI/Uvicorn
7.  **Deployment**: Docker on Phala Network

## Rationale for the Pivot

After extensive experimentation with LangGraph, several challenges emerged, and further analysis suggested MCP as a more suitable architecture:

1.  **Memory Management Issues**: Persistent problems with memory usage and state management in LangGraph remained unresolved.
2.  **Debugging Complexity**: Difficulty in tracing and resolving issues in the complex LangGraph workflows.
3.  **Architectural Mismatch**: LangGraph's graph model was not ideally suited for the desired phase-based, service-oriented architecture.
4.  **Scalability Concerns**:  Uncertainties about the scalability of the LangGraph approach for long-term growth.
5.  **Desire for Service Isolation**:  A need for better isolation and modularity between phases, which MCP servers could provide.

## Advantages of MCP Architecture

The MCP architecture provides significant advantages for Choir:

1.  **Service Encapsulation**: Each phase is encapsulated as a separate MCP server, improving modularity and maintainability.
2.  **Clear Tool Boundaries**:  Each phase's MCP server explicitly defines and controls the tools it can access, enhancing security and preventing runaway tool use.
3.  **Improved Isolation**:  Fault isolation is enhanced as phases run in separate server processes.
4.  **Resource Management**: Each MCP server manages its own resources, potentially improving resource utilization and stability.
5.  **Scalability**:  The service-oriented nature of MCP architecture allows for easier scaling and distribution of phases.
6.  **Technology Alignment**: MCP aligns well with the vision of decentralized, service-oriented AI and the use of Phala Network for secure enclaves.

## PostChain as MCP Servers

The AEIOU-Y PostChain maps naturally to specialized MCP servers, with each phase implemented as a separate server:

- **Action Server**: Handles user input and initial response in the Action phase
- **Experience Server**: Implements knowledge retrieval and context enrichment for the Experience phase
- **Intention Server**: Focuses on user intent modeling and goal setting in the Intention phase
- **Observation Server**: Manages semantic connections and information tagging for the Observation phase
- **Understanding Server**: Performs context evaluation and filtering in the Understanding phase
- **Yield Server**: Handles final response generation and process completion in the Yield phase

## Technical Stack Synergy

The components of the new MCP-based stack work together synergistically:

- **MCP + FastAPI/Uvicorn**:  FastAPI provides a robust API layer for interacting with MCP servers.
- **MCP + libSQL/Turso**: Each MCP server can use libSQL for local state persistence if needed.
- **MCP + PySUI**: MCP servers can potentially integrate with PySUI for blockchain interactions in a modular way.
- **Docker + Phala**: MCP servers can be containerized and deployed securely on Phala Network.

## Migration Path

The migration to MCP architecture will follow a structured path:

1.  **Define MCP Server Interfaces**: Clearly define the tool and resource interfaces for each phase's MCP server.
2.  **Implement Core MCP Servers**:  Develop the basic MCP server structure for each of the AEIOU-Y phases.
3.  **Integrate Langchain Utils**:  Incorporate the existing `langchain_utils.py` for model interactions within MCP servers.
4.  **Implement SSE Streaming**: Add SSE streaming capabilities to each MCP server for real-time output.
5.  **Orchestrate with Python API**: Update the Python API to orchestrate calls to the new MCP servers and handle SSE streams.
6.  **Deploy and Test**:  Deploy the MCP-based architecture in a local Docker environment and then on Phala Network for testing and validation.

## Security Benefits of MCP Architecture

The MCP architecture enhances security in several dimensions:

1.  **Tool Control**:  Strict control over tools available to each phase, reducing the risk of unintended actions.
2.  **Service Isolation**:  Phases run in separate server processes, limiting the impact of potential vulnerabilities in one phase.
3.  **Clear Interfaces**:  Well-defined interfaces between phases (MCP protocol) improve system understanding and security analysis.
4.  **Minimal Tool Exposure**:  Phases only expose necessary tools, reducing the attack surface.
5.  **Phala Integration**:  Deployment on Phala Network provides confidential computing guarantees for sensitive operations within MCP servers.

## Documentation Updates

The documentation will be updated to reflect the new MCP architecture:

1.  Updated: Stack Pivot Summary document to reflect MCP architecture
2.  Updated: Documentation index and navigation to remove actor-model specific content
3.  To be added: MCP architecture diagrams and descriptions
4.  To be added: MCP server implementation guidelines
5.  Archived: Actor-model specific documentation to `docs/archive`

## Conclusion

The pivot from LangGraph to the MCP architecture represents a strategic evolution for Choir.  By adopting MCP, we gain a more modular, scalable, and secure architecture that aligns better with the project's goals of decentralized, service-oriented AI. This transition positions Choir for long-term growth and innovation while maintaining the core AEIOU-Y PostChain conceptual framework.
