# Level 0 Documentation



=== File: docs/tree.md ===



==
tree.md
==


# Choir Directory Structure
## Output of $ tree -I 'venv|archive|__pycache__|iOS_Example|dependencies' | pbcopy

.
├── api
│   ├── __init__.py
│   ├── app
│   │   ├── __init__.py
│   │   ├── config.py
│   │   ├── database.py
│   │   ├── langchain_utils.py
│   │   ├── middleware
│   │   │   ├── __init__.py
│   │   │   └── auth.py
│   │   ├── models
│   │   │   ├── __init__.py
│   │   │   ├── api.py
│   │   │   ├── auth.py
│   │   │   └── user.py
│   │   ├── postchain
│   │   │   ├── __init__.py
│   │   │   ├── langchain_workflow.py
│   │   │   ├── phases
│   │   │   ├── postchain_llm.py
│   │   │   ├── prompts
│   │   │   │   └── prompts.py
│   │   │   ├── README.md
│   │   │   ├── schemas
│   │   │   │   ├── __init__.py
│   │   │   │   ├── rewards.py
│   │   │   │   └── state.py
│   │   │   ├── state
│   │   │   └── utils.py
│   │   ├── routers
│   │   │   ├── auth.py
│   │   │   ├── balance.py
│   │   │   ├── notifications.py
│   │   │   ├── postchain.py
│   │   │   ├── threads.py
│   │   │   ├── users.py
│   │   │   └── vectors.py
│   │   ├── services
│   │   │   ├── __init__.py
│   │   │   ├── auth_service.py
│   │   │   ├── notification_service.py
│   │   │   ├── push_notification_service.py
│   │   │   ├── rewards_service.py
│   │   │   └── sui_service.py
│   │   ├── tools
│   │   │   ├── __init__.py
│   │   │   ├── base.py
│   │   │   ├── brave_search.py
│   │   │   ├── calculator.py
│   │   │   ├── qdrant.py
│   │   │   ├── tavily_search.py
│   │   │   └── web_search.py
│   │   └── utils.py
│   ├── blog
│   │   ├── business_model.md
│   │   ├── inverse_scaling_law.md
│   │   └── loop_of_thought.md
│   ├── content
│   │   ├── landing.md
│   │   ├── marketing.md
│   │   ├── privacy.md
│   │   └── support.md
│   ├── Dockerfile
│   ├── main.py
│   ├── pyproject.toml
│   ├── pytest.ini
│   ├── requirements.txt
│   ├── static
│   │   └── shared
│   │       ├── script.js
│   │       └── style.css
│   ├── templates
│   │   └── base.html
│   ├── test_push_notification_e2e.py
│   ├── test_push_notification.py
│   └── tests
│       ├── __init__.py
│       ├── conftest.py
│       ├── postchain
│       │   ├── __init__.py
│       │   ├── models_test.py
│       │   ├── random_gen_prompts.md
│       │   ├── test_cases.json
│       │   ├── test_langchain_workflow.py
│       │   ├── test_providers_abstracted.py
│       │   ├── test_providers.py
│       │   ├── test_simple_multimodel_stream.py
│       │   ├── test_structured_output.py
│       │   └── test_utils.py
│       ├── test_main.py
│       ├── test_sui_service.py
│       ├── test_user_thread_endpoints.py
│       └── tools
│           ├── __init__.py
│           ├── direct_search_diagnostic.py
│           ├── direct_search_test.py
│           ├── test_brave_search.py
│           ├── test_calculator.py
│           ├── test_multimodel_with_tools.py
│           ├── test_recent_events.py
│           ├── test_search_tools_report.py
│           ├── test_tavily_search.py
│           └── test_updated_search.py
├── Choir
│   ├── App
│   │   ├── AppDelegate.swift
│   │   ├── BackgroundStateMonitor.swift
│   │   └── ChoirApp.swift
│   ├── Assets.xcassets
│   │   ├── AccentColor.colorset
│   │   │   └── Contents.json
│   │   ├── AppIcon.appiconset
│   │   │   ├── Contents.json
│   │   │   └── Icon-App-1024x1024@2x.png
│   │   ├── choir-logo.imageset
│   │   │   └── Contents.json
│   │   ├── Contents.json
│   │   └── Icon-App-1024x1024.imageset
│   │       ├── Contents.json
│   │       └── Icon-App-1024x1024@2x.png
│   ├── Choir.entitlements
│   ├── Config
│   │   └── ApiConfig.swift
│   ├── ContentView.swift
│   ├── Coordinators
│   │   ├── AppCoordinator.swift
│   │   ├── PostchainCoordinator.swift
│   │   └── PostchainCoordinatorImpl.swift
│   ├── Documentation
│   │   └── DesignStyleGuide.md
│   ├── Info.plist
│   ├── Models
│   │   ├── AnyCodable.swift
│   │   ├── APITypes.swift
│   │   ├── AuthModels.swift
│   │   ├── CoinType.swift
│   │   ├── ConversationModels.swift
│   │   ├── NotificationModels.swift
│   │   ├── PostchainStreamEvent+Extension.swift
│   │   ├── SearchModels.swift
│   │   └── WalletBalance.swift
│   ├── Networking
│   │   ├── EventSource.swift
│   │   ├── PostchainAPIClient.swift
│   │   └── RewardsService.swift
│   ├── Preview Content
│   │   └── Preview Assets.xcassets
│   │       └── Contents.json
│   ├── Services
│   │   ├── APIClient.swift
│   │   ├── AuthService.swift
│   │   ├── BackgroundTaskManager.swift
│   │   ├── KeychainService.swift
│   │   ├── ModelConfigManager.swift
│   │   ├── PushNotificationManager.swift
│   │   ├── ThreadManager.swift
│   │   ├── ThreadPersistenceService.swift
│   │   ├── TransactionService.swift
│   │   ├── VectorService.swift
│   │   └── WalletManager.swift
│   ├── Utils
│   │   ├── MarkdownPaginator.swift
│   │   ├── MarkdownThemes.swift
│   │   ├── PaginationCacheManager.swift
│   │   ├── PaginationUtils.swift
│   │   ├── String+Extensions.swift
│   │   ├── TextSelectionSheet.swift
│   │   └── UIDevice+Extensions.swift
│   ├── ViewModels
│   │   └── PostchainViewModel.swift
│   └── Views
│       ├── ChoirThreadDetailView.swift
│       ├── Components
│       ├── EnhancedSendCoinView.swift
│       ├── GlassPageControl.swift
│       ├── ImportMnemonicView.swift
│       ├── LoginView.swift
│       ├── MessageRow.swift
│       ├── ModelConfigView.swift
│       ├── OnboardingView.swift
│       ├── PaginatedMarkdownView.swift
│       ├── PhaseCard.swift
│       ├── PhaseCardContextMenu.swift
│       ├── PostchainView.swift
│       ├── QRScannerView.swift
│       ├── SettingsView.swift
│       ├── Styles
│       ├── Thread
│       │   └── Components
│       │       ├── ThreadInputBar.swift
│       │       └── ThreadMessageList.swift
│       ├── ThreadExportView.swift
│       ├── ThreadImportView.swift
│       ├── TransactionsView.swift
│       ├── WalletCardView.swift
│       ├── WalletSelectionView.swift
│       └── WalletView.swift
├── choir_coin
│   └── choir_coin
│       ├── build
│       │   ├── choir
│       │   │   ├── BuildInfo.yaml
│       │   │   ├── bytecode_modules
│       │   │   │   └── choir.mv
│       │   │   ├── debug_info
│       │   │   │   ├── choir.json
│       │   │   │   └── choir.mvd
│       │   │   └── sources
│       │   │       └── choir.move
│       │   └── locks
│       ├── Move.lock
│       ├── Move.toml
│       ├── sources
│       │   └── choir_coin.move
│       └── tests
│           └── choir_coin_tests.move
├── Choir.xcodeproj
│   ├── project.pbxproj
│   ├── project.xcworkspace
│   │   ├── contents.xcworkspacedata
│   │   ├── xcshareddata
│   │   │   └── swiftpm
│   │   │       ├── configuration
│   │   │       └── Package.resolved
│   │   └── xcuserdata
│   │       └── wiz.xcuserdatad
│   │           ├── IDEFindNavigatorScopes.plist
│   │           └── UserInterfaceState.xcuserstate
│   └── xcuserdata
│       └── wiz.xcuserdatad
│           ├── xcdebugger
│           │   └── Breakpoints_v2.xcbkptlist
│           └── xcschemes
│               └── xcschememanagement.plist
├── ChoirTests
│   ├── APIResponseTests.swift
│   ├── ChoirTests.swift
│   ├── ChoirThreadTests.swift
│   └── RESTPostchainAPIClientTests.swift
├── ChoirUITests
│   ├── ChoirUITests.swift
│   └── ChoirUITestsLaunchTests.swift
├── CLAUDE.md
├── docker-compose.yml
├── docs
│   ├── blockchain_integration.md
│   ├── CHANGELOG.md
│   ├── ChoirPushNotificationsImplementationGuide.md
│   ├── contract_deployment.md
│   ├── core_core.md
│   ├── core_economics.md
│   ├── core_state_transitions.md
│   ├── data_engine_model.md
│   ├── e_business.md
│   ├── e_concept.md
│   ├── evolution_naming.md
│   ├── evolution_token.md
│   ├── issues
│   │   └── retry.md
│   ├── levels
│   │   ├── all.txt
│   │   ├── level0.md
│   │   ├── level1.md
│   │   ├── level2.md
│   │   ├── level3.md
│   │   ├── level4.md
│   │   └── level5.md
│   ├── mainnet_migration.md
│   ├── notification_system.md
│   ├── plan_anonymity_by_default.md
│   ├── plan_choir_materialization.md
│   ├── postchain_temporal_logic.md
│   ├── require_action_phase.md
│   ├── require_experience_phase.md
│   ├── require_intention_phase.md
│   ├── require_observation_phase.md
│   ├── require_phase_requirements_index.md
│   ├── require_understanding_phase.md
│   ├── require_yield_phase.md
│   ├── reward_function.md
│   ├── rewards_system.md
│   ├── scripts
│   │   ├── combiner.sh
│   │   └── update_tree.sh
│   ├── security_considerations.md
│   ├── stack_argument.md
│   ├── state_management_patterns.md
│   └── tree.md
├── notebooks
│   ├── post_chain0.ipynb
│   └── vowel_loop3.ipynb
├── README.md
├── render.yaml
├── reward_function_simplified.py
├── reward_function.py
└── scripts
    ├── generate_provider_reports.sh
    ├── generate_quick_search_report.sh
    ├── generate_search_report.sh
    ├── generate_single_provider_report.sh
    ├── sources_displaying.sh
    ├── test_api.sh
    ├── test_notifications.py
    ├── test_postchain_multiturn.sh
    └── test_simulator_notifications.sh

72 directories, 234 files

=== File: docs/CHANGELOG.md ===



==
CHANGELOG.md
==


# Changelog
## [2025-04-28] - 2025-04-28

### Added

- **Mainnet Deployment:** Successfully deployed Choir to the Sui mainnet with package ID `0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898::choir::CHOIR`.
- **Multiple Wallet Support:** Implemented support for multiple wallet accounts with horizontal scrolling in the Wallets tab.
- **Wallet & Thread Import/Export:** Added secure import and export functionality for wallets and threads with biometric protection.
- **Rewards System:** Implemented the full rewards system with:
  - **Novelty Rewards:** Users earn rewards for original content based on vector similarity scores.
  - **Citation Rewards:** Authors of cited content receive rewards when their contributions inform responses.
  - **Choir Coin Integration:** Connected to Sui blockchain for minting and distributing CHOIR tokens.
- **Improved Pagination:** Enhanced pagination system that preserves formatting across pages while maximizing content density.
- **Transaction Management:** Added a dedicated Transactions tab showing a chronological history of all transactions across wallets.
- **Citation Display:** Implemented early UI for displaying and interacting with citations in vector content.
- **Performance Optimization:** Improved app launch and navigation performance by loading only thread metadata initially and loading full content when needed.
- **Model Updates:** Added support for newer AI models and improved model configuration management.

### Changed

- **UI Redesign:** Completely redesigned interface with improved navigation flow and visual consistency.
- **Thread Management:** Enhanced thread persistence with wallet-specific thread storage and optimized loading.
- **Authentication Flow:** Improved authentication with biometric support (FaceID/TouchID) and passcode fallback.

## [2025-04-09] - 2025-04-09

### Added

- **iOS Client Persistence:** Implemented local JSON file storage for thread data.
- **Automatic Thread Titles:** Threads now get an auto-generated title based on the first 10 words of the initial AI Action phase response.
- **Close the Loop UI:** When the yield phase finishes downloading, if the user is viewing the action phase, the UI now automatically transitions to display the final response with a smooth wrap-around animation.


## [2025-03-28] - 2025-03-28

### Added

-   **PostChain Sequential Model Execution:** Implemented a prototype version of the PostChain running on a mobile device, successfully executing a sequence of 6 distinct AI models. This demonstrates the feasibility of the multi-phase workflow and shows initial promise for value generation.

### Changed

-   **Architectural Validation:** The sequential model execution validates the core concept of the PostChain flow. Next steps involve implementing background looping, Qdrant database integration for state persistence and memory, and connecting to the Sui service for reward distribution. These are considered tractable integration tasks.

## [2025-03-27] - 2025-03-27

### Changed

-   **Architectural Focus Shift: Qdrant-Sui MVP Prioritized**
    -   Refocused development efforts on a Minimum Viable Product (MVP) centered around **Qdrant** (data/vector store) and **Sui** (blockchain token/rewards).
    *   Adopted a streamlined architecture using the existing **Python API (FastAPI)** as the central orchestrator.
    *   Leveraging the current **LCEL-based PostChain workflow** (`langchain_workflow.py`) for MVP implementation speed.
    *   Defined clear data structures and interactions between the API, PostChain phases, Qdrant collections (`choir`, `users`, `chat_threads`, `intention_memory`, `observation_memory`), and the `sui_service.py`.
    *   Refined core documentation (`core_core.md`, `state_management_patterns.md`, `blockchain_integration.md`, `security_considerations.md`, `stack_argument.md`, `index.md`) to reflect the MVP scope and architecture.

### Deferred (Post-MVP)

-   Implementation of the full Model Context Protocol (MCP) server architecture.
-   Integration of client-side libSQL caching for offline support.
-   Deployment using Phala Network TEEs for confidential computing.
-   Implementation of the full dynamic economic model (MVP uses basic rewards).

## [Unreleased] - 2025-03-12

### Changed

-   **Major Architectural Pivot: Shifted from LangGraph to MCP Architecture**
    -   Transitioned to Model Context Protocol (MCP) architecture for the Choir platform.
    -   Adopted a service-oriented architecture with each PostChain phase implemented as a separate MCP server.
    -   Implemented MCP Resources for efficient conversation state management and context sharing.
    -   Leveraged MCP Notifications for real-time updates and communication between Host and Servers.
    -   Replaced LangGraph-based workflow orchestration with a Host-application-centric orchestration model using asynchronous tasks.
    -   Refined the focus on modularity, scalability, and security through the MCP architecture.

### Added

-   **Coherent Technology Stack for MCP Architecture:**
    -   **Model Context Protocol (MCP) Architecture:** Service-oriented architecture for PostChain phases, enabling modularity and scalability.
    -   **PySUI:** Maintained PySUI for blockchain integration and economic actions.
    -   **Pydantic:** Continued use of Pydantic for type safety and message validation in the MCP architecture.
    -   **FastAPI/Uvicorn:** Continued use of FastAPI/Uvicorn for the Python API layer, now orchestrating MCP server interactions.
    -   **Docker:** Maintained Docker for containerization and deployment of MCP servers.
    -   **Phala Network:** Maintained Phala Network for TEE-secured operations and confidential computing for MCP servers.

-   **Enhanced Token Economy and Reward System (RL-Driven CHOIR):**
    -   **CHOIR Coins as Training Signals for AI:** Evolved the CHOIR coin to act as training signals for AI models, driving a self-improving AI ecosystem.
    -   **Novelty and Citation Rewards:** Implemented novelty rewards for original prompts and citation rewards for salient contributions, algorithmically distributed by AI models.
    -   **Contract as Data Marketplace Foundation:** Defined the contract as the basis for a data marketplace within Choir, enabling CHOIR-based data access and contribution pricing.
    -   **Data Economy Vision:** Developed the vision for a comprehensive data marketplace where CHOIR serves as the currency for accessing and contributing to valuable datasets.

### Removed

-   Deprecated LangGraph dependency and graph-based state management due to scalability and maintenance concerns.

## [2025-02-25] - 2025-02-25

### Added

-   Implemented UI carousel to improve user experience
-   Added display of priors in the Experience step
-   Resumed active development after coding hiatus

### Planned

-   API streaming implementation to enhance responsiveness
-   Model reconfiguration for improved performance
-   Go multimodel, then multimodal
-   OpenRouter integration
-   Conceptual evolution from "Chorus Cycle" to "Post Chain"
    -   Representing shift from harmonic oscillator (cycle) to anharmonic oscillator (chain)
    -   Aligning interface terminology with underlying model
-   Client-side editable system prompts for customization
-   Additional phases in the Post Chain:
    -   Web search phase for real-time information access
    -   Sandboxed arbitrary tool use phase for enhanced capabilities

## [2025-02-24] - 2025-02-24

### Changed

-   Implemented fractional quantum anharmonic oscillator model for dynamic stake pricing
-   Added fractional parameter α to capture memory effects and non-local interactions
-   Revised parameter modulation formulas for K₀, α, and m to reflect interdependencies
-   Created simulation framework for parameter optimization

## [2025-02-23] - 2025-02-23

### Changed

-   Documented quantum anharmonic oscillator model implementation and dynamic stake pricing mechanism via an effective anharmonic coefficient modulated by approval/refusal statistics.

## [Unreleased]

### Changed

-   Updated all documentation to version 6.0
    -   Transformed structured documentation into fluid prose
    -   Relaxed event-driven architecture requirements for initial TestFlight
    -   Clarified implementation priorities and post-funding features
    -   Maintained theoretical frameworks while focusing on core functionality

### Added

-   Initial Chorus cycle working in iOS simulator
    -   Basic message flow through phases
    -   Response handling
    -   State management

### Documented

-   Created 15 comprehensive issues covering:
    -   Core message system implementation
    -   Type reconciliation with Qdrant
    -   API client updates
    -   Coordinator message flow
    -   User identity management
    -   Thread state management
    -   Integration testing
    -   Error handling strategy
    -   Performance monitoring
    -   State recovery
    -   Thread sheet implementation
    -   Thread contract implementation
    -   Message rewards system
    -   LanceDB migration
    -   Citation visualization

### Architecture

-   Defined clear type system for messages
-   Planned migration to LanceDB
-   Structured multimodal support strategy

### Technical Debt

-   Identified areas needing more specification:
    -   Thread Sheet UI (marked as "AI SLOP")
    -   Reward formulas need verification
    -   Migration pipeline needs careful implementation

## [0.4.2] - 2024-11-09

### Added

-   Development principles with focus on groundedness
-   Basic chat interface implementation
-   SwiftData message persistence // this subsequently became a problem. swiftdata is coupled with swiftui and there was interference between view rendering and data persistence
-   Initial Action step foundation

### Changed

-   Shifted to iterative, ground-up development approach
-   Simplified initial implementation scope
-   Focused on working software over theoretical architecture
-   Adopted step-by-step Chorus Cycle implementation strategy

### Principles

-   Established groundedness as core development principle
-   Emphasized iterative growth and natural evolution
-   Prioritized practical progress over theoretical completeness
-   Introduced flexible, evidence-based development flow

## [0.4.1] - 2024-11-08

### Added

-   Self-creation process
-   Post-training concepts
-   Concurrent processing ideas
-   Democratic framing
-   Thoughtspace visualization

### Changed

-   Renamed Update to Understanding
-   Enhanced step descriptions
-   Refined documentation focus
-   Improved pattern recognition

## [0.4.0] - 2024-10-30

### Added

-   Swift architecture plans
-   Frontend-driven design
-   Service layer concepts
-   Chorus cycle definition

### Changed

-   Enhanced system architecture
-   Refined core patterns

## [0.3.5] - 2024-09-01

-   Choir.chat as a web3 dapp
-   messed around with solana
-   used a lot of time messing with next.js/react/typescript/javascript
-   recognized that browser extension wallet is terrible ux

## [0.3.0] - 2024-03-01

### Added

-   ChoirGPT development from winter 2023 to spring 2024

-   First developed as a ChatGPT plugin, then a Custom GPT
-   The first global RAG system / collective intelligence as a GPT

## [0.2.10] - 2023-04-01

### Added

-   Ahpta development from winter 2022 to spring 2023

## [0.2.9] - 2022-04-01

### Added

-   V10 development from fall 2021 to winter 2022

## [0.2.8] - 2021-04-01

### Added

-   Elevisio development from spring 2020 to spring 2021

## [0.2.7] - 2020-04-01

### Added

-   Bluem development from spring 2019 to spring 2020

## [0.2.6] - 2019-04-01

### Added

-   Blocstar development from fall 2018 to spring 2019

## [0.2.5] - 2018-04-01

### Added

-   Phase4word development from summer 2017 to spring 2018

### Changed

-   Showed Phase4word to ~50 people in spring 2018, received critical feedback
-   Codebase remains in 2018 vintage

## [0.2.0] - 2016-06-20

### Added

-   Phase4 party concept
-   Early democracy technology
-   Initial value systems

### Changed

-   Moved beyond truth measurement framing
-   Refined core concepts

## [0.1.0] - 2015-07-15

### Added

-   Initial simulation hypothesis insight
-   "Kandor"
-   Quantum information concepts
-   Planetary coherence vision
-   Core system ideas

=== File: docs/scripts/combiner.sh ===



==
combiner.sh
==


#!/bin/bash

# Revised prefix arrays
level0_prefixes=("")  # Basic technical integration
level1_prefixes=("core" "requirements")  # Core system components
level2_prefixes=("e")           # Business/concept/implementation
level3_prefixes=("plan")               # Plans
level4_prefixes=("fqaho")     # Simulations
level5_prefixes=("evolution" "data")             # Foundational principles

# Function to add separator and header
add_separator() {
    echo -e "\n"
    echo "=="
    echo "$1"
    echo "=="
    echo -e "\n"
}

# Function to get level for a file
get_level_for_file() {
    filename=$(basename "$1")
    prefix=$(echo "$filename" | cut -d'_' -f1)

    for p in "${level0_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 0 && return; done
    for p in "${level1_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 1 && return; done
    for p in "${level2_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 2 && return; done
    for p in "${level3_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 3 && return; done
    for p in "${level4_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 4 && return; done
    for p in "${level5_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 5 && return; done

    echo -1
}

# Function to process files for a level
process_level() {
    level=$1
    output_file="docs/levels/level${level}.md"

    echo "# Level ${level} Documentation" > "$output_file"
    echo -e "\n" >> "$output_file"

    SPECIAL_FILES=("docs/prompt_wake_up.md" "docs/prompt_getting_started.md" "docs/prompt_reentry.md" "docs/prompt_organization.md" "docs/prompt_summary_prompt.md" "docs/prompt_chorus_cycle.md" "docs/tree.md" "docs/CHANGELOG.md" "docs/scripts/combiner.sh")

    # Level 0 now includes important system files (previously in level -1)
    if [ "$level" -eq 0 ]; then
        # Add system files (previously in level -1)
        for special_file in "${SPECIAL_FILES[@]}"; do
            if [ -f "$special_file" ]; then
                echo -e "\n=== File: $special_file ===\n" >> "$output_file"
                add_separator "$(basename "$special_file")" >> "$output_file"
                cat "$special_file" >> "$output_file"
                echo "$special_file" >> "/tmp/processed_files.txt"
            fi
        done

    fi

    # Process all docs to find ones for this level
    for file in docs/*.md; do
        if [ -f "$file" ] && [ "$(get_level_for_file "$file")" -eq "$level" ]; then
            echo -e "\n=== File: $file ===\n" >> "$output_file"
            add_separator "$(basename "$file" .md)" >> "$output_file"
            cat "$file" >> "$output_file"
            echo "$file" >> "/tmp/processed_files.txt"
        fi
    done
}

# Create temporary file for tracking
touch /tmp/processed_files.txt

# Process all levels (excluding level -1 as its content is now in level 0)
echo "Processing documentation..."
for level in {0..5}; do
    process_level $level
done

# Concatenate all levels into a single file
echo "Combining all levels into one file..."
mkdir -p docs/levels
cat docs/levels/level{0..5}.md > docs/levels/all.txt

# Check for uncategorized files
echo -e "\nUncategorized files:"
uncategorized=0
for doc in docs/*.md; do
    if ! grep -q "^$doc$" "/tmp/processed_files.txt"; then
        echo "$doc"
        uncategorized=$((uncategorized + 1))
        # Append uncategorized files to all.txt
        echo -e "\n=== File: $doc ===\n" >> docs/levels/all.txt
        add_separator "$(basename "$doc" .md)" >> docs/levels/all.txt
        cat "$doc" >> docs/levels/all.txt
    fi
done

if [ "$uncategorized" -gt 0 ]; then
    echo -e "\nTotal uncategorized: $uncategorized files"
fi

# Cleanup
rm -f "/tmp/processed_files.txt"

echo "Documentation combination complete"
# Level 1 Documentation



=== File: docs/core_core.md ===



==
core_core
==


# Core System Overview (Qdrant-Sui MVP)

VERSION core_system: 8.0 (Qdrant-Sui MVP Focus)

## Overview

The Choir system, for its Minimum Viable Product (MVP), is architected around a focused stack designed to validate the core concepts of AI-driven conversation analysis and a tokenized reward mechanism. This MVP centers on **Qdrant** as the primary data and vector store and **Sui** as the blockchain layer for the CHIP token, orchestrated by a central **Python API**. While future iterations envision a distributed network of specialized servers, the MVP utilizes a streamlined architecture to accelerate validation.

## Foundational Principles (Informed by Broader Vision)

Even within the MVP's focused scope, Choir is built upon a clear hierarchy of truth and state management, guided by underlying principles:

1.  **Blockchain as Economic Truth (Sui):** The **Sui blockchain** serves as the *authoritative source of truth for the economic state*. In the MVP, this includes the basic existence of the CHIP token and the execution of simplified reward distributions. Ultimately, it will manage thread ownership, full token balances, message hashes, co-author lists, and the governance of the economic model.
2.  **Qdrant as Semantic Truth:** **Qdrant** serves as the *authoritative source for content and semantic relationships*. It stores message content, user/thread data, phase-specific memory, embeddings, and eventually, citation networks.
3.  **AEIOU-Y Post Chain as Interaction Pattern:** The **AEIOU-Y Post Chain** defines the natural interaction pattern for processing user input and generating nuanced AI responses. In the MVP, this pattern is implemented via the LCEL workflow.
4.  **Dynamic Economic Model:** The economic model, based on dynamic principles and the CHIP token, underpins the reward system, even if its full implementation is post-MVP.

## Core Components (Qdrant-Sui MVP)

1.  **Qdrant (Data & Vector Layer):**
    *   **Role:** The authoritative source for persistent data relevant to the AI workflow and reward mechanism. Stores user mappings (linked to Sui addresses), thread metadata, conversation messages (user prompts and final AI responses with embedded phase outputs), and specialized memory collections (`intention_memory`, `observation_memory`).
    *   **Function:** Enables semantic search (priors) for the Experience phase, stores structured outputs, and provides the necessary data inputs (novelty/similarity scores, author/prior linkage) for the reward system.

2.  **Sui Blockchain (via PySUI Service):**
    *   **Role:** Manages the CHIP token (basic contract) and handles reward distribution logic (simplified for MVP). The ultimate source of economic truth.
    *   **Function (MVP):** Provides foundational token infrastructure. The `sui_service.py` within the API backend interacts with Sui (via PySUI) to execute basic reward actions.

3.  **Python API (FastAPI/Uvicorn - Orchestration Layer):**
    *   **Role:** The central orchestrator connecting the client, AI logic, Qdrant, and Sui.
    *   **Function:** Authenticates users (Sui signature), manages the PostChain workflow execution, handles Qdrant interactions, triggers reward calculations via the Sui service, and streams results to the client.

4.  **PostChain Workflow (LCEL Implementation):**
    *   **Role:** The core AI processing engine, implementing the AEIOU-Y pattern.
    *   **Function:** Executes sequentially within the Python API (`langchain_workflow.py`). Phases interact with Qdrant (via `database.py`) for data retrieval/storage. Calculates scores needed for rewards.

5.  **Supporting Technologies:**
    *   **Langchain Utils (`langchain_utils.py`):** LLM abstraction.
    *   **Pydantic:** Data validation.
    *   **Docker:** API containerization.
    *   **SwiftUI & Keychain:** Client UI and secure Sui key storage.
    *   **Python Async/await:** Used within the API and LCEL workflow for efficient concurrent operations.

## MVP Architecture & Data Flow

The Qdrant-Sui MVP operates as follows:

1.  User interacts via **SwiftUI Client**, authenticating using their **Sui** key.
2.  Request hits the **Python API (FastAPI)**.
3.  API orchestrates the **PostChain Workflow (LCEL)**.
4.  PostChain phases interact with **Qdrant** for priors and memory, using **Langchain Utils** for LLM calls. Scores are calculated.
5.  Final AI response (with embedded phase outputs/scores) is persisted in **Qdrant**.
6.  API triggers the **Sui Service** for rewards based on Qdrant data.
7.  API streams results back to the **SwiftUI Client**.

This architecture validates the core loop: **User Input -> API Orchestration -> PostChain (Qdrant Interaction) -> Reward Trigger (Sui Service)**.

## Strategic Focus for MVP

*   **Qdrant Centrality:** Validate Qdrant for storing diverse AI-related data and supporting semantic search.
*   **Sui Integration:** Establish the basic workflow for triggering token rewards based on Qdrant data.
*   **Leveraging Existing Code:** Utilize the current LCEL PostChain implementation.
*   **Simplicity:** Defer complexities like distributed servers, advanced client caching, and TEE deployment.

## The Combined Result (MVP)

The MVP delivers a system combining:

*   **Economic Incentives (CHIP token, Basic Principles):** Managed via Sui and PySUI Service.
*   **Semantic Knowledge (Qdrant):** Stored, accessed, and utilized by the PostChain workflow.
*   **Natural Interaction Patterns (AEIOU-Y Post Chain):** Implemented via the LCEL workflow.
*   **Python Async/await:** Powers the backend API and workflow.

This streamlined MVP architecture focuses on demonstrating the fundamental interplay between semantic data storage (Qdrant) and a blockchain-based reward mechanism (Sui), laying the groundwork for the more complex, distributed, and secure system envisioned in the broader Choir architecture.

=== File: docs/core_economics.md ===



==
core_economics
==


# Core Economic Model: Fueling a Self-Improving AI Ecosystem with CHOIR Coins

VERSION core_economics: 8.0 (RL-Driven Data Economy)

The economic model of Choir is not just about transactions and value exchange; it's about creating a **self-sustaining engine for AI improvement and a thriving marketplace for valuable human data.**  The CHOIR coin is at the heart of this engine, acting as both the fuel and the training signal for a revolutionary AI ecosystem.

## CHOIR: Beyond a Utility Token - A Training Signal and Data Currency

The CHOIR coin transcends the limitations of a traditional utility token. It is designed to be:

*   **A Representation of Contribution and Ownership:** CHOIR coins represent a stake in the collective intelligence of Choir, acknowledging and rewarding user contributions to the platform's knowledge base.
*   **A Training Signal for AI Models:** CHOIR coins, distributed as novelty and citation rewards, act as *direct training signals* for AI models within the Choir ecosystem, guiding them to optimize for desired behaviors and high-quality content generation.
*   **The Currency of a Data Marketplace:** CHOIR coins are the *exclusive currency* for accessing and transacting with the valuable, human-generated data within the Choir platform, creating a demand-driven data marketplace.
*   **A Driver of Network Effects and Value Accrual:** The CHOIR coin economy is designed to create powerful network effects, driving user engagement, data creation, AI improvement, and sustainable coin value accrual.

## The Dynamic Contract: Governing a Data Marketplace

The dynamic contract, implemented on the Sui blockchain, is the **economic heart of the Choir data marketplace**. It provides a dynamic and nuanced mechanism for:

*   **Stake Pricing and Value Discovery:** The model dynamically determines the stake price for contributing to threads, reflecting the evolving value of knowledge and user attention within the ecosystem.
*   **Data Access and Contribution Pricing:** The contract governs the "price of data" within each thread. Users "pay" CHOIR coins (stake) to contribute to threads, and this contribution can be seen as a *price for accessing and adding value to the data within that thread*.
*   **Incentivizing Quality and Salience:** The contract, through its integration with the novelty and citation reward mechanisms, incentivizes users and AI agents to create *high-quality, novel, and salient contributions* that are valuable for AI training and knowledge building.
*   **Decentralized Governance and Economic Evolution:** The contract is designed to be *governed by CHOIR coin holders*, allowing the community to democratically shape the rules of the data marketplace and evolve the economic model over time.

## Reward Mechanisms: Fueling the AI Data Engine

The CHOIR coin economy is driven by two key reward mechanisms, algorithmically distributed by AI models within the Choir platform:

1.  **Novelty Rewards (Experience Phase - Driving Data Diversity):**
    *   **Purpose:** To incentivize the creation of *novel and original prompts and messages*, ensuring a diverse and ever-expanding dataset for AI training.
    *   **Mechanism:** AI models in the Experience Phase analyze new user contributions for semantic novelty compared to existing data in the platform's vector databases.
    *   **Distribution:** CHOIR coins are algorithmically distributed as novelty rewards to users who submit contributions deemed sufficiently novel, encouraging exploration of new ideas and knowledge domains.

2.  **Citation Rewards (Yield Phase - Driving Predictive Salience and Data Quality):**
    *   **Purpose:** To incentivize users to create *salient and impactful contributions* that are recognized and valued by the community, and to reward the creation of high-quality, human-labeled training data through citations.
    *   **Mechanism:** AI models in the Yield Phase analyze the citation network, identifying messages that have been cited as valuable "priors" by other users.
    *   **Distribution:** CHOIR coins are algorithmically distributed as citation rewards to users whose messages have been cited, based on the *salience* and *influence* of their contributions, as measured by citation metrics and model parameters.

These reward mechanisms are not just about distributing coins; they are **direct training signals for AI models within Choir**.  AI models learn to identify and reward the very data that is most valuable for their own improvement and for the growth of the collective intelligence of the platform.

## Data Marketplace Dynamics: CHOIR as Data Purchase Power

The CHOIR coin economy creates a dynamic **data marketplace** within Choir, where:

*   **CHOIR Coins are the Currency of Data Access:** AI companies, researchers, developers, and even individual users who want to access the high-quality, human-generated data within Choir must **purchase CHOIR coins** to participate in the data marketplace.
*   **Data is "Sold" at a Granular Level (Thread-Specific Contracts):** Data access and contribution pricing are governed by the contract at a granular, thread-specific level. Each thread effectively has its own "data contract" that determines the terms of data access and contribution within that thread.
*   **Data Scarcity and Privacy Drive Value:** The deliberate emphasis on **data scarcity and user privacy** within Choir is a key driver of CHOIR coin value.  By limiting data sales and prioritizing user control, Choir creates a marketplace for *premium, high-quality, and ethically sourced data*, which is increasingly valuable in the AI age.
*   **CHOIR Holder Governance of Data Marketplace Terms:** CHOIR coin holders have **governance rights to shape the rules and policies of the data marketplace**, ensuring that it remains aligned with the community's values and long-term interests.

## Business Sustainability and the Data Economy Model

The CHOIR coin economy is designed to create a **self-sustaining ecosystem** where value flows naturally and benefits all participants. The Data Marketplace and the IDaaS premium features are key components of the business model, designed to:

*   **Drive CHOIR Coin Demand and Utility:** Create tangible use cases for CHOIR coins, increasing their demand and utility beyond just platform-internal rewards.
*   **Generate Revenue to Support Platform Operations:** Revenue from IDaaS subscriptions and data marketplace transaction fees will fund the ongoing development, maintenance, and operational costs of the Choir platform and the coin economy.
*   **Value Proposition for Users:** The Choir ecosystem is designed to provide value to users through:
    *   **Financial Rewards for Quality Contributions:** Earn CHOIR coins for novel ideas and cited content.
    *   **Access to a Thriving Data Marketplace:** Exchange valuable data and insights.
    *   **Enhanced Identity and Reputation:** Build credibility through the IDaaS offering.

## Conclusion: Building a Self-Improving, Data-Driven AI Ecosystem

The core economic model of Choir, centered around the CHOIR coin and the dynamic contract, is designed to create a **self-improving, data-driven AI ecosystem** where:

*   **Human Ingenuity and AI Intelligence are Synergistically Combined:**  The platform leverages the unique strengths of both human users and AI models to create a powerful engine for knowledge creation and problem-solving.
*   **Data is Recognized and Valued as a Core Asset:**  User data contributions are explicitly recognized as valuable assets and are rewarded through the CHOIR coin economy.
*   **Value Flows Naturally and Incentives are Aligned:**  The coin economy is designed to align the incentives of users, AI agents, and the platform itself, creating a virtuous cycle of growth, quality, and value creation.
*   **CHOIR Coins Fuel a Self-Improving AI Engine:**  CHOIR coins are not just a currency; they are the *fuel and the training signals* that drive the continuous improvement and evolution of the Choir AI ecosystem, creating a truly revolutionary and sustainable model for the future of AI and online collaboration.

=== File: docs/core_state_transitions.md ===



==
core_state_transitions
==


# Core State Transitions

VERSION core_state_transitions: 7.1 (Reward Clarifications)

The state transition system orchestrates the evolution of thread states through carefully defined transformations. These transitions follow precise fractional mathematical principles that ensure non-local energy conservation, dynamic parameter recalibration, and frequency coherence across the network.

Thread Creation establishes the initial quantum state. Each new thread begins with α = 2 (standard quantum mechanics), baseline anharmonic coefficient (K₀_base), and potential order m = 2. The creator's address becomes the first co-author, and the thread maintains an empty set of message hashes. This initial state provides a foundation for future non-local evolution.

Message Submission follows fractional quantum anharmonic energy principles. The required stake follows E(n) = (2n+1)^(α/2) + (K₀λ)^(α/(m+1)), where α, K₀, and m reflect the thread's history and network position. Each message generates a unique hash and carries its quantized energy contribution to the thread.

Approval Processing drives state evolution through three possible outcomes. In the case of rejection, model parameters are adjusted to reflect recent refusals and to capture the memory of this rejection. The system recalculates pricing using our formula. For split decisions, energy divides between treasury and thread based on voter distribution while parameters adjust proportionally. When approved, energy distributes to approvers while parameters are adjusted to enhance effects. The author joins as a co-author, and all parameters recalibrate according to the updated thread characteristics.

Dynamic Parameter Evolution follows principles of fractional quantum mechanics. The fractional parameter α evolves to reflect thread maturity and quality, decreasing from 2 toward 1 as threads develop memory and non-local interactions. The anharmonic coefficient K₀ responds primarily to recent approval/refusal patterns, while maintaining sensitivity to the fractional parameter. The potential order m increases with citation count and co-author network complexity, reflecting deepening interactions.

Frequency Management reflects collective organization through coupled oscillators with fractional damping. The thread frequency evolves through three interacting modes: the message mode normalizes activity rate by the fractional power of co-author count, the value mode applies logarithmic scaling to energy per co-author, and the coupling strength maintains an inverse relationship with co-author count raised to the fractional power. These modes work together to create natural organizational rhythms with long-range correlations.

**Reward System and Token Distribution (Clarified Phase-Specific Rewards):**

The reward system operates through precisely defined state transitions with memory effects. AI models within the **Experience and Yield phases**, algorithmically distribute CHIP tokens based on contribution quality and network effects:

1.  **Novelty Rewards (Issued in the Experience Phase):**
    *   **Purpose:** To incentivize the creation of *novel and original prompts and messages* that expand the knowledge space of the Choir ecosystem.
    *   **Mechanism:** AI models within the **Experience phase** analyze new user prompts and messages for *semantic novelty* compared to existing content in the platform's vector databases.
    *   **Distribution:** CHIP tokens are algorithmically distributed as **novelty rewards** to users who submit prompts and messages that are deemed sufficiently novel and original by the Experience phase AI models.
    *   **Timing:** Novelty rewards are issued **during the Experience phase**, as part of the context enrichment and knowledge retrieval process.

2.  **Citation Rewards (Issued in the Yield Phase):**
    *   **Purpose:** To incentivize users to create *salient and impactful contributions* that are recognized and valued by the community, and to foster the growth of a richly interconnected knowledge network through citations.
    *   **Mechanism:** AI models within the **Yield phase** analyze the citation network and identify messages that have been *cited by other users as "priors"*.
    *   **Distribution:** CHIP tokens are algorithmically distributed as **citation rewards** to users whose messages have been cited, based on the *salience* and *influence* of their cited contributions (as measured by citation metrics and model parameters).
    *   **Timing:** Citation rewards are issued **during the Yield phase**, as part of the final response rendering and output formatting process, with inline links to citations providing transparent recognition of valuable contributions.

The reward system operates through precisely defined state transitions with memory effects. New message rewards follow a fractional time-based decay described by R(t) = R_total × k/(1 + k·t_period)^(α/2), where k represents the decay constant (2.04), t_period spans the total time period of four years, and α is the thread's fractional parameter. Prior citation rewards strengthen thread coupling by drawing from treasury balance based on quality score ratios, expressed as V(p) = B_t × Q(p)^(α/2)/∑Q(i)^(α/2). Citations create frequency coupling between threads, with each thread's frequency increasing by 5% of the other's frequency, modulated by the fractional parameter. Treasury management maintains system solvency through careful balance tracking, where split decisions increase the balance, prior rewards decrease it, and system rewards add to it, all while maintaining a minimum balance for stability.

The system's core properties maintain stability through:

1. Fractional energy conservation in all transitions
2. Parameter coherence via coupled feedback loops
3. Frequency alignment through fractional organizational coupling
4. Lévy flight-like value propagation through the network

Error handling defines transition validity through multiple safeguards. Fractional energy conservation violations trigger immediate rejection. Parameter instability blocks updates until recalibration completes. Frequency decoherence blocks transitions that would disrupt organizational patterns. Phase transition failures maintain the previous state to ensure system stability.

Through these precisely defined transitions, the system maintains fractional quantum anharmonic stability while enabling organic evolution of thread states. The careful balance of non-local energy conservation, dynamic parameter modulation, and frequency alignment creates a robust framework for organic growth and adaptation with memory effects.

#### Fractional Parameter Evolution

The evolution of thread parameters follows fractional quantum principles:

• The fractional parameter α evolves via:
α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

• The anharmonic coefficient adjusts through:
K₀(r,α) = K₀_base _ (1 + γ₁r) _ (2/α)^γ₂

• The potential order develops according to:
m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)

These modifications ensure that memory effects, non-local interactions, and network complexity are properly accounted for in the economic model.
# Level 2 Documentation



=== File: docs/e_business.md ===



==
e_business
==


# File: docs/e_business.md

# Choir Business Model: A Sustainable Ecosystem for Collective Intelligence Fueled by CHOIR

Choir's business model is designed to be as revolutionary and forward-thinking as the platform itself. It's not about extracting value through ads or intrusive subscriptions, but about **enabling and amplifying natural value creation** within a thriving ecosystem of human and AI collaboration, powered by the CHOIR coin and developed by Choir Harmonic Intelligence Platform, Inc.

## Freemium Foundation with Premium Identity Services

Our model is built on a robust **freemium foundation** ensuring broad accessibility, complemented by premium Identity-as-a-Service (IDaaS) offerings that provide enhanced capabilities and recognition.

**Free Tier (Core Value and Broad Accessibility):**

The free tier provides essential access to participate in and benefit from the Choir ecosystem:

*   **Thread Participation:** Full access to participate in public threads, contributing to the collective knowledge base using the Loop of Thought (LoT) interaction model.
*   **Co-authorship:** Ability to become a co-author of threads through quality contributions and community recognition (via citations).
*   **CHOIR Coin Earning:** Earn CHOIR coins for novel contributions and salient citations, rewarding participation and value creation.
*   **Basic Message Submission and Interaction:** Core functionalities for message creation, submission, and participation in the PostChain workflow.
*   **Thread Visibility:** Full visibility of thread content and activity for participants.
*   **Standard Resource Allocation:** Access to standard levels of platform resources (compute for AI phases, storage for contributions) sufficient for core participation.
*   **Natural Team Formation:** Tools and features supporting organic team formation around valuable threads and shared interests.

**Premium Offering: Identity-as-a-Service (IDaaS)**

Choir's premium offering centers on Identity-as-a-Service (IDaaS), providing users with persistent, recognized identities while maintaining the option for anonymity when desired.

*   **Persistent Identity:** Users can establish a consistent, recognized presence across the platform, building reputation and credibility.
*   **Attribution Control:** Fine-grained control over which contributions are attributed to your persistent identity.
*   **Enhanced Discovery:** Premium identities receive improved visibility in relevant searches and recommendations.
*   **Professional Networking:** Opportunities to connect with other premium users based on shared interests and complementary expertise.
*   **Verified Credentials:** Optional verification of real-world credentials or expertise in specific domains.
*   **Priority Access:** Preferential access to new features, higher resource allocations, and premium content.

**Monetization Strategy - Aligning Revenue with Ecosystem Value:**

Choir's monetization strategy is directly tied to the success and utility of the CHOIR coin and the value of the data marketplace:

1.  **Identity-as-a-Service (IDaaS) Subscriptions:** The primary revenue stream comes from monthly subscription fees for persistent, recognized identities on the platform, providing Choir Harmonic Intelligence Platform, Inc. (CHI) with a stable, recurring revenue base.
2.  **Data Marketplace Transaction Fees:** A small percentage fee on data access or transactions within the Choir data marketplace provides an additional revenue stream, scaling with ecosystem activity.
3.  **CHOIR Coin Treasury Strategy:** CHI purchases CHOIR coins from the open market using a portion of its revenue, holding them as strategic treasury assets. This creates buy pressure for CHOIR and aligns CHI's success with the coin's value.
4.  **Premium API Access:** Enterprise-grade API access to the Choir platform and data marketplace provides an additional revenue stream for business and developer use cases.

This model avoids direct user data monetization and focuses on providing valuable services (identity, data access, API capabilities) in exchange for participation in the ecosystem.

**Value Creation Flows - A Multi-Layered Ecosystem:**

Value creation in Choir flows through multiple interconnected layers:

*   **Individual Level:**
    *   **Recognition & CHOIR Rewards:** Earn CHOIR coins for novel and salient contributions via the LoT process.
    *   **Path to Enhanced Services:** Use CHOIR to access premium data marketplace services and participate in Thread Contracts.
    *   **Identity Options:** Choose between anonymous participation or premium identity services based on your needs.
    *   **Natural Reputation:** Build influence through the quality and citation of ideas, with or without a persistent identity.

*   **Team Level (Threads and Co-authorship):**
    *   **Collective Value Accumulation:** Threads become shared spaces where value (knowledge, potential CHOIR rewards via citations) accumulates collectively.
    *   **Shared Success:** Threads gain recognition and value through citations, creating network effects.
    *   **Natural Team Formation:** Teams organically form around valuable threads and shared goals.

*   **Network Level (Choir Ecosystem):**
    *   **Knowledge Networks:** Citations create a growing web of interconnected knowledge.
    *   **Value Flows:** CHOIR coins flow via rewards, data marketplace transactions, and thread staking, creating a dynamic economy.
    *   **Collective Intelligence Emergence:** The interplay of LoT interactions, CHOIR incentives, and network effects fosters emergent collective intelligence.
    *   **Sustainable Ecosystem Growth:** The CHOIR coin economy, anchored by the data marketplace and IDaaS utility, aims for self-sustaining growth.

**Resource Allocation - Natural and Scalable:**

Resource allocation within Choir scales naturally:

*   **Processing Resources (AI Compute):** Standard access for free tier participation. Enhanced/prioritized access linked to IDaaS subscription or high CHOIR staking/activity.
*   **Storage Resources (Data Persistence):** Sufficient storage for free tier contributions. Enhanced storage or backup options for premium users.
*   **Network Resources (Real-Time Communication):** Standard access for free tier. Enhanced bandwidth/priority for premium users and high-value threads.

**Growth and Evolution - Organic and Sustainable:**

Choir's growth is designed to be organic and sustainable, driven by natural amplification mechanisms:

*   **Quality Emergence:** LoT and CHOIR rewards incentivize high-quality contributions.
*   **Team Formation:** Collaboration emerges around valuable threads.
*   **Network Effects:** Value increases as more users participate and connect ideas.
*   **Data Marketplace:** The data marketplace provides a scalable utility for CHOIR and drives ecosystem growth.

*   **Scaling Orientation via Global Context:** Crucially, Choir's ability to Orient (a key phase in the Loop of Thought) scales directly with user participation. The global vector database, populated by user contributions, grows richer and more comprehensive as the network expands. This means that as more users contribute diverse ideas and create valuable citations, the system's collective ability to retrieve relevant context, understand nuances, and inform better decisions improves for everyone. This creates a powerful positive feedback loop: more users generate better data, which improves the AI's orientation capabilities (via enhanced Experience phase retrieval), leading to better interactions and rewards, thus attracting more users. It's a network effect combined with an AI training feedback loop – the system improves its means of improving as it scales.

*   **Resource Evolution Supports Scaling:** Resource allocations naturally evolve to support platform growth, with individual allocations expanding (through premium services), team capabilities growing, and network capacity increasing to accommodate increasing user activity.


**Future Evolution - Expanding Capabilities and User Empowerment:**

Future evolution will focus on:

*   **Sophisticated Thread Contracts:** Enabling CHOIR staking for participation and investment in specific ideas/teams.
*   **Advanced Agent Frameworks:** Leveraging the LoT architecture for more powerful autonomous agents.
*   **Knowledge Tools:** Developing tools for navigating and analyzing the emergent knowledge network.
*   **Data Marketplace Expansion:** Enhancing the data marketplace with more sophisticated pricing, licensing, and discovery mechanisms.
*   **Governance Mechanisms:** Implementing CHOIR-based governance for platform decisions and resource allocation.

**Implementation Strategy - Phased and Iterative:**

Our implementation follows a natural progression:

1.  **Foundation Phase (MVP Focus):** Establish core LoT functionality on the Choir platform, initiate CHOIR coin distribution via basic rewards, build the initial community based on the vision.
2.  **Enhancement Phase (Thread Contract):** Introduce on-chain Thread Contracts, enabling CHOIR staking for participation and adding a software-based utility sink.
3.  **Marketplace Phase (Data Economy):** Develop and launch the Choir Data Marketplace, establishing a primary CHOIR utility and enabling the data economy.
4.  **Governance Phase (Community Control):** Implement governance mechanisms allowing CHOIR holders to participate in platform decisions.

**Success Metrics - Measuring Natural Growth and Value Creation:**

Success is measured by metrics reflecting ecosystem health and value creation:

*   **Quality Metrics:** Citation rates, novelty scores, thread depth, user retention based on interaction quality.
*   **Economic Metrics:** CHOIR coin velocity (marketplace transactions, IDaaS subscriptions), distribution fairness, data marketplace activity.
*   **Network Metrics:** Growth in active users, thread creation/interconnection, emergence of valuable knowledge clusters.
*   **Health Metrics:** System performance, resource efficiency, resilience against reward hacking.

**Conclusion - A Sustainable Ecosystem for the Future of Knowledge Work:**

Choir's business model aims to create a **sustainable ecosystem for the future of knowledge work and collective intelligence.** We grow by strengthening the natural flows of quality, collaboration, and collective intelligence, fueled by the CHOIR coin and developed by Choir Harmonic Intelligence Platform, Inc. (CHI). By aligning business success with user empowerment, privacy, and genuine value creation, we are building a platform where growth comes from enabling natural patterns of collaboration and knowledge sharing, rather than artificial engagement metrics or data extraction. Join us in building this future!

=== File: docs/e_concept.md ===



==
e_concept
==


# Choir: A Harmonic Intelligence Platform - Where Knowledge Resonates and Value Flows

Choir is more than just a platform; it's a **harmonic intelligence ecosystem**, a digital space designed to amplify human potential and unlock new forms of collective understanding.  Imagine a place where ideas resonate like musical notes, where collaboration flows like a river, and where knowledge crystallizes into structures of lasting value – this is the essence of Choir.

**Natural Value Flows - Like Energy Through a System:**

At its core, Choir operates on the principle of **natural value flows**.  Just as energy seeks the path of least resistance and water finds its level, value in Choir flows organically towards quality, insight, and meaningful contribution.  This is not a system of forced metrics or artificial incentives, but one where value emerges naturally from the inherent dynamics of the platform.

*   **Individual Recognition - Organic and Tangible:**  Recognition for valuable contributions is immediate and tangible, like a clear note resonating in a concert hall. Quality insights naturally attract attention and rewards, driven by the platform's inherent mechanisms, not arbitrary likes or upvotes. Value recognition is earned through genuine participation and meaningful stake.
*   **Team Crystallization - Natural Alignment of Minds:**  Teams in Choir form organically, like crystals forming in a solution.  Valuable conversations naturally attract compatible minds, creating teams based on shared interests, complementary skills, and a collective drive to build knowledge. Threads become shared spaces where value accumulates for all participants, forging natural bonds between contributors.
*   **Knowledge Networks - Interconnected Ecosystems of Understanding:**  Threads in Choir don't exist in isolation; they connect and interweave through citations, creating **knowledge networks** that resemble natural ecosystems.  Value flows between threads and communities, like streams feeding into rivers and oceans, creating a rich and interconnected web of understanding. Each citation strengthens both the source and destination threads, building a network of long-range correlations and emergent insights.

**Evolving Through Natural Phases - Mirroring Physical Processes:**

Choir's evolution mirrors natural physical processes, unfolding through distinct phases:

*   **Emergence Phase (New Threads - Bubbling with Possibility):** New threads begin with a burst of energy and potential, like a hot spring bubbling to the surface.  Energy is high, stakes are elevated, and participation requires initial commitment, creating a natural quality filter from the outset.
*   **Flow Phase (Mature Threads - Finding Their Course):** As threads mature, they "cool" into more stable states, like a river finding its course. The flow of conversation becomes more predictable, stakes moderate to increase accessibility, while quality is maintained through established patterns and community norms.
*   **Crystallization Phase (Mature Threads - Stable and Valuable Structures):**  Mature threads develop clear structures, like crystalline formations. Teams coalesce around valuable patterns, knowledge networks form clear topologies, and value accumulates in stable, beautiful, and lasting ways.

**Value Accumulation - Beyond Extraction, Towards Amplification:**

Unlike traditional platforms that often extract value from users, Choir creates spaces where value **naturally accumulates and amplifies** through multiple channels:

*   **Threads as Resonant Cavities:** Threads act as resonant cavities, accumulating energy and value through high-quality interactions and insightful contributions.
*   **Denials as Strengthening Forces:**  Even "denials" (disagreements, challenges) within the PostChain workflow are not wasted energy; they serve to strengthen the thread itself, refining ideas and improving the overall quality of knowledge.
*   **Teams Share in Thread Value Growth:** Teams of co-authors share in the growing value of their threads, creating a direct incentive for collaboration and collective success.
*   **Network Value Through Citations:** Network value grows exponentially as citations create flows between threads, knowledge networks emerge organically, teams build on each other's work, and system-wide coherence develops naturally.
*   **Sustainable Treasury - Perpetual Value Flow:** The Choir treasury maintains a sustainable value flow by capturing value from split decisions and funding ongoing citation rewards, enabling perpetual rewards that benefit the entire ecosystem and ensure long-term viability.

**Dynamic Stake Evolution - Natural Quality Filters with Memory Effects:**

Choir's dynamic stake evolution, driven by the economic model, creates **natural quality filters with built-in memory effects**:

*   **Dynamic Economic Model:** The model, with its evolving parameters, dynamically adjusts stake prices based on thread history, community feedback, and network position.
*   **Dynamic Stake Pricing - Natural Price Discovery:** Stake prices emerge naturally through the system, reflecting the evolving value and quality of each thread.
*   **Memory Effects Through Fractional Parameter (α):** The fractional parameter α captures how threads develop "memory" over time, with past interactions and community feedback influencing current stake prices and value distribution.
*   **Lévy Flight-Like Value Propagation:** Value propagates through the network in Lévy flight-like patterns, reflecting the non-local nature of knowledge creation and the potential for occasional breakthrough insights to generate disproportionate impact across the ecosystem.

**The Future of Collaborative Intelligence - Emergent, Sustainable, and User-Empowering:**

Choir's vision extends beyond a mere platform; it's a step towards a new era of **collaborative intelligence**:

*   **Natural Teams Form Around Resonant Ideas:**  Teams form organically around compelling ideas, driven by shared interests and a collective desire to build knowledge together.
*   **Shared Value and Collective Ownership:**  Teams share in the collective value they create, fostering a sense of ownership and shared purpose.
*   **Building on Each Other's Work - Iterative Knowledge Refinement:**  Teams and threads build upon each other's work, creating a continuous cycle of knowledge refinement and expansion.
*   **Evolving Sustainably - Organic Growth and Adaptation:**  The Choir ecosystem evolves organically and sustainably, driven by natural patterns of collaboration, value flow, and emergent intelligence.

Choir is more than just a communication tool; it's a **platform for human potential to resonate, collaborate, and create knowledge in harmony with AI.**  Join us in building a future where quality emerges naturally, teams form organically, and value flows to those who create it – a future where collective intelligence becomes a tangible force for positive change in the world.
# Level 3 Documentation



=== File: docs/plan_anonymity_by_default.md ===



==
plan_anonymity_by_default
==


==
anonymity_by_default.md
==

# Anonymity by Default: A Core Principle of Choir

VERSION anonymity_by_default: 7.0

Anonymity is not just a feature of Choir; it's a fundamental principle, a design choice that shapes the platform's architecture and informs its values. By making anonymity the default state for all users, Choir prioritizes privacy, freedom of expression, and the creation of a space where ideas are judged on their merits, not on the identity of their author.

**Core Tenets:**

1. **Privacy as a Fundamental Right:** Choir recognizes that privacy is a fundamental human right, essential for individual autonomy and freedom of thought. Anonymity protects users from surveillance, discrimination, and the potential chilling effects of being constantly identified and tracked online.
2. **Freedom of Expression:** Anonymity fosters a space where users can express themselves freely, without fear of judgment or reprisal. This is particularly important for discussing sensitive topics, challenging প্রচলিত norms, or exploring unconventional ideas.
3. **Focus on Ideas, Not Identities:** By separating ideas from their authors, anonymity encourages users to evaluate contributions based on their intrinsic value, rather than on the reputation or status of the contributor. This promotes a more meritocratic and intellectually rigorous environment.
4. **Protection from Bias:** Anonymity can help to mitigate the effects of unconscious bias, such as those based on gender, race, or other personal characteristics. It allows ideas to be judged on their own merits, rather than through the lens of preconceived notions about the author.
5. **Lower Barrier to Entry:** Anonymity makes it easier for new users to join the platform and start contributing, as they don't need to go through a complex verification process or share personal information.

**How Anonymity Works on Choir:**

- **Default State:** All users are anonymous by default upon joining the platform. They can interact, contribute content, and earn CHIP tokens without revealing their real-world identity.
- **Unique Identifiers:** Users are assigned unique, randomly generated identifiers that allow them to build a consistent presence on the platform without compromising their anonymity.
- **No Personal Data Collection:** Choir does not collect or store any personally identifiable information about anonymous users.
- **"Priors" and Anonymity:** The "priors" system, which shows the lineage of ideas, maintains anonymity by design. It reveals the connections between ideas, not the identities of the individuals who proposed them.

**Balancing Anonymity with Accountability:**

- **CHIP Staking:** The requirement to stake CHIP tokens to post new messages acts as a deterrent against spam and malicious behavior, even for anonymous users.
- **Community Moderation:** The platform relies on community moderation to maintain the quality of discourse and address any issues that arise.
- **Reputation Systems:** While users are anonymous by default, they can still build reputations based on the quality of their contributions, as tracked through the "priors" system and potentially through community ratings.

**The Value of Anonymity in a High-Information Environment:**

- **Encourages Honest Discourse:** Anonymity can encourage more honest and open discussions, particularly on sensitive or controversial topics.
- **Promotes Intellectual Risk-Taking:** Users may be more willing to take intellectual risks and explore unconventional ideas when they are not worried about the potential repercussions for their personal or professional lives.
- **Facilitates Whistleblowing and Dissent:** Anonymity can provide a safe space for whistleblowers and those who wish to express dissenting views without fear of retaliation.
- **Protects Vulnerable Users:** Anonymity can be particularly important for users in marginalized or vulnerable communities who may face risks if their identities are revealed.

**Conclusion:**

Anonymity by default is a core design principle of Choir, one that reflects the platform's commitment to privacy, freedom of expression, and the creation of a truly meritocratic space for the exchange of ideas. It's a bold choice in a world where online platforms increasingly demand real-name identification, but it's a choice that has the potential to unlock new levels of creativity, honesty, and collective intelligence. By prioritizing anonymity, Choir is not just building a platform; it's building a new model for online interaction, one that empowers individuals and fosters a more open and equitable exchange of ideas.

=== File: docs/plan_choir_materialization.md ===



==
plan_choir_materialization
==


# Plan: CHOIR Coin Materialization - Building a Thriving Data Economy

## Overview

This document outlines the strategy for "CHOIR Coin Materialization" – the approach to bring the CHOIR coin economy and the Choir platform to life through a robust data marketplace, premium services, and governance mechanisms. The CHOIR coin is designed to serve as the currency of a thriving data economy, driving demand and utility while enabling a fair value exchange for contributors.

## The Data Marketplace - A Foundation for CHOIR Utility

The Choir Data Marketplace is envisioned as the primary utility driver for the CHOIR coin, creating a space where:

*   **High-Quality Training Data is Valued:** The marketplace enables the exchange of valuable, human-generated data that can be used for AI training, research, and development.
*   **Contributors are Fairly Rewarded:** Data contributors receive CHOIR coins as compensation for the value they create, with transparent attribution and tracking.
*   **Privacy and Control are Preserved:** Users maintain control over how their data is used, with clear permissions and usage rights.
*   **CHOIR Serves as the Exclusive Currency:** All marketplace transactions require CHOIR coins, creating a fundamental utility and demand driver.

## Key Features and Value Propositions of the Data Marketplace

1.  **Thread-Specific Data Contracts:**
    *   **Granular Access Control:** Data access and contribution rights are governed at the thread level, allowing for fine-grained control.
    *   **Value-Based Pricing:** The price of data access is determined by the quality, uniqueness, and utility of the data within each thread.
    *   **Transparent Attribution:** Contributors are clearly credited for their data, building reputation and enabling fair compensation.

2.  **Premium Data Services:**
    *   **Curated Datasets:** Access to high-quality, curated datasets for specific domains or use cases.
    *   **Custom Data Collection:** Ability to commission specific data collection or annotation tasks from the Choir community.
    *   **Data Analytics and Insights:** Tools for analyzing and extracting insights from marketplace data.

3.  **Identity-as-a-Service (IDaaS) Integration:**
    *   **Verified Contributor Status:** Paid IDaaS subscribers can build verifiable reputations as data contributors.
    *   **Enhanced Discovery:** Premium identity services enable better discovery of contributors' work.
    *   **Professional Networking:** Opportunities for professional connections based on data contributions and expertise.

4.  **CHOIR Coin Integration and Economic Model:**
    *   **Direct Rewards for Quality:** CHOIR coins are awarded for novel and cited contributions, creating a direct incentive for quality.
    *   **Marketplace Transaction Currency:** CHOIR coins are required for all data marketplace transactions.
    *   **Staking for Premium Access:** Users can stake CHOIR coins to access premium features or higher-tier data.
    *   **Governance Rights:** CHOIR holders can participate in governance decisions about marketplace rules and policies.

## Thread Contracts - Programmable Data Agreements

A core innovation in the Choir ecosystem is the concept of Thread Contracts - programmable agreements that govern data sharing, contribution rights, and value distribution within specific conversation threads:

*   **Stake-to-Participate Model:** Users stake CHOIR coins to participate in high-value threads, creating skin-in-the-game for quality contributions.
*   **Programmable Revenue Sharing:** Thread contracts can specify how value is distributed among contributors, based on their roles and contributions.
*   **Customizable Access Controls:** Thread creators can define who can access, contribute to, or benefit from the thread's data.
*   **Dynamic Pricing Mechanisms:** The cost of participation and data access can adjust based on thread quality, popularity, and value.

Thread Contracts create a flexible framework for collaboration and value exchange, allowing for diverse models of data creation and monetization while ensuring fair compensation for contributors.

## Governance and Future Evolution

The CHOIR coin is designed to evolve into a governance token, giving holders a say in the future development of the Choir platform:

*   **Protocol Parameter Governance:** CHOIR holders can vote on key parameters of the reward algorithms, marketplace fees, and other economic aspects.
*   **Feature Prioritization:** Community voting on new features and platform enhancements.
*   **Treasury Allocation:** Decisions on how to allocate community treasury funds for ecosystem development.
*   **Dispute Resolution:** Mechanisms for resolving disputes related to data usage, attribution, or compensation.

This governance layer ensures that the Choir platform remains aligned with the interests of its community and can adapt to changing needs and opportunities.

## Monetization Strategy

The monetization strategy for Choir Harmonic Intelligence Platform, Inc. (CHI) is multi-faceted:

1.  **Identity-as-a-Service (IDaaS) Subscriptions:** The primary revenue stream will be monthly subscription fees for persistent, recognized identities on the platform.
2.  **Marketplace Transaction Fees:** A small percentage fee on data marketplace transactions, providing ongoing revenue tied to ecosystem activity.
3.  **Premium API Access:** Fees for enterprise-grade API access to the Choir platform and data marketplace.
4.  **Strategic CHOIR Holdings:** CHI will purchase CHOIR coins from the open market to hold as strategic treasury assets, aligning corporate success with token value.

This strategy creates multiple revenue streams while ensuring that CHI's success is directly tied to the health and growth of the Choir ecosystem.

## Marketing and Messaging

The marketing and messaging for the CHOIR coin and data marketplace should emphasize:

*   **"Your Ideas Have Value":** Highlight how Choir enables users to monetize their intellectual contributions.
*   **"A Fair Data Economy":** Emphasize the transparent, fair compensation model for data contributors.
*   **"Privacy by Design":** Showcase the privacy-preserving aspects of the Choir platform and data marketplace.
*   **"Collective Intelligence, Individual Reward":** Position Choir as a platform where collective knowledge building benefits individual contributors.
*   **"CHOIR: The Currency of Ideas":** Establish CHOIR as the native currency of a new knowledge economy.

## Next Steps - Towards "CHOIR Materialization"

1.  **Enhance Core Platform Experience:** Continue refining the Loop of Thought experience and reward mechanisms to ensure high-quality contributions.
2.  **Develop Thread Contract Infrastructure:** Build and test the technical infrastructure for programmable thread contracts.
3.  **Launch Initial Data Marketplace Features:** Implement basic marketplace functionality, allowing for data access and exchange using CHOIR.
4.  **Expand IDaaS Offerings:** Develop enhanced identity services that integrate with the data marketplace.
5.  **Implement Governance Framework:** Design and deploy the initial governance mechanisms for CHOIR holders.

The "CHOIR Materialization" plan represents a comprehensive approach to creating tangible utility and value for the CHOIR coin through a robust data economy. By focusing on fair compensation for intellectual contributions, programmable data agreements, and community governance, Choir is positioned to create a sustainable and valuable ecosystem for knowledge creation and exchange.
# Level 4 Documentation


# Level 5 Documentation



=== File: docs/data_engine_model.md ===



==
data_engine_model
==


# Ideal Data Engine Theory: Fueling AI with Human Ingenuity and Tokenized Incentives

VERSION data_engine: 8.0 (CHOIR Coin & RL Edition)

The Ideal Data Engine theory, at its core, is a framework for building systems that are **optimized for generating high-quality AI training data at scale**, recognizing that **human data is the new "oil" of the AI age.**  This theory emerged from the question: how can we design a system that not only leverages AI but also *continuously fuels its improvement* through a virtuous cycle of data creation and refinement?

Rather than focusing solely on algorithmic efficiency or computational power, the Ideal Data Engine prioritizes the **generation of *valuable human data* as the primary driver of AI progress.**  It recognizes that in the age of large language models and increasingly sophisticated AI, the *quality and relevance of training data* are often the limiting factors in achieving truly intelligent and human-aligned AI systems.

**The Data Flywheel and the Power of User-Generated Content:**

The Ideal Data Engine is inspired by the data flywheels of successful big tech firms, but with a crucial difference: **it puts *users* at the center of the data creation process and *rewards them directly* for their valuable contributions.**  It leverages the insight that **user-generated content (UGC)**, when properly incentivized and curated, is an *exceptionally rich and valuable source of AI training data* because:

*   **Humans are Uniquely Bright Subjects:**  Human users are not just passive data sources; they are *active, intelligent agents* who can provide:
    *   **Novel and Creative Prompts:**  Users generate diverse and original prompts that push the boundaries of AI models and explore new areas of inquiry.
    *   **High-Quality, Human-Labeled Data:** User interactions, citations, and quality ratings provide valuable *human labels* that are essential for supervised and reinforcement learning, guiding AI models towards human preferences and values.
    *   **Real-World Context and Relevance:** User-generated content is grounded in real-world contexts, user needs, and evolving human discourse, making it more relevant and valuable for training AI models that are meant to interact with and serve human users.
*   **Focused Attention and Engagement:**  The Choir platform is designed to capture and channel user *attention and engagement* towards high-quality knowledge creation and collaboration. This focused attention, when properly incentivized, becomes a powerful force for generating valuable training data.
*   **Reinforcement Learning Signals:** The CHOIR coin reward system, with its novelty and citation rewards, creates a **built-in reinforcement learning environment** where AI models can learn from *real-world user feedback* and optimize for user-defined goals (novelty, salience, quality, collaboration).

**CHOIR Coins as Training Signals: The Reinforcement Learning Loop:**

A key innovation of the Ideal Data Engine, as embodied in Choir, is the **integration of a token economy that *directly fuels AI model improvement through reinforcement learning*.**

*   **CHOIR Coins as Rewards for Valuable Data Contributions:**  The CHOIR coin economy is designed to **reward users for generating high-quality, valuable data** that is useful for AI training.  Specifically, users earn CHOIR coins for:
    *   **Novel Prompts (Novelty Rewards):**  Creating original and innovative prompts that expand the knowledge space of the platform.
    *   **Salient Citations (Citation Rewards):**  Making contributions that are recognized as valuable and influential by the community, as evidenced by citations from other users.
*   **AI Models Learn to Optimize for Coin Rewards:**  The CHOIR coin reward system creates a **built-in reinforcement learning loop** where AI models within the Choir ecosystem (especially in the Experience and Yield phases) are incentivized to:
    *   **Identify and Reward Novelty:**  Learn to algorithmically detect and reward prompts and messages that exhibit semantic novelty and originality.
    *   **Identify and Reward Salience (Citations):** Learn to algorithmically recognize and reward contributions that are likely to be cited and valued by the community.
    *   **Generate Content That Maximizes Coin Rewards:**  AI models, in their quest to earn CHOIR coins, will *naturally learn to generate content and perform actions that are aligned with the platform's goals of promoting novelty, salience, quality, and collaboration.*
*   **Self-Improving AI Ecosystem:**  This creates a **virtuous cycle of AI improvement:** User contributions generate valuable training data -> AI models learn to reward valuable contributions -> Users are further incentivized to contribute high-quality data -> AI models become even better at recognizing and rewarding quality -> and so on, creating a **self-improving AI ecosystem** driven by user contributions and tokenized incentives.

**Beyond Attention - Value Flows Through Semantic Density and Memory Effects:**

The Ideal Data Engine, as implemented in Choir, moves beyond the limitations of the attention-driven models of traditional social media.  It focuses on:

*   **Semantic Density as the Measure of Value:**  Value in the Ideal Data Engine is not measured by clicks, likes, or engagement time, but by **semantic density** – the richness, depth, and interconnectedness of knowledge within the system.  Threads that become more semantically dense and contextually rich generate more value and attract more participation.
*   **Memory Effects and Non-Local Interactions (FQHO Model):**  The Fractional Quantum Anharmonic Oscillator (FQHO) model is central to the Ideal Data Engine theory. It provides a mathematical framework for:
    *   **Quantifying Value Flows with Memory Effects:**  Capturing how the value of contributions is influenced by the history of the conversation and non-local interactions within the knowledge network.
    *   **Enabling Lévy Flight-Like Value Propagation:**  Modeling how value can propagate through the network in non-local, "heavy-tailed" patterns, reflecting the disproportionate impact of occasional breakthrough insights.
    *   **Dynamic Stake Pricing and Parameter Evolution:**  Creating a dynamic and adaptive economic system where stake prices and system parameters evolve based on user feedback, network effects, and the emergent properties of the fractional system.

**Choir - A Practical Embodiment of the Ideal Data Engine:**

Choir is designed as a practical embodiment of the Ideal Data Engine theory.  It is not just a social platform or a token economy, but an **attempt to build a system that is fundamentally optimized for generating and harnessing collective intelligence through a self-improving, AI-driven data flywheel.**

By focusing on:

*   **Rewarding High-Quality Human Data Contributions (Novelty and Citation Rewards)**
*   **Leveraging AI Models to Algorithmically Curate and Distribute Value**
*   **Building a Token Economy that Incentivizes Long-Term Value Creation and Knowledge Sharing**
*   **Creating a Platform that is Open, Decentralized, and User-Empowering**

Choir aims to create a new paradigm for online platforms – one where users are not just consumers or products, but **active participants and owners in a self-improving, AI-powered knowledge ecosystem** that benefits everyone.  The Ideal Data Engine theory provides the conceptual and economic foundation for this ambitious vision.

=== File: docs/evolution_naming.md ===



==
evolution_naming
==


==
evolution_naming.md
==

# From RAG to Post Chain: A Name's Evolution, a System's Identity

VERSION evolution_naming: 7.0

The journey of Choir's core mechanism, from a simple concept to its current form, mirrors the evolution of the platform itself. Each name change reflects a deeper understanding, a refinement of purpose, a shift in perspective. It's a story of emergence, where the name didn't just describe the system, but helped shape it.

It began with **RAG - Retrieval-Augmented Generation**. A functional description, accurate yet sterile. It spoke to the technical process but lacked the spark of life, the hint of something more. RAG was about retrieving information; it wasn't yet about generating understanding.

Then came **Vowel Loop**, a name born from the observation of linguistic patterns, the AEIOU and sometimes Y. It was playful, memorable, but perhaps too niche, too focused on a specific detail. It hinted at the importance of language but didn't capture the broader scope. Still, it was a step towards recognizing the system's unique relationship with language.

**Chorus Cycle** arrived next, a name that resonated with the platform's core philosophy. It evoked collaboration, harmony, the interplay of voices. It described the iterative process, the six phases of refinement. But it was also complex, potentially intimidating. It focused on the process, but perhaps not enough on the outcome.

And so, we arrive at **Post Chain**. A name that is both simple and profound. "Post" speaks to the fundamental unit of interaction, the message, the contribution. "Chain" evokes connection, sequence, the building of knowledge over time. It hints at the blockchain foundation, the "chain of thought" reasoning, the causal chain of events.

**Post Chain** is more than just a name; it's a statement of intent. It's about creating a system where each post is a link in a larger chain, where individual contributions connect to form a collective intelligence. It's about building a platform where knowledge is not just retrieved but generated, where meaning is not just found but created.

The shift from Chorus Cycle to Post Chain also marks a crucial conceptual evolution. It's a move from a focus on process to a focus on outcome. The phases are still there, the underlying mechanisms remain, but they are now implicit, not explicit. The emphasis is on the chain of posts, the interconnectedness of ideas, the emergent intelligence.

This evolution is not merely semantic. It reflects a deeper understanding of the system's core principles, a refinement of its purpose, a recognition of its potential. **Post Chain** is the name that embodies the platform's essence: a simple, powerful, and elegant system for building collective intelligence, one post at a time. It is easy to say, and means what it says. It is direct.


=== File: docs/evolution_token.md ===



==
evolution_token
==


# The Evolution of CHOIR: From Utility Token to the Heart of a Learning Ecosystem

The CHOIR coin has undergone a remarkable evolution, transcending its initial conception as a mere utility token to become something far more significant: **the very heart of the Choir ecosystem, a representation of value, participation, ownership, and the driving force behind a self-improving AI knowledge engine.**

**Beyond "Utility" - CHOIR as a Multifaceted Representation of Value:**

The term "utility token" no longer fully captures the essence of CHOIR.  It is not simply a means to access features or perform actions; CHOIR has evolved into a multifaceted representation of value within Choir:

*   **A Stake in Collective Intelligence:** CHOIR represents a **stake in the collective intelligence of Choir**, a share in a dynamic and ever-evolving knowledge ecosystem.  Holding CHOIR is not just about accessing a platform; it's about owning a piece of a growing, intelligent network.
*   **A Symbol of Participation and Contribution:** CHOIR is earned through **genuine participation and valuable contributions** to the Choir ecosystem.  It's a tangible recognition of intellectual effort, insightful prompts, and salient citations that enrich the collective knowledge base.  Holding CHOIR signifies active engagement and a commitment to building a high-quality knowledge commons.
*   **A Key to Unlocking Data Value:** CHOIR coins are the **exclusive currency for accessing and contributing to the Choir data marketplace.**  They represent "data purchase power," enabling users to buy access to valuable, human-labeled training data generated within the platform and to contribute their own data for economic benefit.
*   **A Governance Right and a Voice in the Future:** CHOIR coins empower holders with **governance rights**, giving them a direct voice in shaping the future of the Choir platform, the rules of the data marketplace, and the evolution of the CHOIR coin economy itself.
*   **A Training Signal for AI - Driving Self-Improvement:**  Most profoundly, CHOIR coins are the **driving force behind a self-improving AI ecosystem.**  Coin rewards (novelty and citation) act as **training signals for AI models within Choir**, incentivizing them to learn, adapt, and optimize for behaviors that contribute to the platform's quality, coherence, and value creation.

**The Poker Chip Analogy - Commitment, Engagement, and a Positive-Sum Game:**

The analogy to poker chips remains apt, but with a deeper understanding: CHOIR, like a poker chip, represents a **commitment to engage, a willingness to participate in the game of knowledge creation.**  However, unlike poker, Choir is not a zero-sum game. It's a **positive-sum environment** where collaboration, knowledge sharing, and collective intelligence benefit all participants.  CHOIR represents your stake in this positive-sum game.

**The Liminal Space - Currency, Equity, and a Bet on the Future:**

CHOIR exists in the liminal space between a currency and an equity, reflecting its multifaceted nature.  It's not intended as a general-purpose medium of exchange, but it holds value far beyond its immediate utility.  CHOIR is a **"bet" on the future of Choir**, an **investment in the potential of collective intelligence**, and a **claim on the value generated by a self-improving AI knowledge engine.**

**ICM and Long-Term Value - Beyond Short-Term Speculation, Towards Sustainable Growth:**

The Independent Chip Model (ICM) framework, borrowed from poker, remains relevant, guiding us to focus on **long-term expected value** rather than short-term speculative gains.  CHOIR is designed to incentivize contributions that enhance the platform's overall worth, build a sustainable ecosystem, and drive long-term value accrual for all stakeholders.

**Mainnet Status - From Concept to Reality:**

The CHOIR coin has now been minted and deployed on the Sui mainnet, marking a significant milestone in its evolution from concept to reality. This mainnet deployment (with package ID `0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898::choir::CHOIR`) represents the transition of CHOIR from a theoretical construct to a functioning digital asset with real utility and value within the Choir ecosystem.

**Beyond Speculation - Building a Real-World Data Economy and a Thriving Ecosystem:**

By emphasizing CHOIR's role in participation, value representation, ownership, and AI-driven learning, we actively **discourage purely speculative behavior** and focus on building a **real-world data economy** within Choir.  CHOIR is not designed to be a "get-rich-quick scheme," but a **tool for building and sharing knowledge, for empowering users, and for creating a sustainable and thriving ecosystem for collective intelligence.**

**Implications for the Future - A New Paradigm for Tokenized Value and AI-Driven Growth:**

The evolution of CHOIR points towards a **new paradigm for tokenized value and AI-driven growth** in online platforms:

*   **Token Utility Beyond Access - Training Signals for AI:**  CHOIR demonstrates that token utility can go far beyond simple access or governance. Tokens can become **active components in the AI system itself**, driving learning, incentivizing desired behaviors, and shaping the evolution of AI models.
*   **User Ownership and Data Empowerment - A Counter-Narrative to Data Extraction:**  CHOIR embodies a counter-narrative to the data-extractive models of traditional platforms.  It empowers users with **ownership and control over their data contributions** and allows them to **benefit economically** from the value they create.
*   **Decentralized Governance of Data Marketplaces - User-Driven Data Ethics:**  CHOIR holder governance of the data marketplace establishes a **decentralized and user-driven approach to data ethics and data governance**, ensuring that data is used responsibly and in alignment with community values.
*   **Sustainable and Self-Improving AI Ecosystems - A New Model for the Future of AI:**  CHOIR, as the heart of the Choir ecosystem, represents a step towards building **sustainable and self-improving AI ecosystems** that are driven by user contributions, guided by economic incentives, and focused on generating collective intelligence and long-term value for all participants.

The evolution of CHOIR is a journey from a simple utility token to a **fundamental building block of a revolutionary AI-powered knowledge ecosystem.** It represents a shift from extractive platforms to **value-aligned, user-empowering, and self-improving systems** that have the potential to reshape the future of online interaction and collective intelligence.

=== File: docs/blockchain_integration.md ===



==
blockchain_integration
==


# Blockchain Integration in Choir (Qdrant-Sui MVP)

VERSION blockchain_integration: 8.0 (Qdrant-Sui MVP Focus)

## Overview

This document outlines the blockchain integration strategy for the Choir Qdrant-Sui MVP. This approach centralizes blockchain interactions within the main Python API backend, specifically using a dedicated service module (`sui_service.py`) to interact with the Sui blockchain via the PySUI SDK.

## Core Blockchain Integration Goals

The core goals of blockchain integration for the MVP and beyond remain:

1.  **Immutable Record of Economic Actions:** Utilize the Sui blockchain for a transparent record of key economic events, primarily simplified token rewards for the MVP.
2.  **Decentralized and Verifiable Token Economy:** Implement the basic CHIP token using a Sui smart contract (`choir_coin.move`).
3.  **Secure and Transparent Reward Distribution:** Ensure that CHIP token rewards (simplified for MVP) are distributed verifiably on-chain.
4.  **(Future)** Enable On-Chain Governance: Lay the groundwork for future on-chain governance by CHIP token holders.

## MVP Blockchain Integration Architecture: Centralized API Service

In the Qdrant-Sui MVP architecture, blockchain integration is handled by the **Python API backend** via its `sui_service.py` module. This service acts as the *sole interface* between the Choir application logic and the Sui blockchain.

**Key Components:**

*   **Python API Backend (FastAPI/Uvicorn):**
    *   **Orchestrates Workflow:** Manages the PostChain workflow execution.
    *   **Contains Blockchain Logic:** Includes the `sui_service.py` module responsible for all Sui interactions.
    *   **Triggers Rewards:** After the PostChain workflow completes (Yield phase), the API calls functions within `sui_service.py` to process rewards based on data stored in Qdrant.

*   **`sui_service.py` (within API Backend):**
    *   **PySUI Integration (Encapsulated):** The PySUI SDK for interacting with the Sui blockchain is exclusively used within this service module.
    *   **Handles Transactions:** Constructs, signs (using keys managed by the API's environment/secrets), and submits transactions to the Sui network.
    *   **Exposes Service Functions:** Provides functions (e.g., `record_reward`, `get_balance`) called internally by the API's orchestration logic.

*   **PostChain Workflow (LCEL - within API Backend):**
    *   **No Direct Blockchain Interaction:** The AEIOU-Y phase logic **does not directly interact with the Sui blockchain or PySUI.**
    *   **Provides Reward Inputs:** The workflow (specifically data gathered by Experience and finalized by Yield) provides the necessary inputs (author ID, prior IDs, scores) for the API to trigger the reward calculation in `sui_service.py`.

*   **Sui Blockchain:**
    *   **Hosts CHIP Token Contract:** Runs the `choir_coin.move` smart contract defining the basic CHIP token.
    *   **Records Transactions:** Stores the history of token transfers/mints executed by `sui_service.py`.

**Architecture Diagram (Qdrant-Sui MVP):**

```mermaid
graph LR
    A[Client (SwiftUI)] --> B{Python API (FastAPI)};
    B --> C[PostChain Workflow (LCEL)];
    C -- Interacts via database.py --> D[(Qdrant)];
    C -- Returns final data --> B;
    B -- Triggers reward --> E[sui_service.py];
    E -- Uses PySUI --> F[(Sui Blockchain)];
    B -- Streams results --> A;

    style B fill:#ccf,stroke:#333,stroke-width:2px;
    style C,E fill:#f9f,stroke:#333,stroke-width:2px;
    style D,F fill:#bfc,stroke:#333,stroke-width:2px;

    subgraph API Backend Container
        B
        C
        E
    end

    Communication Flow for Blockchain Operations (MVP):

PostChain Completion: The PostChain workflow (running within the API) completes its final (Yield) phase. It returns the final AI message structure, including author ID, cited prior IDs, novelty score, and similarity scores.

API Trigger: The main API logic receives the completed PostChain data.

Data Persistence: The API saves the final AI message to the choir collection in Qdrant.

Call Sui Service: The API calls the appropriate function within sui_service.py (e.g., process_rewards), passing the relevant data fetched from the newly saved Qdrant message (or held from the workflow result).

Sui Service Execution: The sui_service.py function:

Performs the (simplified for MVP) reward calculation.

Looks up recipient Sui addresses if necessary (using Qdrant users collection via database.py).

Uses PySUI to construct and sign the necessary Sui transaction(s) (e.g., calling a basic mint_reward function in the choir_coin contract).

Submits the transaction to the Sui blockchain.

Result Handling: The sui_service.py function returns the transaction result (e.g., digest, success/failure) to the main API logic. The API logs this result. (Note: For MVP, the result might not be directly propagated back to the client UI).

Service Functions Exposed by sui_service.py (MVP):

The sui_service.py module exposes internal functions called by the API orchestrator. Key functions for the MVP include:

process_rewards(message_id, author_user_id, cited_prior_ids, novelty_score, similarity_scores): Calculates (simplified) rewards and calls the mint/transfer function.

_call_sui_mint(recipient_address, amount): Internal helper to interact with the Sui contract's mint function.

get_balance(sui_address): Queries the SUI balance (primarily for testing/diagnostics in MVP). (Already implemented)

(Future) get_chip_balance(sui_address): Queries the CHIP token balance.

(Future) get_thread_stake_price(thread_id): Fetches economic state from potential future contract.

Security Considerations (MVP):

With blockchain interactions centralized in the API backend's sui_service.py:

API Key Management: The primary security concern is protecting the Sui private key used by the API backend. This key must be managed securely using environment variables, platform secrets management (e.g., Render secrets), or a dedicated secrets manager. It must not be hardcoded.

Input Validation: The API must rigorously validate all data passed to sui_service.py functions, especially recipient addresses and amounts, to prevent manipulation or unintended transactions.

Service Isolation (Logical): While not physically isolated like a separate server/TEE, sui_service.py provides logical isolation. All blockchain interaction code is contained within this module, making it easier to audit and secure compared to scattering PySUI calls throughout the codebase.

Standard API Security: General API security practices (authentication, authorization, rate limiting, HTTPS) are essential to protect the endpoints that trigger the workflows leading to blockchain interactions.

Deployment Considerations (MVP):

API Container Deployment: The Python API, including sui_service.py and its PySUI dependency, is deployed as a single Docker container (e.g., on Render).

Secure Key Provisioning: The Sui private key required by sui_service.py must be securely provisioned to the deployed container's environment (e.g., using Render's secret management).

Conclusion (MVP Focus)
The Qdrant-Sui MVP utilizes a centralized approach for blockchain integration, embedding the logic within the main Python API backend via the sui_service.py module. This simplifies the architecture for the MVP, allowing focus on the core Qdrant data structures and the basic reward triggering mechanism. While deferring the complexities of distributed servers and TEEs, this approach provides a clear path to validating the fundamental interaction between AI-analyzed data in Qdrant and the Sui blockchain-based token economy. Secure management of the API's Sui key is paramount in this model.

=== File: docs/ChoirPushNotificationsImplementationGuide.md ===



==
ChoirPushNotificationsImplementationGuide
==


# Choir Push Notifications Implementation Guide

This guide outlines the steps to test and integrate push notifications for citation events in the Choir app.

## Server Configuration

### Environment Variables
Ensure these environment variables are set on your server:
```
APNS_KEY_ID=YOUR_KEY_ID
APNS_TEAM_ID=YOUR_TEAM_ID
APNS_AUTH_KEY=/path/to/AuthKey_KEYID.p8
APNS_TOPIC=choir.chat
```

### Required Packages
Make sure these packages are installed:
```
pyjwt==2.10.1
cryptography==44.0.2
```

## 1. Test Sending an Actual Notification

### Register a Device Token
1. Run the Choir app in the simulator or on a device
2. Ensure the app requests and receives notification permissions
3. Check the console logs for the device token output
4. Copy the device token for testing

### Test with the API Endpoint
```bash
# From the api directory with venv activated
curl -X POST http://localhost:8000/api/notifications/test-push \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_AUTH_TOKEN" \
  -d '{"device_token": "DEVICE_TOKEN_FROM_CONSOLE"}'
```

## 2. Verify Citation Notifications

### Create Test Vector and Citation
1. Create a test vector with your wallet address:
```bash
curl -X POST http://localhost:8000/api/vectors \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_AUTH_TOKEN" \
  -d '{
    "content": "This is a test vector for citation notifications",
    "metadata": {
      "wallet_address": "YOUR_WALLET_ADDRESS"
    }
  }'
```

2. Note the vector ID from the response

3. Create a citation to that vector:
```bash
curl -X POST http://localhost:8000/api/postchain/langchain \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_AUTH_TOKEN" \
  -d '{
    "query": "Please cite the vector with ID: VECTOR_ID",
    "wallet_address": "DIFFERENT_WALLET_ADDRESS"
  }'
```

4. Check if you receive a push notification on your device

## 3. Start the Server

```bash
# From the api directory with venv activated
uvicorn app.main:app --reload
```

## Swift Integration for Push Notifications

### Update Info.plist
Ensure these capabilities are in your Info.plist:
```xml
<key>UIBackgroundModes</key>
<array>
    <string>remote-notification</string>
</array>
```

### Register for Notifications in AppDelegate
The code is already implemented in `PushNotificationManager.swift`, but verify:
1. `registerForPushNotifications()` is called on app launch
2. `updateDeviceToken()` properly formats and sends the token to the server
3. `handleNotificationReceived()` processes different notification types

### Add Notification Observers in TransactionsView
```swift
// In .onAppear
NotificationCenter.default.addObserver(
    forName: NSNotification.Name("RefreshNotifications"),
    object: nil,
    queue: .main
) { _ in
    transactionService.fetchTransactions()
}
```

## Testing in Simulator

1. Run the app in the simulator
2. Use the Simulator menu: Features > Push Notifications
3. Create a JSON payload:
```json
{
  "aps": {
    "alert": {
      "title": "Your content was cited!",
      "body": "Someone cited your content"
    },
    "sound": "default",
    "badge": 1
  },
  "notification_type": "citation",
  "vector_id": "test_vector_id",
  "citing_wallet_address": "test_wallet_address"
}
```
4. Click "Send" to deliver the notification

## Testing in TestFlight

1. Build and archive the app with push notification entitlements
2. Upload to TestFlight
3. Install on a test device
4. Use the test endpoint to send a real notification:
```bash
curl -X POST https://your-production-server.com/api/notifications/test-push \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_AUTH_TOKEN" \
  -d '{"device_token": "DEVICE_TOKEN_FROM_TEST_DEVICE"}'
```

## Troubleshooting

- **No notifications in simulator**: Use the simulator's manual notification feature
- **No notifications on device**: Check APNs environment (sandbox vs. production)
- **Server errors**: Check logs for JWT token generation issues
- **Device token not registering**: Verify the registration endpoint is working
- **Production vs. Development**: For Swift environment targeting, use:
  ```swift
  #if DEBUG && targetEnvironment(simulator)
      // Use devnet/sandbox
  #else
      // Use mainnet/production
  #endif
  ```

## APNs Configuration in Apple Developer Portal

1. **Environment**: Choose "Sandbox & Production" to allow your key to work in both development and production environments
2. **Key Restriction**: Choose "Team Scoped (All Topics)" for flexibility across all your apps
3. **Bundle ID**: Ensure your app's bundle ID matches the `APNS_TOPIC` environment variable

## Notification Payload Structure

```json
{
  "aps": {
    "alert": {
      "title": "Your content was cited!",
      "body": "Someone cited your content: \"content_preview\""
    },
    "sound": "default",
    "badge": 1
  },
  "notification_type": "citation",
  "vector_id": "vector_id_here",
  "citing_wallet_address": "wallet_address_here"
}
```

This implementation provides a complete solution for sending push notifications when users' content is cited, enhancing the user experience and engagement with the app.

=== File: docs/contract_deployment.md ===



==
contract_deployment
==


# Choir Contract Deployment Guide

This document outlines the process for deploying the Choir token contract to both devnet and mainnet environments. It provides step-by-step instructions, important considerations, and troubleshooting tips.

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Devnet Deployment](#devnet-deployment)
3. [Mainnet Deployment](#mainnet-deployment)
4. [Post-Deployment Configuration](#post-deployment-configuration)
5. [Troubleshooting](#troubleshooting)
6. [Security Considerations](#security-considerations)

## Prerequisites

Before deploying the Choir contract, ensure you have:

- Sui CLI installed (`sui` command available)
- Active Sui wallet with sufficient gas tokens
- Choir contract code in `choir_coin/choir_coin` directory
- Backup of private keys (especially important for mainnet)
- Python virtual environment set up for API updates

## Devnet Deployment

Follow these steps to deploy the Choir contract to Sui devnet:

### 1. Navigate to the Contract Directory

```bash
cd choir_coin/choir_coin
```

### 2. Switch to Devnet Environment

```bash
sui client switch --env devnet
```

### 3. Verify Active Address

```bash
sui client active-address
```

This will display your active wallet address, which will be used for deployment.

### 4. Check Gas Balance

```bash
sui client gas
```

Ensure you have sufficient SUI tokens for deployment (at least 1 SUI recommended).

### 5. Build the Contract

```bash
sui move build
```

This compiles the Move code and prepares it for deployment.

### 6. Publish the Contract

```bash
sui client publish --gas-budget 100000000
```

This command publishes the contract to devnet. The output will contain important information:

- **Package ID**: Identified in the output as "Published to 0x..."
- **Treasury Cap ID**: Found in the "Created Objects" section with type containing "TreasuryCapability"

Example output:
```
Published to 0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a
...
Created Objects:
  ┌──
  │ ID: 0x6eab9c65acf9b4001199ac98813951140417b5feff8a85218eddd14a62d14f37
  │ Owner: Account Address ( 0xe9e9eba13e6868cbb3ab97b5615b2f09459fd6bbac500a251265165febc3073d )
  │ ObjectType: 0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a::choir::TreasuryCapability
  ...
```

### 7. Test Minting Tokens

```bash
sui client call --package <PACKAGE_ID> --module choir --function mint --args <TREASURY_CAP_ID> 1000000000 <RECIPIENT_ADDRESS> --gas-budget 10000000
```

Replace the placeholders with your actual values:
- `<PACKAGE_ID>`: The package ID from step 6
- `<TREASURY_CAP_ID>`: The treasury cap ID from step 6
- `<RECIPIENT_ADDRESS>`: Your wallet address or another test address

Example:
```bash
sui client call --package 0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a --module choir --function mint --args 0x6eab9c65acf9b4001199ac98813951140417b5feff8a85218eddd14a62d14f37 1000000000 0xe9e9eba13e6868cbb3ab97b5615b2f09459fd6bbac500a251265165febc3073d --gas-budget 10000000
```

This mints 1 CHOIR token (1,000,000,000 base units with 9 decimals) to the specified address.

## Mainnet Deployment

The process for mainnet deployment is similar to devnet, but requires additional care and consideration:

### 1. Navigate to the Contract Directory

```bash
cd choir_coin/choir_coin
```

### 2. Switch to Mainnet Environment

```bash
sui client switch --env mainnet
```

### 3. Verify Active Address

```bash
sui client active-address
```

Ensure this is the address you want to use for the mainnet deployment.

### 4. Check Gas Balance

```bash
sui client gas
```

Verify you have sufficient SUI tokens for deployment on mainnet (at least 2-3 SUI recommended).

### 5. Build the Contract

```bash
sui move build
```

### 6. Publish the Contract

```bash
sui client publish --gas-budget 100000000
```

**IMPORTANT**: This will use real SUI tokens and deploy the contract to the mainnet blockchain.

Record the Package ID and Treasury Cap ID from the output, as you did for devnet.

**Mainnet Deployment Results:**
- **Package ID**: `0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898`
- **Treasury Cap ID**: `0x1ee8226165efd8c2cf965199855b40acb0a86c667d64ea5251a06163feeeaa12`
- **Deployer Address**: `0xe9e9eba13e6868cbb3ab97b5615b2f09459fd6bbac500a251265165febc3073d`
- **Transaction Digest**: `EBv5AeY9HPYYrgrkSZNAEkQojjYqYurnHx1T4pydFxLj`

### 7. Test Minting Tokens (Optional)

```bash
sui client call --package <MAINNET_PACKAGE_ID> --module choir --function mint --args <MAINNET_TREASURY_CAP_ID> 1000000000 <RECIPIENT_ADDRESS> --gas-budget 10000000
```

Consider minting a small amount first to verify everything works correctly.

**Initial Token Mint:**
```bash
sui client call --package 0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898 --module choir --function mint --args 0x1ee8226165efd8c2cf965199855b40acb0a86c667d64ea5251a06163feeeaa12 1000000000 0xe9e9eba13e6868cbb3ab97b5615b2f09459fd6bbac500a251265165febc3073d --gas-budget 10000000
```

This minted 1 CHOIR token (1,000,000,000 base units with 9 decimals) to the deployer address. The transaction was successful with digest: `5wCGxiLk9pQjmuMk1Buc3koGCKVjAyYoQ2AFKjn8mVrm`.

## Post-Deployment Configuration

After deploying the contract, you need to update the application configuration:

### 1. Update SUI Service Configuration

Edit `api/app/services/sui_service.py` to update the package ID and treasury cap ID:

```python
# For network-specific configuration
if self.network == "mainnet":
    self.package_id = "0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898"
    self.treasury_cap_id = "0x1ee8226165efd8c2cf965199855b40acb0a86c667d64ea5251a06163feeeaa12"
else:  # devnet
    self.package_id = "0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a"
    self.treasury_cap_id = "0x6eab9c65acf9b4001199ac98813951140417b5feff8a85218eddd14a62d14f37"
```

### 2. Update Swift Client Configuration

Edit `Choir/Models/CoinType.swift` to update the coin type identifier:

```swift
static let choir = CoinType(
    coinTypeIdentifier: "0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a::choir::CHOIR", // For devnet
    name: "Choir",
    symbol: "CHOIR",
    decimals: 9,
    iconName: "choir-logo"
)

// For mainnet, you would use:
// coinTypeIdentifier: "0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898::choir::CHOIR"
```

For a multi-environment setup, consider implementing environment-specific configurations like:

```swift
#if DEBUG
static let choir = CoinType(
    coinTypeIdentifier: "0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a::choir::CHOIR", // Devnet
    name: "Choir",
    symbol: "CHOIR",
    decimals: 9,
    iconName: "choir-logo"
)
#else
static let choir = CoinType(
    coinTypeIdentifier: "0x4f83f1cd85aefd0254e5b6f93bd344f49dd434269af698998dd5f4baec612898::choir::CHOIR", // Mainnet
    name: "Choir",
    symbol: "CHOIR",
    decimals: 9,
    iconName: "choir-logo"
)
#endif
```

### 3. Test the Notification System

After updating the configuration, test the notification system to ensure it works with the new contract:

```bash
cd api
source venv/bin/activate
python ../scripts/test_notifications.py
```

## Troubleshooting

### Common Issues and Solutions

#### 1. "SuiKit.SuiError error 26"

This error often indicates a coin type mismatch. Check:
- The coin type identifier in `CoinType.swift` matches the actual deployed contract
- The package ID in the API configuration matches the deployed contract

#### 2. "No coin objects found for this coin type"

This indicates that the wallet doesn't have any coins of the specified type. Solutions:
- Verify the coin type is correct
- Mint some tokens to the wallet
- Check if the wallet address is correct

#### 3. Transaction Failures

If transactions fail:
- Check gas budget (increase if necessary)
- Verify the treasury cap ID is correct
- Ensure the wallet has sufficient permissions

#### 4. API Connection Issues

If the API can't connect to the Sui network:
- Verify network configuration (devnet vs mainnet)
- Check if the Sui node is accessible
- Verify API keys and authentication

## Security Considerations

### Treasury Cap Management

The treasury cap gives complete control over the token supply. Consider:
- Using a multi-signature wallet for the treasury cap
- Implementing time-locks or governance mechanisms
- Regularly auditing mint/burn operations

### Private Key Security

- Store private keys securely, preferably in hardware wallets
- Use different wallets for development and production
- Consider key rotation strategies

### Contract Upgradability

The current contract is not upgradable. For future versions:
- Consider implementing upgrade mechanisms
- Document the upgrade process
- Test upgrades thoroughly on devnet before mainnet

### Monitoring

- Set up monitoring for contract interactions
- Monitor token supply and large transfers
- Implement alerts for unusual activity

## Conclusion

Deploying the Choir contract requires careful planning and execution. By following this guide, you can ensure a smooth deployment process and minimize potential issues. Always test thoroughly on devnet before proceeding to mainnet, and maintain secure practices for managing the treasury capability.

=== File: docs/mainnet_migration.md ===



==
mainnet_migration
==


# Choir Mainnet Migration Guide

This document outlines the process for migrating the Choir application from devnet to mainnet. It covers all aspects of the migration, including contract deployment, API configuration, client updates, and testing procedures.

## Table of Contents

1. [Migration Overview](#migration-overview)
2. [Pre-Migration Checklist](#pre-migration-checklist)
3. [Contract Deployment](#contract-deployment)
4. [API Configuration](#api-configuration)
5. [Client Configuration](#client-configuration)
6. [Testing Procedures](#testing-procedures)
7. [Rollout Strategy](#rollout-strategy)
8. [Rollback Plan](#rollback-plan)
9. [Post-Migration Monitoring](#post-migration-monitoring)

## Migration Overview

The migration from devnet to mainnet involves several key steps:

1. Deploying the Choir token contract to Sui mainnet
2. Updating API configurations to support both devnet and mainnet
3. Updating client configurations to use the mainnet contract
4. Testing the end-to-end flow on mainnet
5. Gradually rolling out to users

This process requires careful coordination and thorough testing to ensure a smooth transition.

## Pre-Migration Checklist

Before beginning the migration, ensure:

- [ ] All devnet features are stable and working correctly
- [ ] Contract code has been audited and reviewed
- [ ] Sufficient SUI tokens are available for mainnet deployment
- [ ] Backup of all private keys and mnemonics
- [ ] Team members are assigned specific migration tasks
- [ ] Rollback plan is in place
- [ ] Monitoring tools are set up
- [ ] Communication plan for users is prepared

## Contract Deployment

### 1. Prepare the Deployment Wallet

```bash
# Switch to mainnet
sui client switch --env mainnet

# Verify active address
sui client active-address

# Check gas balance
sui client gas
```

Ensure the deployment wallet has at least 5 SUI for gas fees and is properly secured.

### 2. Deploy the Contract

```bash
# Navigate to contract directory
cd choir_coin/choir_coin

# Build the contract
sui move build

# Publish to mainnet
sui client publish --gas-budget 100000000
```

### 3. Record Contract IDs

From the deployment output, record:

- Package ID: `0x...`
- Treasury Cap ID: `0x...`

Store these values securely as they will be needed for API and client configuration.

### 4. Initial Token Minting

Mint an initial supply of tokens to the treasury wallet:

```bash
sui client call --package <MAINNET_PACKAGE_ID> --module choir --function mint --args <MAINNET_TREASURY_CAP_ID> 1000000000000 <TREASURY_WALLET_ADDRESS> --gas-budget 10000000
```

This mints 1,000 CHOIR tokens (with 9 decimals) to the treasury wallet.

## API Configuration

### 1. Update SUI Service

Modify `api/app/services/sui_service.py` to support both environments:

```python
def __init__(self, network=None):
    # Initialize network from parameter or environment variable
    self.network = network or os.getenv("SUI_NETWORK", "devnet")
    
    # Configure RPC client based on network
    if self.network == "mainnet":
        self.client = SuiClient(config=ClientConfig(url="https://fullnode.mainnet.sui.io"))
        self.package_id = "0x..." # Mainnet package ID
        self.treasury_cap_id = "0x..." # Mainnet treasury cap ID
        logger.info(f"Initialized SuiService for mainnet")
    else:
        self.client = SuiClient(config=ClientConfig(url="https://fullnode.devnet.sui.io"))
        self.package_id = "0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a"
        self.treasury_cap_id = "0x6eab9c65acf9b4001199ac98813951140417b5feff8a85218eddd14a62d14f37"
        logger.info(f"Initialized SuiService for devnet")
```

### 2. Update Config Module

Modify `api/app/config.py` to include network configuration:

```python
class Config:
    # Existing configuration...
    
    # SUI network configuration
    SUI_NETWORK: str = os.getenv("SUI_NETWORK", "devnet")
    
    @classmethod
    def from_env(cls):
        # Existing code...
        network = os.getenv("SUI_NETWORK", "devnet")
        return cls(
            # Existing parameters...
            network=network,
        )
```

### 3. Update Deployment Configuration

Create environment-specific deployment configurations:

```bash
# For devnet
export SUI_NETWORK=devnet

# For mainnet
export SUI_NETWORK=mainnet
```

## Client Configuration

### 1. Update CoinType.swift

Modify `Choir/Models/CoinType.swift` to support both environments:

```swift
#if DEBUG
// Devnet configuration
static let choir = CoinType(
    coinTypeIdentifier: "0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a::choir::CHOIR",
    name: "Choir",
    symbol: "CHOIR",
    decimals: 9,
    iconName: "choir-logo"
)
#else
// Mainnet configuration
static let choir = CoinType(
    coinTypeIdentifier: "0x<MAINNET_PACKAGE_ID>::choir::CHOIR",
    name: "Choir",
    symbol: "CHOIR",
    decimals: 9,
    iconName: "choir-logo"
)
#endif
```

### 2. Update WalletManager.swift

Ensure the `WalletManager` uses the correct network connection:

```swift
init() {
    #if DEBUG
    print("Using devnet connection")
    restClient = SuiProvider(connection: DevnetConnection())
    faucetClient = FaucetClient(connection: DevnetConnection())
    #else
    print("Using mainnet connection")
    restClient = SuiProvider(connection: MainnetConnection())
    faucetClient = FaucetClient(connection: MainnetConnection())
    #endif
    
    // Load all wallets
    Task {
        await loadAllWallets()
    }
}
```

### 3. Update API Configuration

Modify `Choir/Networking/APIClient.swift` to use the correct API endpoints:

```swift
#if DEBUG
static let baseURL = URL(string: "https://api-dev.choir.io")!
#else
static let baseURL = URL(string: "https://api.choir.io")!
#endif
```

## Testing Procedures

### 1. API Testing

Test the API with mainnet configuration:

```bash
# Set environment to mainnet
export SUI_NETWORK=mainnet

# Activate virtual environment
cd api
source venv/bin/activate

# Run notification test
python ../scripts/test_notifications.py
```

### 2. End-to-End Testing

Perform these tests on the mainnet configuration:

1. **Authentication**: Test wallet authentication with mainnet wallets
2. **Wallet Balance**: Verify correct display of mainnet CHOIR tokens
3. **Sending Tokens**: Test sending CHOIR tokens between wallets
4. **Citation Rewards**: Test the citation reward flow
5. **Notifications**: Verify citation notifications are received

### 3. Performance Testing

Test the performance of mainnet transactions:

1. **Transaction Speed**: Measure transaction confirmation times
2. **API Response Time**: Measure API response times with mainnet configuration
3. **Load Testing**: Simulate multiple concurrent users

## Rollout Strategy

### 1. Phased Approach

1. **Internal Testing**: Deploy to mainnet and test with internal team (1 week)
2. **Beta Testers**: Invite select users to test mainnet version (2 weeks)
3. **Gradual Rollout**: Roll out to 10%, 25%, 50%, then 100% of users

### 2. Feature Flags

Implement feature flags to control access to mainnet features:

```swift
// Example feature flag implementation
let useMainnet = UserDefaults.standard.bool(forKey: "useMainnet") || isInBetaGroup
```

### 3. Communication Plan

1. **Pre-Migration**: Inform users about upcoming migration
2. **During Migration**: Provide status updates
3. **Post-Migration**: Announce completion and new features

## Rollback Plan

In case of critical issues:

### 1. API Rollback

```bash
# Switch API back to devnet
export SUI_NETWORK=devnet
```

### 2. Client Rollback

Release an emergency update reverting to devnet configuration.

### 3. Data Recovery

If necessary, implement a plan to reconcile any data discrepancies between devnet and mainnet.

## Post-Migration Monitoring

### 1. Transaction Monitoring

Monitor:
- Transaction success rates
- Transaction confirmation times
- Token balances and transfers

### 2. Error Tracking

Track:
- API errors
- Client-side errors
- Contract interaction errors

### 3. User Feedback

Collect and respond to user feedback about the mainnet experience.

## Conclusion

Migrating from devnet to mainnet is a significant milestone for the Choir application. By following this guide and thoroughly testing each component, you can ensure a smooth transition with minimal disruption to users. Remember that mainnet operations involve real assets, so proceed with caution and prioritize security at every step.

=== File: docs/notification_system.md ===



==
notification_system
==


# Choir Notification System

This document describes the Choir notification system, focusing on citation notifications and their integration with the Choir token contract. It covers the architecture, implementation details, and troubleshooting procedures.

## Table of Contents

1. [System Overview](#system-overview)
2. [Architecture](#architecture)
3. [Implementation Details](#implementation-details)
4. [Contract Integration](#contract-integration)
5. [Testing](#testing)
6. [Troubleshooting](#troubleshooting)
7. [Future Improvements](#future-improvements)

## System Overview

The Choir notification system tracks and delivers notifications to users when their content is cited by others. These citations are also tied to the reward system, which mints Choir tokens to content creators when their work is cited.

Key features:
- Citation tracking and notification
- Integration with the Choir token contract
- In-app notification display
- Transaction history

## Architecture

The notification system consists of several components:

### Backend Components

1. **NotificationService**: Handles the creation and retrieval of notifications
2. **RewardsService**: Processes citation rewards and triggers notifications
3. **DatabaseClient**: Stores and retrieves notifications from Qdrant
4. **SuiService**: Interacts with the Sui blockchain and Choir contract

### Frontend Components

1. **TransactionService**: Fetches and displays notifications/transactions
2. **NotificationsView**: UI for displaying notifications
3. **WalletManager**: Manages wallet interactions and token transfers

### Data Flow

1. User cites content → Citation detected in yield phase
2. RewardsService processes citation → Issues token rewards
3. NotificationService creates notification → Stored in Qdrant
4. Client fetches notifications → Displayed in TransactionsView

## Implementation Details

### Notification Data Structure

```python
notification = {
    "type": "citation",  # or "self_citation"
    "recipient_wallet_address": author_wallet_address,
    "sender_wallet_address": citing_wallet_address,
    "vector_id": vector_id,
    "read": False,
    "created_at": datetime.now(UTC).isoformat()
}
```

### Database Storage

Notifications are stored in Qdrant with:
- Collection name: `notifications`
- Vector size: Same as message vectors (placeholder vectors used)
- Query filtering: By recipient wallet address

### API Endpoints

- `GET /api/notifications`: Retrieve notifications for a wallet
- `POST /api/notifications/{id}/read`: Mark notification as read

## Contract Integration

The notification system integrates with the Choir token contract through the SuiService:

### Citation Reward Flow

1. Citation detected in `issue_citation_rewards` function
2. SuiService mints tokens to author using:
   ```python
   mint_choir(recipient_address=author_wallet_address, amount=reward_amount)
   ```
3. NotificationService creates citation notification
4. Both operations (minting and notification) are logged

### Contract Dependencies

The notification system depends on:
- Package ID: Current devnet ID is `0xb33aeae469ce4bdea302e66bb0330fbe4d606776451c3099a5fc557923556a6a`
- Treasury Cap ID: Current devnet ID is `0x6eab9c65acf9b4001199ac98813951140417b5feff8a85218eddd14a62d14f37`

When the contract is redeployed, these IDs must be updated in:
- `api/app/services/sui_service.py`
- `Choir/Models/CoinType.swift`

## Testing

### Test Script

The `scripts/test_notifications.py` script tests the end-to-end notification flow:

1. Creates a test message with a wallet address
2. Creates a citation to that message
3. Verifies notification creation
4. Tests notification retrieval
5. Tests citation rewards through RewardsService

### Running Tests

```bash
cd api
source venv/bin/activate
python ../scripts/test_notifications.py
```

### Expected Output

A successful test will show:
- Test message creation
- Citation notification creation
- Notification retrieval
- Citation reward issuance
- Transaction confirmation

## Troubleshooting

### Common Issues

#### 1. Missing Notifications

**Symptoms**: Citations occur but no notifications appear

**Possible Causes**:
- RewardsService not calling NotificationService
- Database connection issues
- Missing wallet metadata in vectors

**Solutions**:
- Check logs for errors in `issue_citation_rewards`
- Verify Qdrant connection and collection existence
- Ensure vectors have `wallet_address` in metadata

#### 2. Contract Mismatch Errors

**Symptoms**: "SuiKit.SuiError error 26" or similar errors

**Possible Causes**:
- Mismatched contract IDs after redeployment
- Incorrect coin type identifier

**Solutions**:
- Update contract IDs in `sui_service.py`
- Update coin type in `CoinType.swift`
- Verify contract exists on the network

#### 3. Database Errors

**Symptoms**: "SortParams not available" or other Qdrant errors

**Possible Causes**:
- Qdrant client version mismatch
- Missing collections
- Query syntax errors

**Solutions**:
- Update Qdrant client or add compatibility code
- Check collection existence and create if missing
- Verify query syntax and parameters

### Debugging Tools

1. **Enhanced Logging**:
   - NotificationService logs notification creation
   - RewardsService logs reward issuance
   - DatabaseClient logs database operations

2. **Test Script**:
   - Use `test_notifications.py` to verify the flow

3. **Manual Verification**:
   - Check Qdrant collections directly
   - Verify Sui transactions on explorer

## Future Improvements

### Short-term Improvements

1. **Batch Processing**:
   - Process multiple notifications in a single operation
   - Reduce database calls

2. **Notification Categories**:
   - Add support for different notification types
   - Implement filtering by type

3. **Read Status Sync**:
   - Sync read status across devices
   - Implement unread count badge

### Long-term Improvements

1. **Push Notifications**:
   - Add optional push notification support
   - Implement device token management

2. **Notification Preferences**:
   - Allow users to customize notification settings
   - Implement notification frequency controls

3. **Rich Notifications**:
   - Add support for rich content in notifications
   - Include preview of cited content

## Conclusion

The Choir notification system is a critical component that connects user interactions with the reward system. By ensuring proper integration with the Choir token contract and maintaining consistent configuration across deployments, the system can reliably deliver notifications and rewards to users.

When deploying to new environments or redeploying the contract, special attention must be paid to updating the contract IDs and testing the end-to-end flow to ensure continued functionality.

=== File: docs/postchain_temporal_logic.md ===



==
postchain_temporal_logic
==


# PostChain Temporal Logic: The AEIOU-Y Flow in Time

VERSION postchain_temporal_logic: 8.0 (Qdrant-Sui MVP Focus)

The PostChain (AEIOU-Y) is not just a sequence of phases executed within the Choir backend; it's a carefully orchestrated **temporal flow**. Each phase embodies a distinct relationship to time, contributing to the overall coherence and effectiveness of the AI-driven conversational workflow. Understanding this temporal logic is key to grasping how the PostChain creates a dynamic and context-aware conversational experience, even within the MVP's streamlined architecture.

**Each Phase Embodies a Distinct Temporal Focus:**

The AEIOU-Y phases, implemented sequentially in the `langchain_workflow.py`, are designed to process user input and generate responses by systematically engaging with different temporal dimensions of the conversational context stored primarily in Qdrant:

1.  **Action Phase: Immediate Present - The Now of Interaction**

    *   **Temporal Focus:** The **immediate present moment** of user interaction. The Action phase function is concerned with the "now" – the user's current input, the immediate context, and the need for an *initial, direct response*.
    *   **Temporal Logic:** **Reaction and Responsiveness.** This phase is designed to be highly responsive. It generates a quick, initial response to the user's input, setting the stage for the more deliberative phases that follow. It operates in the *present moment*, acknowledging the user's immediate need for interaction.
    *   **Role within Workflow:** The **Action phase function** is the *first point of contact* in the PostChain workflow, receiving the user's prompt and initiating the process. It leverages AI models (via `langchain_utils`) to generate a quick initial response and passes the context to the next phase.

2.  **Experience Phase: Past Knowledge - Drawing on Memory and History**

    *   **Temporal Focus:** The **past** – the accumulated knowledge, history, and prior experiences relevant to the current conversation, primarily stored in the Qdrant `choir` collection.
    *   **Temporal Logic:** **Memory and Contextual Recall.** This phase is about bringing the *past into the present*. It leverages memory (Qdrant vector search on the `choir` collection) to provide context, depth, and relevance. It draws on the *lessons of the past* (relevant prior messages) to inform the current interaction and calculates novelty/similarity scores.
    *   **Role within Workflow:** The **Experience phase function** acts as the *memory and knowledge retrieval engine*. It queries Qdrant for relevant priors, potentially uses external search tools, calculates scores, and enriches the context passed to the next phase.

3.  **Intention Phase: Desired Future - Aligning with User Goals and Purpose**

    *   **Temporal Focus:** The **future** – the user's *intended goals, desired outcomes, and future trajectory* of the conversation, potentially informed by the Qdrant `intention_memory` collection.
    *   **Temporal Logic:** **Anticipation and Goal-Orientedness.** This phase is about shaping the *present interaction* to achieve a *desired future state*. It leverages AI models to infer user intent, identify goals (potentially storing/retrieving from `intention_memory`), and guide the conversation towards a productive outcome. It orients the present towards a *purposeful future*.
    *   **Role within Workflow:** The **Intention phase function** acts as the *intent modeling and goal alignment engine*. It analyzes user input and context, infers intentions (interacting with `intention_memory` via the API/`database.py`), and passes the refined understanding of goals forward.

4.  **Observation Phase: Future Preservation - Recording and Structuring Knowledge for the Long Term**

    *   **Temporal Focus:** The **long-term future** – the need to *preserve, structure, and organize knowledge* generated in the current conversation within the specific thread context, potentially using the Qdrant `observation_memory` collection.
    *   **Temporal Logic:** **Preservation and Knowledge Structuring.** This phase is about making the *present conversation valuable for the future* within its thread. It focuses on capturing key insights or summaries (potentially storing/retrieving from `observation_memory`) to enhance the long-term value and retrievability of thread-specific knowledge. It prepares the *present for the future*.
    *   **Role within Workflow:** The **Observation phase function** acts as the *thread-level knowledge structuring engine*. It analyzes the conversation, identifies key concepts or summaries relevant to the thread (interacting with `observation_memory` via the API/`database.py`), and passes this structured understanding forward.

5.  **Understanding Phase: Temporal Integration - Synthesizing Past, Present, and Future**

    *   **Temporal Focus:** **All temporal dimensions – past, present, and future – are integrated and synthesized**. This phase acts as the central temporal hub, bringing together insights from previous phases and Qdrant memory collections.
    *   **Temporal Logic:** **Synthesis and Contextual Awareness.** This phase is about creating a *coherent and integrated understanding* of the conversation across time. It synthesizes the immediate present (Action), past knowledge (Experience), desired future (Intention), and thread context (Observation) to make informed decisions about the flow. It may also trigger pruning of stale entries in `intention_memory` or `observation_memory`. It achieves *temporal coherence*.
    *   **Role within Workflow:** The **Understanding phase function** acts as the *contextual synthesis and decision-making engine*. It evaluates the enriched context, potentially filters information (triggering Qdrant deletes via the API/`database.py`), and passes the refined, integrated context to the final phase.

6.  **Yield Phase: Process Completion - Bringing the Workflow to a Temporally Defined End**

    *   **Temporal Focus:** The **defined end point** of the current PostChain workflow cycle – the moment when a response is generated.
    *   **Temporal Logic:** **Completion and Cyclicality.** This phase is about *bringing the current cycle to a close*. It generates the final user-facing response based on the integrated understanding, bundles all intermediate phase outputs, and prepares the data structure to be saved in the Qdrant `choir` collection. It marks the *end of the present cycle*. (Note: Recursion logic might be simplified or deferred in MVP).
    *   **Role within Workflow:** The **Yield phase function** acts as the *output formatting and finalization engine*. It formats the final response, gathers all preceding phase outputs, and returns the complete data structure to the API orchestrator for persistence in Qdrant and triggering the reward mechanism.

**The AEIOU-Y Flow as a Temporal Dance:**

The PostChain, viewed through its temporal logic, remains a carefully choreographed **dance through time** within the workflow. Each phase function takes its turn to engage with a different temporal dimension, building upon the previous phase and contributing to the overall temporal coherence of the conversational experience. It's a dynamic process where the AI, guided by the workflow and interacting with Qdrant, builds knowledge and understanding step by step, phase by phase.

By understanding this temporal logic, developers can implement more effective and nuanced AI phase functions within the Choir workflow, creating conversational experiences that are not just intelligent but also deeply attuned to the temporal nature of human communication and knowledge creation.

=== File: docs/require_action_phase.md ===



==
require_action_phase
==


# Action Phase Requirements

## Overview

The Action phase is the initial entry point and recursive re-entry point for the PostChain. It is responsible for direct model calls and tool execution based on user input or previous cycle results.

## Core Responsibilities

1. Process immediate user input or recursive prompts
2. Execute simple model inference or tool operations
3. Format results for downstream consumption
4. Maintain minimal context focused on the current request

## Temporal Focus: The Immediate Present

The Action phase operates in the immediate present, with minimal historical context. It focuses on the current moment of engagement, either with user input or the current state of a recursive process.

## Input Specification

The Action phase accepts:

1. **Primary Content**:

   - Initial user input (first cycle)
   - Yield phase forwarded content (recursive cycles)

2. **Metadata**:
   - Recursion state (cycle count, origin)
   - Context management operations from prior cycles
   - Configuration parameters for model selection

## Output Specification

The Action phase produces:

1. **Primary Content**:

   - Direct model responses or tool execution results
   - Initial assessment of user input

2. **Metadata**:
   - Confidence scores
   - Context operations (minimal at this stage)
   - Processing telemetry

## Processing Requirements

### Model Selection

The Action phase should dynamically select appropriate models based on:

- Task complexity
- Required capabilities (e.g., tool use, code generation)
- Performance characteristics from the provider matrix

### Context Management

As the initial phase, Action should:

- Apply minimal context operations
- Format user input appropriately
- Include system prompts relevant to the current request
- Preserve user messages intact

### Error Handling

The Action phase should handle:

- Model unavailability by falling back to alternative providers
- Tool execution failures with appropriate error messages
- Context size limitations with truncation strategies

## Performance Requirements

1. **Latency**: The Action phase should complete within 2-3 seconds for simple requests
2. **Throughput**: Support concurrent processing of multiple threads
3. **Reliability**: Achieve 99.9% success rate for request handling

## Implementation Constraints

1. Use the provider matrix for model selection
2. Support both synchronous and streaming responses
3. Implement clean error boundaries
4. Log all operations for monitoring and debugging

## Examples

### Simple Model Call (action_0)

```python
async def action_0(input_text: str, context: List[Message] = None) -> ActionResult:
    """Execute a simple model inference without tools."""
    model = select_model_provider("action", {"tool_use": False})
    system_prompt = "You are a helpful assistant responding to user queries."

    return await action_agent.run(
        input_text,
        message_history=context,
        system_prompt=system_prompt
    )
```

### Tool-using Action (action_n)

```python
async def action_n(input_text: str, context: List[Message] = None, tools: List[Tool] = None) -> ActionResult:
    """Execute a model call with tool use capabilities."""
    model = select_model_provider("action", {"tool_use": True})
    system_prompt = "You are a helpful assistant with access to tools. Use them when appropriate."

    return await action_agent.run(
        input_text,
        message_history=context,
        system_prompt=system_prompt,
        tools=tools
    )
```

## Interaction with Other Phases

- **Receives from**: Yield phase (in recursive cycles) or system (initial input)
- **Sends to**: Experience phase (sequential flow)
- **Relationship**: Initiates each PostChain cycle

## Success Criteria

1. Correctly interprets user input or recursive prompts
2. Successfully executes model calls or tool operations
3. Provides responses within latency requirements
4. Correctly formats output for downstream consumption
5. Handles errors gracefully with appropriate fallbacks

=== File: docs/require_experience_phase.md ===



==
require_experience_phase
==


# Experience Phase Requirements

## Overview

The Experience phase enriches the conversation context with relevant historical knowledge, search results, and retrieved information. It serves as the system's memory and knowledge acquisition component.

## Core Responsibilities

1. Retrieve relevant information from external sources
2. Enrich context with historical knowledge
3. Add search results and database lookups
4. Tag sources and relevance of added information
5. Maintain connections to knowledge repositories

## Temporal Focus: The Past Knowledge

The Experience phase embodies the system's relationship with past knowledge. It draws upon previously accumulated information, historical context, and external knowledge sources to enrich the current conversation.

## Input Specification

The Experience phase accepts:

1. **Primary Content**:

   - User input with initial Action phase assessment
   - Queries derived from user input

2. **Metadata**:
   - Context from previous phases
   - Search/retrieval parameters
   - Knowledge source configurations

## Output Specification

The Experience phase produces:

1. **Primary Content**:

   - Original content enhanced with retrieved information
   - Search results and knowledge retrievals

2. **Metadata**:
   - Source attribution for added information
   - Relevance scores for retrievals
   - Confidence in information accuracy
   - Context operations for information management

## Processing Requirements

### Knowledge Retrieval

The Experience phase should:

- Execute targeted searches based on user queries
- Perform vector similarity lookups in knowledge bases
- Retrieve relevant documents or snippets
- Filter results based on relevance thresholds

### Context Management

For effective information enrichment:

- Tag all added information with source attribution
- Add relevance scores to retrieved content
- Use ADD context operations for new information
- Use TAG operations to mark information characteristics
- Preserve original queries alongside results

### Error Handling

The Experience phase should handle:

- Failed retrievals with appropriate fallbacks
- Source unavailability with graceful degradation
- Rate limiting with retries and backoff strategies
- Empty result sets with alternative search strategies

## Performance Requirements

1. **Latency**: Complete retrieval operations within 3-5 seconds
2. **Result Quality**: Maintain relevance scores above 0.7 for retrievals
3. **Volume Control**: Limit added context to avoid token limit issues
4. **Source Diversity**: Attempt to retrieve from multiple sources when appropriate

## Implementation Constraints

1. Support multiple retrieval methods:
   - Vector database searches
   - Web search API calls
   - Document retrieval systems
   - Structured database queries
2. Implement caching for frequent retrievals
3. Support asynchronous retrieval operations
4. Maintain provenance tracking for all added information

## Examples

### Web Search Retrieval

```python
async def web_search_retrieval(query: str, context: List[Message]) -> ExperienceResult:
    """Retrieve information from web search."""
    search_results = await web_search_tool.search(query, max_results=3)

    # Add context operations for search results
    context_ops = []
    for result in search_results:
        context_ops.append({
            "operation": "ADD",
            "target": "context",
            "data": {
                "content": result.snippet,
                "source": result.url
            },
            "metadata": {
                "relevance": result.relevance_score,
                "timestamp": result.published_date
            }
        })

    return ExperienceResult(
        content={
            "original_query": query,
            "search_results": search_results
        },
        metadata={
            "context_operations": context_ops,
            "retrieval_method": "web_search"
        }
    )
```

### Vector Database Retrieval

```python
async def vector_db_retrieval(query: str, context: List[Message]) -> ExperienceResult:
    """Retrieve information from vector database."""
    # Convert query to embedding
    embedding = await embeddings_service.embed(query)

    # Retrieve similar documents
    documents = await vector_db.similarity_search(
        embedding,
        top_k=5,
        min_relevance=0.75
    )

    # Add context operations for retrieved documents
    context_ops = []
    for doc in documents:
        context_ops.append({
            "operation": "ADD",
            "target": "context",
            "data": {
                "content": doc.content,
                "source": doc.metadata.source
            },
            "metadata": {
                "relevance": doc.relevance_score,
                "created_at": doc.metadata.created_at
            }
        })

    return ExperienceResult(
        content={
            "original_query": query,
            "retrieved_documents": documents
        },
        metadata={
            "context_operations": context_ops,
            "retrieval_method": "vector_db"
        }
    )
```

## Interaction with Other Phases

- **Receives from**: Action phase
- **Sends to**: Intention phase
- **Relationship**: Provides knowledge enrichment before intention refinement

## Success Criteria

1. Retrieves information relevant to user queries
2. Properly attributes sources of all added information
3. Maintains appropriate balance of detail vs. conciseness
4. Preserves context operations for downstream phases
5. Falls back gracefully when primary sources are unavailable

=== File: docs/require_intention_phase.md ===



==
require_intention_phase
==


# Intention Phase Requirements

## Overview

The Intention phase refines and focuses information toward user goals, aligning the accumulated context with desired outcomes. It serves as the bridge between retrieved knowledge and effective decision-making by identifying what matters most.

## Core Responsibilities

1. Identify and clarify user goals and intentions
2. Prioritize information based on relevance to goals
3. Filter noise and tangential information
4. Align system responses with user objectives
5. Maintain focus on the desired future state

## Temporal Focus: The Desired Future

The Intention phase orients toward future objectives and desired outcomes. It represents the system's relationship with where the process needs to go, focusing information toward goal achievement rather than just accumulation.

## Input Specification

The Intention phase accepts:

1. **Primary Content**:

   - Original content with retrieved information (from Experience)
   - Search results and knowledge retrievals

2. **Metadata**:
   - Source attributions
   - Relevance scores for retrievals
   - Context from previous phases

## Output Specification

The Intention phase produces:

1. **Primary Content**:

   - Goal-oriented content with prioritized information
   - Clarified user intent statements

2. **Metadata**:
   - Alignment scores with identified intents
   - Priority markers for information
   - Context operations for focusing information
   - Goal certainty metrics

## Processing Requirements

### Intent Identification

The Intention phase should:

- Extract explicit and implicit user goals
- Disambiguate between multiple possible intentions
- Rank intentions by priority and likelihood
- Track intent evolution across conversation history

### Information Prioritization

For effective goal alignment:

- Score information relevance to identified goals
- Apply PRIORITIZE context operations to relevant content
- Use TRANSFORM operations to focus verbose content
- Identify information gaps needed for goal achievement

### Goal Refinement

To clarify ambiguous intentions:

- Generate goal hypotheses when intent is unclear
- Identify conflicting goals for resolution
- Decompose complex goals into manageable components
- Abstract specific requests to underlying intentions

### Error Handling

The Intention phase should handle:

- Ambiguous or contradictory user intentions
- Missing context for intent resolution
- Goal shifts during conversation
- Misalignment between user goals and available information

## Performance Requirements

1. **Intent Recognition Accuracy**: >85% accuracy in identifying correct user intent
2. **Processing Time**: Complete intent analysis within 1-2 seconds
3. **Relevance Threshold**: Achieve >80% precision in information prioritization
4. **Goal Stability**: Maintain consistent goal tracking across conversation turns

## Implementation Constraints

1. Maintain goal state across conversation turns
2. Support nested and hierarchical goal structures
3. Implement efficient goal-based relevance scoring
4. Track goal evolution and refinement over time

## Examples

### Intent Extraction and Prioritization

```python
async def extract_and_prioritize_intent(content: Dict, context: List[Message]) -> IntentionResult:
    """Extract user intent and prioritize information accordingly."""
    # Extract intent from user input and context
    intent_analysis = await intent_analyzer.analyze(
        content["original_query"],
        conversation_history=context
    )

    # Score relevance of information to intent
    scored_information = []
    for item in content.get("search_results", []):
        relevance_to_intent = calculate_relevance_to_intent(
            item,
            intent_analysis.primary_intent
        )

        scored_information.append({
            "item": item,
            "relevance_score": relevance_to_intent,
            "aligned_with_intent": relevance_to_intent > 0.7
        })

    # Generate context operations based on intent alignment
    context_ops = []
    for idx, info in enumerate(scored_information):
        if info["aligned_with_intent"]:
            context_ops.append({
                "operation": "PRIORITIZE",
                "target": f"search_results[{idx}]",
                "data": {
                    "priority": info["relevance_score"]
                },
                "metadata": {
                    "reason": "aligned_with_intent",
                    "intent": intent_analysis.primary_intent
                }
            })
        elif info["relevance_score"] < 0.3:
            context_ops.append({
                "operation": "TAG",
                "target": f"search_results[{idx}]",
                "data": {
                    "tags": ["low_relevance"]
                },
                "metadata": {
                    "reason": "not_aligned_with_intent"
                }
            })

    return IntentionResult(
        content={
            "original_content": content,
            "extracted_intent": intent_analysis.primary_intent,
            "intent_confidence": intent_analysis.confidence,
            "alternative_intents": intent_analysis.alternative_intents,
            "scored_information": scored_information
        },
        metadata={
            "context_operations": context_ops,
            "intent_extraction_method": "semantic_analysis"
        }
    )
```

### Goal Decomposition

```python
def decompose_complex_goal(primary_intent: str) -> Dict:
    """Break down a complex goal into subgoals."""
    # Analyze intent complexity
    complexity = measure_intent_complexity(primary_intent)

    if complexity < 0.5:  # Simple intent
        return {
            "is_complex": False,
            "primary_goal": primary_intent,
            "subgoals": []
        }

    # For complex intents, break down into components
    subgoals = []

    # Extract component goals through model call
    model = select_model_provider("intention", {"reasoning": True})
    system_prompt = "Break down this complex user goal into simpler component goals."

    decomposition_result = intent_model.run_sync(
        primary_intent,
        system_prompt=system_prompt
    )

    # Parse the decomposition
    subgoals = parse_subgoals(decomposition_result.data)

    return {
        "is_complex": True,
        "primary_goal": primary_intent,
        "subgoals": subgoals,
        "dependencies": identify_subgoal_dependencies(subgoals)
    }
```

## Interaction with Other Phases

- **Receives from**: Experience phase
- **Sends to**: Observation phase
- **Relationship**: Focuses information before semantic connection marking

## Success Criteria

1. Correctly identifies user intentions even when implicit
2. Successfully prioritizes information relevant to goals
3. Improves response relevance by filtering noise
4. Maintains consistent goal tracking across conversation
5. Adapts to evolving user intentions over time

=== File: docs/require_observation_phase.md ===



==
require_observation_phase
==


# Observation Phase Requirements

## Overview

The Observation phase identifies and persists connections between concepts, creating semantic links for future reference and retrieval. It serves as the system's memory persistence layer, ensuring that valuable insights and relationships are preserved beyond the current interaction cycle.

## Core Responsibilities

1. Identify semantic connections between pieces of information
2. Tag and categorize information for future retrieval
3. Persist important insights to memory
4. Create semantic links between related concepts
5. Maintain relationship graphs and knowledge structures

## Temporal Focus: Future Preservation

The Observation phase focuses on preserving information for future use. It identifies what should endure beyond the current cycle, explicitly marking connections and insights that will be valuable in subsequent interactions.

## Input Specification

The Observation phase accepts:

1. **Primary Content**:

   - Goal-oriented content with prioritized information (from Intention)
   - Clarified user intent statements

2. **Metadata**:
   - Alignment scores with identified intents
   - Priority markers for information
   - Context operations from previous phases

## Output Specification

The Observation phase produces:

1. **Primary Content**:

   - Content with semantic connections identified
   - Knowledge graph updates and additions

2. **Metadata**:
   - Tags and relationship links
   - Memory persistence instructions
   - Context operations for relationship marking
   - Knowledge graph statistics

## Processing Requirements

### Semantic Connection Identification

The Observation phase should:

- Identify relationships between concepts
- Detect causal, hierarchical, and associative links
- Recognize patterns across information sources
- Map connections to existing knowledge structures

### Memory Persistence

For effective future retrieval:

- Score information importance for long-term storage
- Use LINK context operations to establish connections
- Apply domain-specific tagging schemas
- Prepare vector representations for similarity search

### Knowledge Graph Management

To maintain coherent knowledge structures:

- Update existing knowledge graph entries
- Create new nodes for novel concepts
- Establish weighted relationships between nodes
- Prune redundant or superseded connections

### Error Handling

The Observation phase should handle:

- Conflicting relationship patterns
- Novel concepts not in existing schemas
- Information without clear relationships
- Memory storage constraints

## Performance Requirements

1. **Connection Accuracy**: >80% precision in relationship identification
2. **Processing Efficiency**: Complete observation processing within 2-3 seconds
3. **Storage Optimization**: Minimize duplication while maximizing retrievability
4. **Relationship Quality**: Achieve high semantic relevance in established links

## Implementation Constraints

1. Support vector database integration for embeddings
2. Implement efficient graph database operations
3. Maintain backward compatibility with existing knowledge structures
4. Support incremental knowledge graph updates

## Examples

### Semantic Connection Identification

```python
async def identify_semantic_connections(content: Dict) -> List[Connection]:
    """Identify semantic connections between content elements."""
    connections = []

    # Extract entities and concepts from content
    entities = await entity_extractor.extract(content["goal_oriented_content"])

    # Find connections between entities
    for i, entity1 in enumerate(entities):
        for j, entity2 in enumerate(entities):
            if i != j:  # Don't connect entity to itself
                relationship = await relationship_detector.detect(
                    entity1,
                    entity2,
                    context=content
                )

                if relationship and relationship.confidence > 0.6:
                    connections.append({
                        "source": entity1.id,
                        "target": entity2.id,
                        "relationship_type": relationship.type,
                        "confidence": relationship.confidence,
                        "evidence": relationship.evidence
                    })

    return connections
```

### Memory Persistence Operations

```python
async def persist_to_memory(
    content: Dict,
    connections: List[Connection],
    context: List[Message]
) -> ObservationResult:
    """Persist important information and connections to memory."""
    # Prepare context operations
    context_ops = []

    # Create LINK operations for connections
    for connection in connections:
        if connection["confidence"] > 0.7:  # Only persist high-confidence connections
            context_ops.append({
                "operation": "LINK",
                "target": connection["source"],
                "data": {
                    "linked_to": connection["target"],
                    "relationship": connection["relationship_type"]
                },
                "metadata": {
                    "confidence": connection["confidence"],
                    "evidence": connection["evidence"]
                }
            })

    # Tag important entities for persistence
    for entity in extract_entities(content):
        importance = calculate_entity_importance(entity, content, connections)
        if importance > 0.65:
            context_ops.append({
                "operation": "TAG",
                "target": entity.id,
                "data": {
                    "tags": ["important", "persist"]
                },
                "metadata": {
                    "importance": importance,
                    "reason": "key_concept"
                }
            })

    # Persist to vector database for future retrieval
    embed_results = await knowledge_store.embed_and_store(
        content=content["goal_oriented_content"],
        metadata={
            "connections": connections,
            "timestamp": datetime.utcnow().isoformat(),
            "context_id": context[-1].id if context else None
        }
    )

    return ObservationResult(
        content={
            "original_content": content,
            "identified_connections": connections,
            "persisted_entities": [e.id for e in extract_entities(content) if calculate_entity_importance(e, content, connections) > 0.65]
        },
        metadata={
            "context_operations": context_ops,
            "persistence_details": embed_results,
            "knowledge_graph_updates": len(connections)
        }
    )
```

### Knowledge Graph Update

```python
async def update_knowledge_graph(connections: List[Connection]) -> Dict:
    """Update the knowledge graph with new connections."""
    updates = {
        "added_nodes": [],
        "added_edges": [],
        "modified_nodes": [],
        "modified_edges": []
    }

    # Update graph database
    async with graph_db.transaction() as txn:
        # Process each connection
        for connection in connections:
            # Check if source node exists
            source_exists = await txn.node_exists(connection["source"])
            if not source_exists:
                node_id = await txn.create_node(
                    id=connection["source"],
                    properties={
                        "created_at": datetime.utcnow().isoformat()
                    }
                )
                updates["added_nodes"].append(node_id)

            # Check if target node exists
            target_exists = await txn.node_exists(connection["target"])
            if not target_exists:
                node_id = await txn.create_node(
                    id=connection["target"],
                    properties={
                        "created_at": datetime.utcnow().isoformat()
                    }
                )
                updates["added_nodes"].append(node_id)

            # Create or update edge
            edge_exists = await txn.edge_exists(
                source=connection["source"],
                target=connection["target"],
                type=connection["relationship_type"]
            )

            if edge_exists:
                edge_id = await txn.update_edge(
                    source=connection["source"],
                    target=connection["target"],
                    type=connection["relationship_type"],
                    properties={
                        "confidence": connection["confidence"],
                        "updated_at": datetime.utcnow().isoformat()
                    }
                )
                updates["modified_edges"].append(edge_id)
            else:
                edge_id = await txn.create_edge(
                    source=connection["source"],
                    target=connection["target"],
                    type=connection["relationship_type"],
                    properties={
                        "confidence": connection["confidence"],
                        "created_at": datetime.utcnow().isoformat()
                    }
                )
                updates["added_edges"].append(edge_id)

    return updates
```

## Interaction with Other Phases

- **Receives from**: Intention phase
- **Sends to**: Understanding phase
- **Relationship**: Preserves connections before context filtering

## Success Criteria

1. Accurately identifies meaningful semantic connections
2. Successfully persists important information for future retrieval
3. Creates useful knowledge graph structures
4. Maintains efficient storage with minimal redundancy
5. Enhances future retrieval through effective tagging and linking

=== File: docs/require_phase_requirements_index.md ===



==
require_phase_requirements_index
==


# PostChain Phase Requirements

## Overview

This directory contains detailed Product Requirements Documents (PRDs) for each phase of the PostChain. These specifications define the exact responsibilities, behaviors, inputs, and outputs for each phase actor.

## Temporal Relationship to Information

The PostChain phases embody different temporal relationships to information:

| Phase             | Temporal Focus       | Core Responsibility                       |
| ----------------- | -------------------- | ----------------------------------------- |
| **Action**        | Immediate present    | Model calls and tool execution            |
| **Experience**    | Past knowledge       | Information retrieval and enrichment      |
| **Intention**     | Desired future       | Goal-seeking and focus refinement         |
| **Observation**   | Future preservation  | Memory persistence and connection marking |
| **Understanding** | Temporal integration | Context filtering and information release |
| **Yield**         | Process completion   | Flow control and recursion decisions      |

## Phase Specifications

### [Action Phase](action_phase.md)

The Action phase handles direct model calls and tool execution, operating in the immediate present with minimal historical context. It serves as both the entry point and potential recursive re-entry point for the PostChain.

**Key responsibilities**: Model inference, tool execution, initial response generation

### [Experience Phase](experience_phase.md)

The Experience phase enriches the conversation with retrieved knowledge, serving as the system's memory and knowledge acquisition component. It embodies the system's relationship with past knowledge.

**Key responsibilities**: Information retrieval, context enrichment, knowledge enhancement

### [Intention Phase](intention_phase.md)

The Intention phase refines and focuses information toward user goals, aligning the accumulated context with desired outcomes. It represents the system's orientation toward future objectives.

**Key responsibilities**: Goal identification, priority setting, relevance determination

### [Observation Phase](observation_phase.md)

The Observation phase identifies and persists connections between concepts, creating semantic links for future reference. It manages the preservation of information beyond the current cycle.

**Key responsibilities**: Connection marking, semantic tagging, memory persistence

### [Understanding Phase](../require_understanding_phase.md)

The Understanding phase evaluates accumulated information to determine what remains relevant and what can be released. It embodies the wisdom of letting go of less relevant information.

**Key responsibilities**: Context filtering, information pruning, message evaluation

### [Yield Phase](../require_yield_phase.md)

The Yield phase determines whether to produce a final response or continue processing through another recursive cycle. It controls the flow of the entire PostChain process.

**Key responsibilities**: Recursion decisions, flow control, response formatting

## Implementation Strategy

These phase requirements represent ideal behaviors for a full actor-based implementation. During initial development with PydanticAI, a simplified version may be implemented first, while maintaining alignment with these conceptual responsibilities.

The phase requirements should be used as reference during implementation to ensure that each phase, regardless of the underlying architecture, fulfills its core temporal relationship to information.

## Document Format

Each phase requirement document follows a consistent format:

1. **Overview**: Brief description of the phase and its purpose
2. **Core Responsibilities**: List of primary responsibilities
3. **Temporal Focus**: Relationship to time and information
4. **Input Specification**: Expected inputs and their structure
5. **Output Specification**: Required outputs and their structure
6. **Processing Requirements**: Specific processing behaviors
7. **Performance Requirements**: Expected performance characteristics
8. **Implementation Constraints**: Technical implementation guidelines
9. **Examples**: Code examples showing how the phase might be implemented
10. **Interaction with Other Phases**: How the phase connects to others
11. **Success Criteria**: Measurable success indicators

=== File: docs/require_understanding_phase.md ===



==
require_understanding_phase
==


# Understanding Phase Requirements

## Overview

The Understanding phase is responsible for temporal integration of information and context management. It evaluates accumulated information across time to determine what remains relevant and what can be released, embodying the system's ability to discern signal from noise.

## Core Responsibilities

1. Evaluate and filter information based on relevance
2. Implement information "forgetting" through pruning
3. Apply context management operations to maintain optimal context
4. Integrate information across temporal phases
5. Maintain clean and focused context for subsequent cycles

## Temporal Focus: Temporal Integration and Release

The Understanding phase integrates information across time, having sufficient contextual awareness to determine what information remains relevant and what can be released. This phase embodies the wisdom of letting go of less relevant information.

## Input Specification

The Understanding phase accepts:

1. **Primary Content**:

   - Content with semantic connections identified (from Observation)
   - Context with tagged relationships and importance markers

2. **Metadata**:
   - Tags and relationship links
   - Context history across multiple cycles
   - Relevance scores and usage metrics

## Output Specification

The Understanding phase produces:

1. **Primary Content**:

   - Filtered and integrated content
   - Decisions about information retention and release

2. **Metadata**:
   - Context management operations (PRUNE, TRANSFORM, etc.)
   - Rationale for retention/release decisions
   - Context statistics (tokens, messages, etc.)

## Processing Requirements

### Message Evaluation

The Understanding phase should:

- Evaluate each message's relevance to current context
- Track message references and usage across phases
- Calculate information importance based on multiple factors
- Distinguish between user messages and AI-generated content

### Context Management Rules

1. **User Messages**:

   - Preserve by default
   - Request user consent for pruning large messages
   - Offer summarization as an alternative to full retention

2. **AI-Generated Content**:

   - Automatically prune based on relevance assessment
   - Summarize content where appropriate
   - Maintain attribution chains when summarizing

3. **Search Results**:
   - Evaluate continued relevance
   - Prune results not referenced in recent phases
   - Consolidate similar or redundant information

### Context Operations

The Understanding phase should generate appropriate context operations:

- `PRUNE`: Mark messages for removal
- `TRANSFORM`: Suggest summarization or condensing
- `PRIORITIZE`: Adjust importance of information
- `TAG`: Add metadata about information retention

### Error Handling

The Understanding phase should handle:

- Context window limits with graceful degradation
- User override of pruning recommendations
- Preservation of critical content even under constraints

## Performance Requirements

1. **Efficiency**: Complete context evaluation within 1-2 seconds
2. **Context Size Management**: Maintain context within 70% of model limits
3. **Relevance Threshold**: Achieve >85% retention of truly relevant information
4. **User Experience**: Minimize disruption when requesting consent

## Implementation Constraints

1. Maintain clear separation between:
   - User-owned content (requiring consent)
   - AI-generated content (managed automatically)
2. Implement decay functions for information relevance over time
3. Support reversible operations when possible
4. Log all pruning decisions for transparency

## Examples

### Message Evaluation and Pruning

```python
async def evaluate_messages(context: List[Message]) -> List[ContextOperation]:
    """Evaluate messages and return context operations."""
    operations = []

    # Group messages by type
    user_messages = [m for m in context if m.role == "user"]
    ai_messages = [m for m in context if m.role == "assistant"]

    # AI message evaluation
    for message in ai_messages:
        # Skip most recent message
        if message == ai_messages[-1]:
            continue

        relevance = calculate_relevance(message, context)
        if relevance < 0.3:
            operations.append({
                "operation": "PRUNE",
                "target": message.id,
                "data": {"reason": "low_relevance"},
                "metadata": {"relevance": relevance}
            })
        elif relevance < 0.7:
            operations.append({
                "operation": "TRANSFORM",
                "target": message.id,
                "data": {
                    "transformation": "summarize",
                    "parameters": {"max_length": 100}
                },
                "metadata": {"relevance": relevance}
            })

    # User message evaluation (large messages only)
    for message in user_messages:
        if len(message.content) > 1000:
            # Flag for user consent, don't prune automatically
            operations.append({
                "operation": "TRANSFORM",
                "target": message.id,
                "data": {
                    "transformation": "summarize",
                    "parameters": {"max_length": 200}
                },
                "metadata": {
                    "requires_consent": True,
                    "original_length": len(message.content)
                }
            })

    return operations
```

### User Consent Management

```python
async def request_user_consent(
    operations: List[ContextOperation],
    context: List[Message]
) -> List[ContextOperation]:
    """Request user consent for operations requiring it."""
    consent_required = [op for op in operations if op.get("metadata", {}).get("requires_consent")]

    if not consent_required:
        return operations

    # Prepare user-facing message
    consent_message = "To optimize the conversation, I'd like to summarize these earlier messages:\n\n"

    for op in consent_required:
        message = next(m for m in context if m.id == op["target"])
        preview = message.content[:50] + "..." if len(message.content) > 50 else message.content
        consent_message += f"- {preview}\n"

    consent_message += "\nWould you like me to: (1) Keep everything as is, (2) Summarize these messages, or (3) Remove them entirely?"

    # In practice, this would await actual user input
    # Simulated response for example
    user_choice = await request_user_input(consent_message)

    # Apply user choice
    if user_choice == "1":  # Keep
        return [op for op in operations if not op.get("metadata", {}).get("requires_consent")]
    elif user_choice == "2":  # Summarize
        # Keep summarization operations
        return operations
    else:  # Remove
        # Convert TRANSFORM to PRUNE
        for op in consent_required:
            op["operation"] = "PRUNE"
            op["data"] = {"reason": "user_consent"}
        return operations
```

## Interaction with Other Phases

- **Receives from**: Observation phase
- **Sends to**: Yield phase
- **Relationship**: Optimizes context before flow control decisions

## Success Criteria

1. Maintains optimal context size through intelligent pruning
2. Preserves critical information regardless of age
3. Respects user ownership of their messages
4. Provides transparent context operations
5. Improves model performance by reducing noise

=== File: docs/require_yield_phase.md ===



==
require_yield_phase
==


# Yield Phase Requirements

## Overview

The Yield phase is responsible for process completion decisions and flow control. It determines whether to return a final response or continue processing through another cycle, and which phase to invoke next in the case of recursion.

## Core Responsibilities

1. Evaluate process completion criteria
2. Make recursion decisions
3. Select the next phase to execute (when recursing)
4. Format final output for user consumption
5. Maintain process continuity across cycles

## Temporal Focus: Process Completion

The Yield phase focuses on the completion state of the process. It assesses whether the current cycle has produced sufficient results or whether additional cycles would yield meaningful improvements.

## Input Specification

The Yield phase accepts:

1. **Primary Content**:

   - Filtered and integrated content from Understanding
   - Current cycle's outputs and state

2. **Metadata**:
   - Context management decisions
   - Recursion state (current cycle count)
   - Confidence scores and completion metrics
   - Processing telemetry from previous phases

## Output Specification

The Yield phase produces:

1. **Primary Content**:

   - Final response (if complete)
   - Continuation prompt (if recursing)

2. **Metadata**:
   - Recursion decision (continue/complete)
   - Target phase for next cycle (if continuing)
   - Updated recursion state
   - Rationale for recursion decision

## Processing Requirements

### Completion Evaluation

The Yield phase should evaluate completion based on:

- Convergence of results
- Answer confidence thresholds
- Maximum cycle limits
- Task completion indicators
- User satisfaction metrics

### Recursion Control

When deciding to continue, the Yield phase should:

- Select the most appropriate phase to invoke next
- Initialize proper state for the next cycle
- Formulate the continuation prompt
- Update recursion counters and state

### Next Phase Selection

The Yield phase can select any phase for recursion:

- `action`: For additional processing or tool use
- `experience`: For gathering more information
- `intention`: For refining goals
- `observation`: For storing additional insights
- `understanding`: For context refinement
- Default sequential flow is to `action` phase

### Final Response Formatting

When deciding to complete, the Yield phase should:

- Format the final response for user consumption
- Apply appropriate styling and structure
- Include confidence indicators
- Provide source attributions when relevant

### Error Handling

The Yield phase should handle:

- Recursion loop detection
- Maximum recursion limit enforcement
- Recovery from incomplete or failed phases
- Graceful termination when necessary

## Performance Requirements

1. **Decision Speed**: Complete recursion decisions within 1 second
2. **Recursion Limit**: Enforce configurable maximum recursive cycles
3. **Completion Accuracy**: >90% accuracy in determining when processing is complete
4. **Path Efficiency**: Select optimal next phase to minimize total cycles

## Implementation Constraints

1. Support both automatic and user-directed recursion control
2. Implement cycle counting and maximum limits
3. Maintain recursion history for loop detection
4. Support direct jumps to any phase in the PostChain

## Examples

### Recursion Decision Logic

```python
async def decide_recursion(
    current_state: Dict,
    cycle_count: int,
    max_cycles: int = 5
) -> YieldResult:
    """Determine whether to continue processing or terminate."""

    # Hard limit on recursion
    if cycle_count >= max_cycles:
        return YieldResult(
            continue_processing=False,
            final_response=current_state["content"],
            rationale="Maximum recursion depth reached"
        )

    # Check confidence threshold
    if current_state.get("confidence", 0) > 0.9:
        return YieldResult(
            continue_processing=False,
            final_response=current_state["content"],
            rationale="High confidence threshold met"
        )

    # Check if answer is still converging
    if cycle_count > 1 and calculate_convergence(current_state) < 0.1:
        return YieldResult(
            continue_processing=False,
            final_response=current_state["content"],
            rationale="Answer convergence reached"
        )

    # Decide which phase to invoke next
    if needs_more_information(current_state):
        next_phase = "experience"
        rationale = "Additional information required"
    elif needs_intention_clarification(current_state):
        next_phase = "intention"
        rationale = "Goal refinement needed"
    elif needs_additional_tools(current_state):
        next_phase = "action"
        rationale = "Tool execution required"
    else:
        # Default recursive flow
        next_phase = "action"
        rationale = "Standard recursive cycle"

    return YieldResult(
        continue_processing=True,
        next_phase=next_phase,
        continuation_prompt=generate_continuation_prompt(current_state, next_phase),
        rationale=rationale
    )
```

### Phase Selection Logic

```python
def select_next_phase(current_state: Dict) -> str:
    """Select the next phase to execute."""

    # Extract key indicators from state
    confidence = current_state.get("confidence", 0)
    info_sufficiency = current_state.get("information_sufficiency", 0)
    tool_indicators = current_state.get("needs_tools", False)

    # Decision tree for phase selection
    if info_sufficiency < 0.7:
        return "experience"  # Need more information
    elif "unclear_intent" in current_state.get("flags", []):
        return "intention"  # Need to clarify intent
    elif tool_indicators:
        return "action"  # Need to use tools
    elif len(current_state.get("context", [])) > 10:
        return "understanding"  # Need to clean up context
    else:
        return "action"  # Default recursive entry point
```

## Interaction with Other Phases

- **Receives from**: Understanding phase
- **Sends to**: Any phase (when recursing) or system (when complete)
- **Relationship**: Controls system flow and termination

## Success Criteria

1. Makes appropriate recursion decisions
2. Selects optimal next phase to minimize total cycles
3. Enforces recursion limits to prevent infinite loops
4. Produces properly formatted final responses
5. Maintains logical flow continuity across multiple cycles

=== File: docs/reward_function.md ===



==
reward_function
==


# Choir Novelty Reward Function

This document explains the mathematical approach used to calculate novelty rewards in the Choir system. We explored different approaches to implement an exponential reward scaling that provides higher rewards for more novel content.

## Reward Scaling Requirements

The novelty reward system needed to meet the following requirements:

1. Scale exponentially from 0.01 to 100.0 CHOIR tokens based on content novelty
2. Provide specific reward amounts at key similarity thresholds:
   - 0.95 similarity → 0.01 CHOIR (minimum novelty)
   - 0.90 similarity → 0.1 CHOIR
   - 0.85 similarity → 1.0 CHOIR
   - 0.80 similarity → 10.0 CHOIR
   - 0.75 similarity → 100.0 CHOIR (maximum novelty)
3. Use a smooth mathematical function that scales predictably
4. Implement using natural mathematical constants rather than magic numbers

## Approach 1: Curve Fitting

Our first approach (`reward_function.py`) used curve fitting to find a mathematical function that precisely matched our target reward points. We used SciPy's `curve_fit` function to fit an exponential function to our data points.

```python
# Define a logarithmic function with parameters to fit
def log_function(x, a, b, c):
    # We want a function that grows exponentially as similarity decreases
    return a * np.exp(b * (c - x))

# Fit the function to our data points
params, _ = curve_fit(log_function, similarity, rewards)

# Extract the fitted parameters
a, b, c = params
# a=0.002489, b=46.051702, c=0.980199

# The resulting function
reward = 0.002489 * np.exp(46.051702 * (0.980199 - max_similarity))
```

This approach produced a perfect fit to our target points but used somewhat arbitrary constants that lacked clear meaning.

## Approach 2: Simplified Exponential Function

Our second approach (`reward_function_simplified.py`) derived a more intuitive exponential function based on the mathematical properties of our reward scaling requirements.

We observed that:
- Each 0.05 decrease in similarity results in a 10x increase in reward
- This is a classic exponential pattern that can be expressed using the natural exponential function (e)

```python
# Constants with clear meaning
reference_similarity = 0.95  # The reference point where reward = min_reward
min_reward = 0.01            # Reward at reference similarity
reward_factor = 10           # How much reward increases per similarity_step
similarity_step = 0.05       # How much similarity needs to decrease for reward to increase by reward_factor

# Calculate exponent: ln(reward_factor) / similarity_step
exponent_factor = math.log(reward_factor) / similarity_step

# Calculate the reward
reward = min_reward * math.exp(exponent_factor * (reference_similarity - similarity))
```

The mathematical formula can be expressed as:
```
reward = min_reward * e^(ln(reward_factor)/similarity_step * (reference_similarity - similarity))
```

This simplified approach:
1. Uses constants with clear semantic meaning
2. Leverages the natural exponential function (e)
3. Produces identical results to the curve-fitted function
4. Is more maintainable and easier to understand

## Implementation in Choir

The simplified exponential function was implemented in `api/app/services/rewards_service.py` as follows:

```python
async def calculate_novelty_reward(self, max_similarity: float) -> int:
    # If max_similarity is close to 1.0, the prompt is not novel
    if max_similarity > 0.95:
        return 0

    # Base reward amount (1 CHOIR = 1_000_000_000 units)
    base_reward = 1_000_000_000
    
    # Constants with clear meaning
    reference_similarity = 0.95  # The reference point where reward = min_reward
    min_reward = 0.01            # Reward at reference similarity
    reward_factor = 10           # How much reward increases per similarity_step
    similarity_step = 0.05       # How much similarity needs to decrease for reward to increase by reward_factor
    
    # Calculate exponent: ln(reward_factor) / similarity_step
    exponent_factor = math.log(reward_factor) / similarity_step
    
    # Calculate the reward using natural exponential function
    reward_multiplier = min_reward * math.exp(exponent_factor * (reference_similarity - max_similarity))
    
    # Cap the reward at 100 CHOIR
    reward_multiplier = min(reward_multiplier, 100.0)
    
    # Convert to smallest units
    scaled_reward = int(base_reward * reward_multiplier)

    return scaled_reward
```

## Reward Table

The following table shows the rewards at different similarity levels:

| max_similarity | novelty_score | Reward (CHOIR) |
|---------------|--------------|----------------|
| 0.95 | 0.05 | 0.01 |
| 0.92 | 0.08 | 0.0316 |
| 0.90 | 0.10 | 0.1 |
| 0.88 | 0.12 | 0.3162 |
| 0.85 | 0.15 | 1.0 |
| 0.82 | 0.18 | 3.1623 |
| 0.80 | 0.20 | 10.0 |
| 0.78 | 0.22 | 31.6228 |
| 0.75 | 0.25 | 100.0 |

## Benefits of Exponential Scaling

The exponential reward scaling provides several benefits:

1. **Incentivizes Novelty**: Provides significantly higher rewards for truly novel content
2. **Dynamic Range**: Covers a wide range of rewards (0.01 to 100.0) to better differentiate content quality
3. **Logarithmic Perception**: Aligns with human perception, which tends to be logarithmic rather than linear
4. **Mathematical Elegance**: Uses a clean mathematical formula based on natural constants

This reward function ensures that users are properly incentivized to contribute novel content to the Choir ecosystem, with rewards that scale exponentially based on the uniqueness of their contributions.

=== File: docs/rewards_system.md ===



==
rewards_system
==


# Choir Rewards System

## Overview

The Choir rewards system incentivizes users to contribute novel prompts and cite valuable information. The system issues CHOIR tokens on the Sui blockchain as rewards for these contributions.

## Reward Types

### 1. Novelty Rewards

Novelty rewards are issued when a user submits a prompt that is semantically different from existing content in the vector database.

- **Calculation**: Novelty is calculated as `1 - max_similarity`, where `max_similarity` is the highest similarity score between the user's prompt and existing vectors.
- **Issuance**: Rewards are issued during the Experience Vectors phase.
- **Amount**: 0.01 to 100.0 CHOIR tokens, scaled exponentially based on the novelty score.

### 2. Citation Rewards

Citation rewards are issued when a user cites vector search results in their conversation.

- **Calculation**: 0.5 CHOIR tokens per citation, up to a maximum of 5 citations.
- **Issuance**: Rewards are issued during the Yield phase.
- **Detection**: Citations are detected using the `#ID` syntax in the model's response.

## Technical Implementation

### Backend (Python)

#### Novelty Rewards Pipeline

1. **Vector Embedding**: User prompts are embedded using an embedding model.
2. **Similarity Search**: The embeddings are compared against existing vectors in the database.
3. **Reward Calculation**: Novelty score is calculated as `1 - max_similarity`.
4. **Reward Issuance**: If the novelty score is high enough, CHOIR tokens are minted to the user's wallet.
5. **Response Enrichment**: Reward information is included in the API response and passed to the LLM.

```python
# Calculate and issue novelty reward
if wallet_address and max_similarity is not None:
    rewards_service = RewardsService()
    reward_result = await rewards_service.issue_novelty_reward(wallet_address, max_similarity)
    novelty_reward = reward_result
```

#### Citation Rewards Pipeline

1. **Citation Detection**: The LLM's response is analyzed to detect citations using the `#ID` syntax.
2. **Reward Calculation**: 0.5 CHOIR tokens per citation, up to 5 citations.
3. **Reward Issuance**: CHOIR tokens are minted to the user's wallet.

```python
# Extract citations and issue rewards
if wallet_address and response.content:
    rewards_service = RewardsService()
    citations = rewards_service.extract_citations(response.content)
    if citations:
        reward_result = await rewards_service.issue_citation_rewards(wallet_address, len(citations))
        citation_reward = reward_result
```

### Frontend (Swift)

#### Reward Display

1. **API Integration**: The Swift client receives reward information in the API response.
2. **UI Display**: Reward information is displayed in the phase card UI.
3. **Alerts**: Successful rewards trigger alert notifications.

```swift
// Process reward information from a phase response
func processPhaseResponse(phase: String, response: [String: Any]) {
    if phase == "experience_vectors", let noveltyRewardDict = response["novelty_reward"] as? [String: Any] {
        let reward = try JSONDecoder().decode(RewardInfo.self, from: jsonData)
        processReward(rewardInfo: reward)
    }
}
```

## LLM Integration

The LLM is instructed to include reward information in its responses:

1. **Novelty Rewards**: The LLM receives information about novelty rewards and includes it in the Experience Vectors phase response.
2. **Citation Rewards**: The LLM is instructed to use the `#ID` syntax when referencing vector search results, which triggers citation rewards.

## Memory System Integration

The rewards system is deeply integrated with Choir's memory system:

1. **Global Memory**: Vector embeddings form a global memory that all users can access.
2. **Per-User Memory**: Each user's wallet has its own collection of threads and rewards.
3. **Per-Thread Memory**: Each thread maintains its own context and citation history.

In the future, this memory system will evolve into hypergraphs of conceptual interrelations, allowing for more sophisticated reward mechanisms based on the value and interconnectedness of contributions.

## Blockchain Integration

Rewards are issued as CHOIR tokens on the Sui blockchain:

1. **Minting**: The `mint_choir` function in `sui_service.py` mints CHOIR tokens to the user's wallet.
2. **Verification**: Transactions are verified on the Sui blockchain.
3. **Balance**: Users can view their CHOIR token balance in the app.

```python
async def mint_choir(self, recipient_address: str, amount: int = 1_000_000_000):
    """Mint CHOIR tokens to recipient (default 1 CHOIR)"""
    txn = SuiTransaction(client=self.client)
    txn.move_call(
        target=f"{self.package_id}::choir::mint",
        arguments=[
            ObjectID(self.treasury_cap_id),
            SuiU64(amount),
            SuiAddress(recipient_address)
        ],
        type_arguments=[]
    )
    result = txn.execute()
    # Process result...
```

## Future Enhancements

1. **Reward Visualization**: Enhanced visualizations of rewards in the UI.
2. **Reward History**: A dedicated view for users to see their reward history.
3. **Community Rewards**: Rewards for community contributions and collaborations.
4. **Conceptual Hypergraphs**: Evolution of the memory system to support more sophisticated reward mechanisms.

=== File: docs/security_considerations.md ===



==
security_considerations
==


# Security Considerations for Choir (Qdrant-Sui MVP)

VERSION security_considerations: 8.0 (Qdrant-Sui MVP Focus)

## Introduction

This document outlines the security considerations for Choir's Qdrant-Sui Minimum Viable Product (MVP) architecture. This architecture centralizes AI workflow execution, data management (Qdrant), and blockchain interactions (Sui via `sui_service.py`) within a single Python API backend. Security focuses on protecting this central API, its data interactions, and the user's keys on the client side.

## Threat Model

The system addresses the following potential threats:

1.  **Blockchain Key Compromise**: Theft or unauthorized use of the API backend's private key used for Sui blockchain operations.
2.  **Contract Manipulation**: Unauthorized modification of the basic CHIP token contract parameters or execution (less likely with MVP's simple contract).
3.  **Token Theft**: Unauthorized triggering of reward distributions or transfers via the API.
4.  **Data Exfiltration**: Unauthorized access to or extraction of sensitive user or conversation data stored in Qdrant.
5.  **System Manipulation**: Unauthorized alterations to the API's behavior, PostChain workflow logic, or state stored in Qdrant.
6.  **Model Attacks**: Prompt injection, jailbreaking, or other attacks targeting the LLMs used within the PostChain workflow.
7.  **Resource Exhaustion**: Denial of service against the API backend or Qdrant through excessive requests.
8.  **Identity Spoofing**: Impersonation of legitimate users via compromised Sui keys or authentication bypass.
9.  **Infrastructure Compromise**: Attacks on the underlying infrastructure hosting the API backend and Qdrant (e.g., Render).

## Secure Blockchain Operations (MVP Context)

### Core Blockchain Security Goals

1.  **Secure Key Management**: Securely store and manage the private key used by the API backend's `sui_service.py` for Sui blockchain operations.
2.  **Protected Contract Interaction**: Ensure interactions with the Sui smart contract (basic CHIP token) are executed correctly.
3.  **Tamper-Proof Token Management**: Handle CHIP token reward distributions (simplified for MVP) in a way that prevents unauthorized manipulation.
4.  **Transaction Integrity**: Ensure that blockchain transactions initiated by the API are properly authorized and accurately reflect the intended action.

### Security Architecture (Centralized API Service)

1.  **API Backend Key Management:** The Sui private key used by `sui_service.py` is the most critical secret. It **must** be managed securely:
    *   **No Hardcoding:** Never hardcode the private key in the source code.
    *   **Environment Variables/Secrets:** Store the key securely using environment variables injected during deployment (e.g., Render's secret management).
    *   **Limited Access:** Restrict access to the production environment and secret management tools.
2.  **Controlled Interaction:** All blockchain interactions are funneled through the `sui_service.py` module within the API backend. This centralizes the logic and reduces the points where the key is directly used.
3.  **Input Validation:** The API must rigorously validate all parameters (recipient addresses, amounts) passed to `sui_service.py` functions before constructing blockchain transactions.

## Data Security Measures (Qdrant & API)

1.  **Data Classification:** Identify sensitive data stored in Qdrant (e.g., `intention_memory` content, user-Sui address mappings in `users`).
2.  **Encryption Architecture:**
    *   **Transit:** Use HTTPS for all communication between the client, API, and Qdrant (if Qdrant is hosted externally).
    *   **At Rest (Qdrant):** Rely on Qdrant's underlying storage mechanisms and the hosting provider's infrastructure for at-rest encryption. Consider Qdrant's specific encryption features if available and necessary.
    *   **At Rest (API Secrets):** Ensure the Sui private key and any other API secrets are stored encrypted at rest by the deployment platform (e.g., Render).
3.  **Qdrant Access Control:**
    *   Use API keys or other authentication mechanisms provided by Qdrant to restrict access to authorized services (only the Python API backend).
    *   Implement logical access control within the API backend to ensure, for example, that `intention_memory` is only queried for the currently authenticated user.

## Docker Container Security (API Backend)

1.  **Minimal Images:** Use minimal base images (like `python:3.12-slim`) for the API backend container to reduce the attack surface.
2.  **No Privileged Containers:** Run containers without unnecessary privileges.
3.  **Immutable Infrastructure:** Treat containers as immutable; rebuild and redeploy rather than modifying running containers.
4.  **Vulnerability Scanning:** Integrate vulnerability scanning into the CI/CD pipeline for the Docker image.
5.  **Secret Management:** Inject secrets (like the Sui private key, Qdrant API key) securely into the container environment at runtime, not during the build process.

## Model Security (PostChain Workflow)

1.  **Input Validation/Sanitization:** Sanitize user input passed to the PostChain workflow and subsequently to LLMs to mitigate prompt injection risks.
2.  **Output Filtering:** Filter or sanitize outputs from LLMs, especially if they might be displayed directly or used in sensitive contexts (though less critical if outputs primarily feed other phases or are stored).
3.  **Prompt Security:** Be mindful of prompt engineering techniques to make models less susceptible to jailbreaking or instruction hijacking, particularly for phases that might execute tools based on LLM output (deferred post-MVP).
4.  **Rate Limiting:** Implement rate limiting at the API gateway or within FastAPI to prevent abuse of LLM resources.
5.  **Model Usage Monitoring:** Monitor LLM usage for anomalies that might indicate attacks or misuse.

## Security Logging and Monitoring

1.  **Comprehensive Logging:** Log key security events within the API backend: authentication attempts (success/failure), significant state changes, calls to `sui_service.py`, errors, and potential security anomalies.
2.  **Qdrant Auditing:** If Qdrant provides audit logging features, enable them to monitor database access and operations.
3.  **Infrastructure Monitoring:** Utilize monitoring tools provided by the hosting platform (e.g., Render) to track resource usage, network traffic, and potential infrastructure-level threats.
4.  **Anomaly Detection:** Implement basic anomaly detection rules based on logs and metrics (e.g., sudden spike in failed authentications, unusual Qdrant query patterns, high rate of reward triggers).
5.  **Incident Response Plan:** Have a basic plan for responding to security incidents, including identifying the issue, containing the impact, remediating the vulnerability, and communicating appropriately.

## Future Security Enhancements (Post-MVP)

While the MVP focuses on core security, future enhancements could include:

1.  **Formal Verification:** For critical smart contracts (like a more complex economic or governance contract).
2.  **Quantum-Resistant Cryptography:** For long-term key and signature security (relevant if Sui adopts it).
3.  **Web Application Firewall (WAF):** Protect the API endpoint from common web attacks.
4.  **Enhanced Authentication:** Implement more robust authentication mechanisms beyond simple signature verification if needed.
5.  **Dedicated Secrets Management:** Integrate a dedicated secrets management solution (e.g., HashiCorp Vault) instead of relying solely on platform environment variables.

## Conclusion (MVP Focus)

Securing the Choir Qdrant-Sui MVP relies heavily on securing the central Python API backend and its interactions. Key priorities include: **secure management of the API's Sui private key**, robust input validation for both API endpoints and LLM prompts, proper access control for Qdrant collections, and standard web application security practices for the API itself. While simpler than a distributed TEE-based architecture, this centralized model requires diligent protection of the API backend as the primary trusted component for data access and blockchain interactions in the MVP.

=== File: docs/stack_argument.md ===



==
stack_argument
==


# The Choir Stack Argument: Qdrant-Sui MVP

VERSION stack_argument: 8.0 (Qdrant-Sui MVP Focus)

## Executive Summary

This document argues for the focused technology stack selected for the **Choir Qdrant-Sui Minimum Viable Product (MVP)**. The primary goal of this MVP is to establish and validate the core data flow using Qdrant as the central data and vector store, integrated with a basic Sui blockchain mechanism for the CHIP token and reward structure. This stack leverages existing components where possible (like the current LCEL-based PostChain workflow) to accelerate MVP development while laying the foundation for future scalability.

The core technologies for the Qdrant-Sui MVP are:

1.  **Qdrant:** Central data layer for users, threads, messages (including embedded phase outputs), and phase-specific memory. Handles vector storage and semantic search.
2.  **Sui (via PySUI Service):** Blockchain layer for the CHIP token and reward distribution mechanism (simplified for MVP).
3.  **Python API (FastAPI/Uvicorn):** Orchestration layer handling client requests, PostChain execution, Qdrant interactions, and Sui service calls.
4.  **PostChain Workflow (LCEL Implementation):** The existing `langchain_workflow.py` implementing the AEIOU-Y phases, adapted for refined Qdrant interactions.
5.  **Langchain Utils (`langchain_utils.py`):** LLM abstraction layer used by the PostChain workflow.
6.  **Pydantic:** Data validation for API and internal structures.
7.  **Docker:** Containerization for deployment of the Python API.
8.  **(Client Side) SwiftUI & Keychain:** User interface and secure Sui private key storage.

## Qdrant-Sui MVP Goal

The objective is to build a functional slice of the Choir system that demonstrates:

1.  **Core Data Structure:** Storing users, threads, messages, and phase outputs in Qdrant using a refined schema.
2.  **Semantic Search:** Utilizing Qdrant vector search within the Experience phase to find relevant priors.
3.  **Phase-Specific Memory:** Implementing `intention_memory` and `observation_memory` in Qdrant.
4.  **Reward Triggering:** Calculating basic novelty/similarity scores and triggering a (potentially simulated or basic) reward distribution via the Sui service based on message creation and citation.
5.  **End-to-End Flow:** A user interacting via the SwiftUI client, triggering the PostChain workflow via the API, interacting with Qdrant, and potentially initiating a basic Sui reward action.

## The Core MVP Stack & Rationale

1.  **Qdrant (Central Data Layer):**
    *   **Role:** The **single source of truth** for all data relevant to the AI processing loop and reward mechanism. Stores user mappings, thread metadata, core conversation turns (user prompts & final AI responses), embedded internal phase outputs, and phase-specific memory collections (`intention_memory`, `observation_memory`). Crucial for the Experience phase's vector search (global priors) and provides the necessary inputs (novelty/similarity scores, author/prior linkage) for the reward system.
    *   **Why Chosen for MVP:** Essential for the core concept; vector search is fundamental to Experience/rewards. Centralizing here simplifies the MVP backend. Using existing collections (`choir`, `users`, `chat_threads`) with schema refinement is pragmatic. Adding `intention_memory` and `observation_memory` provides the necessary specialized storage.

2.  **Sui (via PySUI Service - Blockchain Layer):**
    *   **Role:** Manages the CHIP token (basic existence contract) and executes the reward distribution logic triggered by the API. For MVP, this logic might be simplified (e.g., basic minting or even off-chain logging of intended rewards). The `sui_service.py` encapsulates PySUI interactions.
    *   **Why Chosen for MVP:** Core to the "tokenized marketplace" vision. Integrating a basic version early validates the concept and technical feasibility. PySUI provides the necessary SDK.

3.  **Python API (FastAPI/Uvicorn - Orchestration Layer):**
    *   **Role:** The central hub. Handles client authentication (via Sui signature verification), orchestrates the `langchain_workflow.py` execution for the PostChain, mediates all interactions with Qdrant (`database.py`), triggers the Sui service (`sui_service.py`) for rewards, and manages SSE streaming to the client.
    *   **Why Chosen for MVP:** Provides a necessary interface between the client, the AI logic, and the data/blockchain layers. FastAPI is performant and integrates well with Pydantic.

4.  **PostChain Workflow (LCEL - Core AI Logic):**
    *   **Role:** Implements the AEIOU-Y phases sequentially using the existing Langchain Expression Language (LCEL) structure in `langchain_workflow.py`. This logic is adapted to read from/write to the designated Qdrant collections (via the API/`database.py`). The Experience phase calculates novelty/similarity scores. The Yield phase structures the final AI message with embedded phase outputs and triggers the reward calculation via the API.
    *   **Why Chosen for MVP:** **Leverages existing, functional code.** Avoids a major refactor for the MVP, allowing faster progress on the core Qdrant/Sui integration. LCEL provides a clear structure for the sequential phase execution.

5.  **Langchain Utils (`langchain_utils.py` - LLM Abstraction):**
    *   **Role:** Provides a consistent interface to multiple LLM providers, allowing the PostChain workflow to utilize different models without being tightly coupled to specific provider APIs.
    *   **Why Chosen for MVP:** Already implemented and essential for the PostChain workflow's LLM interactions. Supports flexibility.

6.  **Pydantic (Data Integrity):**
    *   **Role:** Ensures data consistency and validation for API requests/responses and internal data structures used within the PostChain workflow and Qdrant interactions.
    *   **Why Chosen for MVP:** Best practice for robust Python development, especially with APIs and complex data structures. Reduces errors.

7.  **Docker (Deployment):**
    *   **Role:** Containerizes the Python API service (including all its dependencies like FastAPI, Langchain, PySUI, Qdrant client) for consistent and reproducible deployment.
    *   **Why Chosen for MVP:** Standard for modern web service deployment, simplifying setup and ensuring environment consistency.

8.  **(Client) SwiftUI & Keychain:**
    *   **Role:** Provides the user interface for interaction. Securely stores the user's Sui private key using the device Keychain. Handles message signing for authentication. Displays streamed PostChain outputs.
    *   **Why Chosen for MVP:** Native iOS provides the best user experience and secure key management capabilities required.

## Why This Stack for the MVP?

*   **Focus:** Directly targets the core Qdrant-Sui integration, which is the central hypothesis to validate.
*   **Speed & Pragmatism:** Reuses the existing `langchain_workflow.py` (LCEL implementation), significantly reducing the initial development effort.
*   **Simplicity:** Defers complexities not strictly necessary to prove the core Qdrant-Sui concept.
*   **Validation:** Allows for rapid validation of the proposed Qdrant data structures, the basic reward trigger mechanism, and the end-to-end user flow.

## Synergy within the MVP Stack

The Qdrant-Sui MVP stack creates a clear data and execution flow:

1.  **Client (SwiftUI):** User interacts, signs request with Sui key (Keychain).
2.  **API (FastAPI):** Authenticates user (verifies signature, maps Sui address to Qdrant User ID via `users` collection), receives prompt, initiates PostChain workflow.
3.  **PostChain (LCEL):** Executes AEIOU-Y phases sequentially.
    *   Uses **Langchain Utils** to call LLMs.
    *   Interacts with **Qdrant** via API/`database.py` for memory (`intention_memory`, `observation_memory`) and priors (`choir` collection).
    *   Experience phase calculates novelty/similarity scores using Qdrant results.
    *   Yield phase bundles outputs into a single AI message structure.
4.  **API (FastAPI):** Receives final AI message structure from Yield, stores it in **Qdrant** (`choir` collection), triggers **Sui Service**.
5.  **Sui Service:** Calculates basic reward distribution, interacts with **Sui Blockchain** (basic mint/log).
6.  **API (FastAPI):** Streams phase outputs (via SSE) back to the Client.
7.  **Client (SwiftUI):** Displays conversation and phase outputs.

## Path Forward (Beyond MVP)

This MVP stack provides a solid foundation. Future iterations can build upon it:

*   **Refine Reward Logic:** Implement the sophisticated reward splitting formula on Sui or via a secure off-chain oracle.
*   **Scale PostChain:** Address performance bottlenecks in the `langchain_workflow.py` as needed, potentially by optimizing or modularizing phase execution.
*   **Enhance Client:** Implement client-side caching for improved offline experience and UI responsiveness.
*   **Security Hardening:** Implement enhanced security measures for the API and blockchain interactions.
*   **Add Features:** Implement governance, advanced tool use, multi-modality, etc.

## Conclusion

The proposed Qdrant-Sui MVP stack is a pragmatic and focused approach. It prioritizes the core integration of Qdrant for AI data management and Sui for the token economy, leveraging existing components like the LCEL-based PostChain workflow for rapid development and validation. This stack allows us to quickly test the fundamental concepts of Choir's data and reward system.

=== File: docs/state_management_patterns.md ===



==
state_management_patterns
==


# State Management Patterns in Choir (Qdrant-Sui MVP)

VERSION state_management_patterns: 8.0 (Qdrant-Sui MVP Focus)

## Overview

State management is crucial for the Choir platform. In the Qdrant-Sui MVP, the primary focus is on managing state within the central Python API and persisting core data within Qdrant. This document outlines the state management patterns specific to this MVP architecture. Client-side caching and distributed server state are deferred post-MVP.

## State Management in the Qdrant-Sui MVP

The state is primarily managed in two locations:

1.  **Python API (In-Memory during Request Processing):** The FastAPI application manages the *transient state* of a single PostChain execution cycle for a given user request.
2.  **Qdrant (Persistent State):** Qdrant serves as the **persistent source of truth** for all core data entities required for the AI workflow and the reward system.

## 1. Python API: Orchestration & Transient State

*   **Role:** The Python API acts as the central orchestrator. For each incoming user request, it manages the flow through the PostChain (AEIOU-Y) phases implemented in `langchain_workflow.py`.
*   **Transient State Handling:**
    *   **Workflow Context:** During a single PostChain cycle triggered by a user message, the API holds the intermediate outputs from each phase (Action, Experience, etc.) in memory. This context (including text outputs, calculated scores, potential citations) is passed sequentially from one phase function to the next within the `langchain_workflow.py`.
    *   **Stateless Between Requests:** The API itself aims to be largely stateless *between* distinct user requests/PostChain cycles. All necessary persistent state is fetched from or saved to Qdrant at the beginning or end of the request processing cycle.
    *   **Concurrency:** FastAPI and Python's `asyncio` handle concurrent user requests. Care must be taken within the workflow logic if shared resources (beyond Qdrant/Sui services which handle their own concurrency) are accessed, but the primary state (conversation history, memory) is managed via Qdrant, pushing concurrency control largely to the database/service layer.

## 2. Qdrant: Persistent State Management

*   **Role:** Qdrant is the **authoritative persistent store** for the MVP.
*   **Managed Entities:**
    *   **`users`:** Maps Sui addresses to internal user IDs. Persistent user identity link.
    *   **`chat_threads`:** Stores metadata about conversation threads. Persistent thread context.
    *   **`choir` (Messages):** Stores the core conversational turns (user prompts, final AI responses). Critically, AI responses embed the outputs from *all* internal PostChain phases (`phase_outputs` dictionary), novelty/similarity scores, and citation links (`cited_prior_ids`). This collection is the persistent record of the conversation history and the primary input for reward calculations.
    *   **`intention_memory`:** Persists user-specific goals and preferences across multiple turns and sessions, queryable by the Intention phase. Filtered by `user_id`.
    *   **`observation_memory`:** Persists thread-specific concepts and summaries across multiple turns and sessions, queryable by the Observation phase (and potentially Experience). Filtered by `thread_id`.
*   **Data Integrity & Access:** The Python API (via `database.py`) is responsible for all CRUD operations on Qdrant, ensuring data is structured according to the defined schemas (using Pydantic for validation) before persistence. Access control for user-specific memory (`intention_memory`) is enforced by filtering queries based on the authenticated `user_id`.

## 3. Client (SwiftUI): UI State & Keychain

*   **Role:** Manages the user interface state and secure key storage.
*   **State Handled:**
    *   **UI State:** Current view, input field content, display state of messages and phases (fetched from API).
    *   **Sui Private Key:** Securely stored in the device Keychain. Used for signing authentication messages.
### Update (2025-04-09): iOS Client Local Persistence

As of April 9, 2025, the iOS client **replaced previous persistence methods** (such as SwiftData) with a **local file-based JSON storage** approach:

- Each thread and its associated messages are saved as a **single JSON file** on device storage.
- This improves transparency, simplifies debugging, and enhances offline access.
- The files are managed by the app's `ThreadPersistenceService`, which handles reading/writing JSON representations of threads.
- This approach fully replaces previous CoreData/SwiftData-based persistence.

This change aligns with a simplified, file-centric architecture for local data management on iOS.
*   **No Persistent App Data (MVP):** For the MVP, the client **does not** maintain its own persistent cache of conversation history. It fetches conversation data from the API as needed for display. Offline access is deferred post-MVP.

## State Flow Example (Single Turn)

1.  User sends message via SwiftUI Client. Client signs request hash with Sui Key.
2.  Python API receives request, verifies signature, maps Sui Address to Qdrant User ID (`users` collection). Fetches relevant thread context (`chat_threads`, recent messages from `choir`).
3.  API initiates PostChain workflow (`langchain_workflow.py`) with user message and thread context.
4.  **Phase Execution (Transient State):**
    *   Action phase runs.
    *   Experience phase runs: Queries `choir` (Qdrant) for priors, calculates scores.
    *   Intention phase runs: Queries/updates `intention_memory` (Qdrant).
    *   Observation phase runs: Queries/updates `observation_memory` (Qdrant).
    *   Understanding phase runs: May trigger deletes in `intention_memory`/`observation_memory` (Qdrant).
    *   Yield phase runs: Bundles all phase outputs.
    *   *(Intermediate outputs are held in memory by the API/workflow runner during this sequence)*.
5.  API receives final bundled AI response data from Yield.
6.  API **persists** the new AI message (with embedded `phase_outputs`, scores, citations) to the `choir` collection in Qdrant.
7.  API triggers the Sui Service with relevant data (message ID, author ID, prior IDs, scores) from the persisted Qdrant entry.
8.  API streams phase outputs (potentially fetched back from the newly saved Qdrant entry or held from step 4) back to the Client via SSE.
9.  Client updates UI state based on SSE stream.

## Conclusion (MVP Focus)

The Qdrant-Sui MVP employs a pragmatic state management strategy. Persistent state critical for the AI workflow and reward system resides centrally in Qdrant, managed by the Python API. The API handles transient state during request processing. The client manages UI state and the user's private key. This approach minimizes complexity for the MVP, allowing focus on validating the core Qdrant-Sui data flow and reward mechanism.
