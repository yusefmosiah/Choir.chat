# Level 0 Documentation



=== File: docs/tree.md ===



==
tree.md
==


# Choir Directory Structure
## Output of $ tree -I 'venv|archive|__pycache__|iOS_Example|dependencies' | pbcopy

.
├── CLAUDE.md
├── Choir
│   ├── App
│   │   └── ChoirApp.swift
│   ├── Assets.xcassets
│   │   ├── AccentColor.colorset
│   │   │   └── Contents.json
│   │   ├── AppIcon.appiconset
│   │   │   ├── Contents.json
│   │   │   └── Icon-App-1024x1024@2x.png
│   │   ├── Contents.json
│   │   └── Icon-App-1024x1024.imageset
│   │       ├── Contents.json
│   │       └── Icon-App-1024x1024@2x.png
│   ├── Choir.entitlements
│   ├── ContentView.swift
│   ├── Coordinators
│   │   ├── MockChorusCoordinator.swift
│   │   └── RESTChorusCoordinator.swift
│   ├── Info.plist
│   ├── Models
│   │   ├── ChoirThread.swift
│   │   ├── ChorusModels.swift
│   │   └── Phase.swift
│   ├── Networking
│   │   └── ChorusAPIClient.swift
│   ├── Preview Content
│   │   └── Preview Assets.xcassets
│   │       └── Contents.json
│   ├── Protocols
│   │   └── ChorusCoordinator.swift
│   ├── Services
│   │   ├── KeychainService.swift
│   │   └── WalletManager.swift
│   ├── ViewModels
│   │   └── ChorusViewModel.swift
│   └── Views
│       ├── ChoirThreadDetailView.swift
│       ├── ChorusCycleView.swift
│       ├── Components
│       ├── MessageRow.swift
│       ├── Thread
│       │   └── Components
│       │       ├── ThreadInputBar.swift
│       │       └── ThreadMessageList.swift
│       └── WalletView.swift
├── Choir.xcodeproj
│   ├── project.pbxproj
│   ├── project.xcworkspace
│   │   ├── contents.xcworkspacedata
│   │   ├── xcshareddata
│   │   │   └── swiftpm
│   │   │       ├── Package.resolved
│   │   │       └── configuration
│   │   └── xcuserdata
│   │       └── wiz.xcuserdatad
│   │           ├── IDEFindNavigatorScopes.plist
│   │           └── UserInterfaceState.xcuserstate
│   └── xcuserdata
│       └── wiz.xcuserdatad
│           ├── xcdebugger
│           │   └── Breakpoints_v2.xcbkptlist
│           └── xcschemes
│               └── xcschememanagement.plist
├── ChoirTests
│   ├── APIResponseTests.swift
│   ├── ChoirTests.swift
│   ├── ChoirThreadTests.swift
│   └── ChorusAPIClientTests.swift
├── ChoirUITests
│   ├── ChoirUITests.swift
│   └── ChoirUITestsLaunchTests.swift
├── api
│   ├── Dockerfile
│   ├── __init__.py
│   ├── app
│   │   ├── __init__.py
│   │   ├── chorus_cycle.py
│   │   ├── chorus_graph.py
│   │   ├── config.py
│   │   ├── database.py
│   │   ├── langchain_utils.py
│   │   ├── models
│   │   │   ├── __init__.py
│   │   │   └── api.py
│   │   ├── postchain
│   │   │   ├── __init__.py
│   │   │   ├── api.py
│   │   │   ├── provider_info.md
│   │   │   └── schemas
│   │   │       ├── __init__.py
│   │   │       ├── aeiou.py
│   │   │       └── state.py
│   │   ├── routers
│   │   │   ├── balance.py
│   │   │   ├── chorus.py
│   │   │   ├── embeddings.py
│   │   │   ├── postchain.py
│   │   │   ├── threads.py
│   │   │   ├── users.py
│   │   │   └── vectors.py
│   │   ├── services
│   │   │   ├── __init__.py
│   │   │   ├── chorus.py
│   │   │   └── sui_service.py
│   │   ├── tools
│   │   │   ├── __init__.py
│   │   │   ├── base.py
│   │   │   ├── brave_search.py
│   │   │   ├── calculator.py
│   │   │   ├── conversation.py
│   │   │   ├── duckduckgo_search.py
│   │   │   ├── qdrant.py
│   │   │   ├── qdrant_workflow.py
│   │   │   ├── tavily_search.py
│   │   │   └── web_search.py
│   │   └── utils.py
│   ├── main.py
│   ├── postchain_tests.log
│   ├── pyproject.toml
│   ├── pytest.ini
│   ├── requirements.txt
│   ├── run_tests.sh
│   ├── test_reports
│   │   └── groq
│   │       ├── deepseek_r1_distill_llama_70b_specdec_super_bowl_search_20250307_180115.json
│   │       ├── deepseek_r1_distill_llama_70b_specdec_super_bowl_search_20250307_180115.md
│   │       ├── deepseek_r1_distill_llama_70b_super_bowl_search_20250307_180124.json
│   │       ├── deepseek_r1_distill_llama_70b_super_bowl_search_20250307_180124.md
│   │       ├── deepseek_r1_distill_qwen_32b_super_bowl_search_20250307_180112.json
│   │       ├── deepseek_r1_distill_qwen_32b_super_bowl_search_20250307_180112.md
│   │       ├── llama_3.3_70b_versatile_super_bowl_search_20250307_180054.json
│   │       ├── llama_3.3_70b_versatile_super_bowl_search_20250307_180054.md
│   │       ├── qwen_qwq_32b_super_bowl_search_20250307_180055.json
│   │       └── qwen_qwq_32b_super_bowl_search_20250307_180055.md
│   └── tests
│       ├── __init__.py
│       ├── conftest.py
│       ├── postchain
│       │   ├── __init__.py
│       │   ├── analysis.py
│       │   ├── random_gen_prompts.md
│       │   ├── run_all_tests.py
│       │   ├── run_tests.py
│       │   ├── test_cases.json
│       │   ├── test_cases.py
│       │   ├── test_fast_looping.py
│       │   ├── test_framework.py
│       │   ├── test_langgraph_multiturn.py
│       │   ├── test_langgraph_multiturn_abstracted.py
│       │   ├── test_providers.py
│       │   ├── test_providers_abstracted.py
│       │   ├── test_random_multimodel.py
│       │   ├── test_random_multimodel_stream.py
│       │   ├── test_simple_multimodel.py
│       │   ├── test_simple_multimodel_stream.py
│       │   ├── test_structured_output.py
│       │   ├── test_structured_output_abstracted.py
│       │   ├── test_tool_multimodel.py
│       │   ├── test_tool_random_multimodel.py
│       │   └── test_utils.py
│       ├── results
│       │   ├── basic_flow
│       │   │   ├── final_state.json
│       │   │   ├── interactions.jsonl
│       │   │   └── metadata.json
│       │   ├── confidence_thresholds
│       │   │   ├── final_state.json
│       │   │   ├── interactions.jsonl
│       │   │   └── metadata.json
│       │   ├── error_handling
│       │   │   ├── final_state.json
│       │   │   ├── interactions.jsonl
│       │   │   └── metadata.json
│       │   ├── looping_behavior
│       │   │   ├── final_state.json
│       │   │   ├── interactions.jsonl
│       │   │   └── metadata.json
│       │   └── tool_integration
│       │       ├── final_state.json
│       │       ├── interactions.jsonl
│       │       └── metadata.json
│       ├── test_chorus_endpoints.py
│       ├── test_core_endpoints.py
│       ├── test_main.py
│       ├── test_response_schemas.py
│       ├── test_structured_outputs.py
│       ├── test_sui_service.py
│       ├── test_user_thread_endpoints.py
│       └── tools
│           ├── __init__.py
│           ├── direct_search_diagnostic.py
│           ├── direct_search_test.py
│           ├── haiku_search_test.py
│           ├── langgraph_test.py
│           ├── run_tool_tests.py
│           ├── test_anthropic_langgraph.py
│           ├── test_brave_search.py
│           ├── test_calculator.py
│           ├── test_duckduckgo_search.py
│           ├── test_langgraph_providers_tools.py
│           ├── test_multimodel_with_tools.py
│           ├── test_provider_langgraph.py
│           ├── test_qdrant.py
│           ├── test_qdrant_workflow.py
│           ├── test_recent_events.py
│           ├── test_search_tools_report.py
│           ├── test_tavily_search.py
│           └── test_updated_search.py
├── choir_coin
│   └── choir_coin
│       ├── Move.lock
│       ├── Move.toml
│       ├── build
│       │   └── choir
│       │       ├── BuildInfo.yaml
│       │       ├── bytecode_modules
│       │       │   ├── choir.mv
│       │       │   └── choir_tests.mv
│       │       ├── source_maps
│       │       │   ├── choir.json
│       │       │   ├── choir.mvsm
│       │       │   ├── choir_tests.json
│       │       │   └── choir_tests.mvsm
│       │       └── sources
│       │           ├── choir.move
│       │           └── choir_tests.move
│       ├── sources
│       │   └── choir_coin.move
│       └── tests
│           └── choir_coin_tests.move
├── docker-compose.yml
├── docs
│   ├── CHANGELOG.md
│   ├── core_core.md
│   ├── core_economics.md
│   ├── core_state_transitions.md
│   ├── data_engine_model.md
│   ├── e_business.md
│   ├── e_concept.md
│   ├── evolution_naming.md
│   ├── evolution_token.md
│   ├── fqaho_simulation.md
│   ├── fqaho_visualization.md
│   ├── levels
│   │   ├── all.txt
│   │   ├── level0.md
│   │   ├── level1.md
│   │   ├── level2.md
│   │   ├── level3.md
│   │   ├── level4.md
│   │   └── level5.md
│   ├── plan_anonymity_by_default.md
│   ├── plan_identity_as_a_service.md
│   ├── plan_langgraph.md
│   ├── plan_langgraph_postchain.md
│   ├── plan_libsql.md
│   ├── plan_model_config_checklist.md
│   ├── plan_postchain_checklist.md
│   ├── plan_tools_qdrant_checklist.md
│   ├── plan_tools_search_checklist.md
│   ├── scripts
│   │   ├── combiner.sh
│   │   └── update_tree.sh
│   └── tree.md
├── notebooks
│   ├── fqaho_simulation.ipynb
│   ├── post_chain0.ipynb
│   └── vowel_loop3.ipynb
├── postchain_tests.log
├── render.yaml
├── reports
└── scripts
    ├── generate_provider_reports.sh
    ├── generate_quick_search_report.sh
    ├── generate_search_report.sh
    └── generate_single_provider_report.sh

66 directories, 212 files

=== File: docs/CHANGELOG.md ===



==
CHANGELOG.md
==


# Changelog

## [2025-02-25] - 2025-02-25

### Added

- Implemented UI carousel to improve user experience
- Added display of priors in the Experience step
- Resumed active development after coding hiatus

### Planned

- API streaming implementation to enhance responsiveness
- Model reconfiguration for improved performance
- Go multimodel, then multimodal
- OpenRouter integration
- Conceptual evolution from "Chorus Cycle" to "Post Chain"
  - Representing shift from harmonic oscillator (cycle) to anharmonic oscillator (chain)
  - Aligning interface terminology with underlying FQAHO model
- Client-side editable system prompts for customization
- Additional phases in the Post Chain:
  - Web search phase for real-time information access
  - Sandboxed arbitrary tool use phase for enhanced capabilities

## [2025-02-24] - 2025-02-24

### Changed

- Implemented fractional quantum anharmonic oscillator model for dynamic stake pricing
- Added fractional parameter α to capture memory effects and non-local interactions
- Revised parameter modulation formulas for K₀, α, and m to reflect interdependencies
- Created simulation framework for parameter optimization

## [2025-02-23] - 2025-02-23

### Changed

- Documented quantum anharmonic oscillator model implementation and dynamic stake pricing mechanism via an effective anharmonic coefficient modulated by approval/refusal statistics.

## [Unreleased]

### Changed

- Updated all documentation to version 6.0
  - Transformed structured documentation into fluid prose
  - Relaxed event-driven architecture requirements for initial TestFlight
  - Clarified implementation priorities and post-funding features
  - Maintained theoretical frameworks while focusing on core functionality

### Added

- Initial Chorus cycle working in iOS simulator
  - Basic message flow through phases
  - Response handling
  - State management

### Documented

- Created 15 comprehensive issues covering:
  - Core message system implementation
  - Type reconciliation with Qdrant
  - API client updates
  - Coordinator message flow
  - User identity management
  - Thread state management
  - Integration testing
  - Error handling strategy
  - Performance monitoring
  - State recovery
  - Thread sheet implementation
  - Thread contract implementation
  - Message rewards system
  - LanceDB migration
  - Citation visualization

### Architecture

- Defined clear type system for messages
- Planned migration to LanceDB
- Structured multimodal support strategy

### Technical Debt

- Identified areas needing more specification:
  - Thread Sheet UI (marked as "AI SLOP")
  - Reward formulas need verification
  - Migration pipeline needs careful implementation

## [0.4.2] - 2024-11-09

### Added

- Development principles with focus on groundedness
- Basic chat interface implementation
- SwiftData message persistence
- Initial Action step foundation

### Changed

- Shifted to iterative, ground-up development approach
- Simplified initial implementation scope
- Focused on working software over theoretical architecture
- Adopted step-by-step Chorus Cycle implementation strategy

### Principles

- Established groundedness as core development principle
- Emphasized iterative growth and natural evolution
- Prioritized practical progress over theoretical completeness
- Introduced flexible, evidence-based development flow

## [0.4.1] - 2024-11-08

### Added

- Self-creation process
- Post-training concepts
- Concurrent processing ideas
- Democratic framing
- Thoughtspace visualization

### Changed

- Renamed Update to Understanding
- Enhanced step descriptions
- Refined documentation focus
- Improved pattern recognition

## [0.4.0] - 2024-10-30

### Added

- Swift architecture plans
- Frontend-driven design
- Service layer concepts
- Chorus cycle definition

### Changed

- Enhanced system architecture
- Refined core patterns

## [0.3.5] - 2024-09-01

- Choir.chat as a web3 dapp
- messed around with solana
- used a lot of time messing with next.js/react/typescript/javascript
- recognized that browser extension wallet is terrible ux

## [0.3.0] - 2024-03-01

### Added

- ChoirGPT development from winter 2023 to spring 2024

- First developed as a ChatGPT plugin, then a Custom GPT
- The first global RAG system / collective intelligence as a GPT

## [0.2.10] - 2023-04-01

### Added

- Ahpta development from winter 2022 to spring 2023

## [0.2.9] - 2022-04-01

### Added

- V10 development from fall 2021 to winter 2022

## [0.2.8] - 2021-04-01

### Added

- Elevisio development from spring 2020 to spring 2021

## [0.2.7] - 2020-04-01

### Added

- Bluem development from spring 2019 to spring 2020

## [0.2.6] - 2019-04-01

### Added

- Blocstar development from fall 2018 to spring 2019

## [0.2.5] - 2018-04-01

### Added

- Phase4word development from summer 2017 to spring 2018

### Changed

- Showed Phase4word to ~50 people in spring 2018, received critical feedback
- Codebase remains in 2018 vintage

## [0.2.0] - 2016-06-20

### Added

- Phase4 party concept
- Early democracy technology
- Initial value systems

### Changed

- Moved beyond truth measurement framing
- Refined core concepts

## [0.1.0] - 2015-07-15

### Added

- Initial simulation hypothesis insight
- "Kandor"
- Quantum information concepts
- Planetary coherence vision
- Core system ideas

=== File: docs/scripts/combiner.sh ===



==
combiner.sh
==


#!/bin/bash

# Revised prefix arrays
level0_prefixes=("")  # Basic technical integration
level1_prefixes=("core")  # Core system components
level2_prefixes=("e")           # Business/concept/implementation
level3_prefixes=("plan")               # State/economic models
level4_prefixes=("fqaho")     # Simulations
level5_prefixes=("evolution" "data")             # Foundational principles

# Function to add separator and header
add_separator() {
    echo -e "\n"
    echo "=="
    echo "$1"
    echo "=="
    echo -e "\n"
}

# Function to get level for a file
get_level_for_file() {
    filename=$(basename "$1")
    prefix=$(echo "$filename" | cut -d'_' -f1)

    for p in "${level0_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 0 && return; done
    for p in "${level1_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 1 && return; done
    for p in "${level2_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 2 && return; done
    for p in "${level3_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 3 && return; done
    for p in "${level4_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 4 && return; done
    for p in "${level5_prefixes[@]}"; do [[ "$prefix" == "$p" ]] && echo 5 && return; done

    echo -1
}

# Function to process files for a level
process_level() {
    level=$1
    output_file="docs/levels/level${level}.md"

    echo "# Level ${level} Documentation" > "$output_file"
    echo -e "\n" >> "$output_file"

    SPECIAL_FILES=("docs/prompt_wake_up.md" "docs/prompt_getting_started.md" "docs/prompt_reentry.md" "docs/prompt_organization.md" "docs/prompt_summary_prompt.md" "docs/prompt_chorus_cycle.md" "docs/tree.md" "docs/CHANGELOG.md" "docs/scripts/combiner.sh")

    # Level 0 now includes important system files (previously in level -1)
    if [ "$level" -eq 0 ]; then
        # Add system files (previously in level -1)
        for special_file in "${SPECIAL_FILES[@]}"; do
            if [ -f "$special_file" ]; then
                echo -e "\n=== File: $special_file ===\n" >> "$output_file"
                add_separator "$(basename "$special_file")" >> "$output_file"
                cat "$special_file" >> "$output_file"
                echo "$special_file" >> "/tmp/processed_files.txt"
            fi
        done

    fi

    # Process all docs to find ones for this level
    for file in docs/*.md; do
        if [ -f "$file" ] && [ "$(get_level_for_file "$file")" -eq "$level" ]; then
            echo -e "\n=== File: $file ===\n" >> "$output_file"
            add_separator "$(basename "$file" .md)" >> "$output_file"
            cat "$file" >> "$output_file"
            echo "$file" >> "/tmp/processed_files.txt"
        fi
    done
}

# Create temporary file for tracking
touch /tmp/processed_files.txt

# Process all levels (excluding level -1 as its content is now in level 0)
echo "Processing documentation..."
for level in {0..5}; do
    process_level $level
done

# Concatenate all levels into a single file
echo "Combining all levels into one file..."
mkdir -p docs/levels
cat docs/levels/level{0..5}.md > docs/levels/all.txt

# Check for uncategorized files
echo -e "\nUncategorized files:"
uncategorized=0
for doc in docs/*.md; do
    if ! grep -q "^$doc$" "/tmp/processed_files.txt"; then
        echo "$doc"
        uncategorized=$((uncategorized + 1))
    fi
done

if [ "$uncategorized" -gt 0 ]; then
    echo -e "\nTotal uncategorized: $uncategorized files"
fi

# Cleanup
rm -f "/tmp/processed_files.txt"

echo "Documentation combination complete"
# Level 1 Documentation



=== File: docs/core_core.md ===



==
core_core
==


# Core System Overview

VERSION core_system: 7.0

Note: This document describes the core system architecture, with initial focus on TestFlight functionality. More sophisticated event-driven mechanisms described here will be implemented post-funding.

The Choir system is built around a clear hierarchy of truth and state management. At its foundation, the blockchain serves as the authoritative source for all ownership and economic state – thread ownership, token balances, message hashes, and co-author lists. This ensures that the economic model, with its fractional equity distribution and fractional quantum anharmonic thread evolution (where dynamic parameter modulation is driven by approval/refusal feedback and memory effects), has an immutable and verifiable foundation.

Alongside the blockchain, Qdrant acts as the authoritative source for all content and semantic relationships. It stores the actual message content, embeddings, and the growing network of citations and semantic links. This separation of concerns allows the system to maintain both economic integrity through the blockchain and rich semantic relationships through the vector database.

The AEIOU-Y chorus cycle sits at the heart of the interaction model, processing user input through a series of well-defined steps. The cycle begins with pure response in the Action step, enriches it with prior knowledge in the Experience step, aligns with user intent in the Intention step, records semantic connections in the Observation step, decides on continuation in the Update step, and produces the final response in the Yield step.

State updates flow naturally between these components. When a user submits input, the system coordinates necessary updates across the UI, blockchain, and vector store. The chorus cycle processes the input while maintaining system state consistency. These state changes are carefully managed to maintain data integrity and system coherence.

The economic model employs FQAHO-based dynamics: the system parameters (α, K₀, m) evolve based on thread history and network position. The fractional parameter α captures memory effects and non-local interactions, decreasing from 2 toward 1 as threads mature. The anharmonic coefficient K₀ increases when a thread receives many refusals and decreases with strong approval. The potential order m reflects thread complexity and network depth. This parameter evolution naturally filters quality while accounting for memory effects and non-local interactions.

Equity is distributed according to fractional formulas, ensuring fair value attribution while maintaining mathematical elegance and accounting for memory effects. The distribution follows E(s) = (1/N) \* (s/P₀)^(α/2), balancing co-author count with stake amount and the thread's fractional parameter.

The knowledge system builds a growing semantic network through citations and prior references, with non-local interactions captured by the fractional approach. Each message can reference previous messages as priors, creating a web of semantic relationships with long-range correlations. These relationships are stored in Qdrant and help inform future responses through the Experience step of the chorus cycle.

State management follows the natural hierarchy of truth. The chain state is authoritative for ownership and economics. The vector state is authoritative for content and semantics. Local state serves only to coordinate UI updates and handle temporary synchronization needs. This clear hierarchy ensures system consistency while enabling responsive user interaction.

All of this is implemented using Swift's modern concurrency system. Async/await enables clean asynchronous code. Structured concurrency through task groups ensures proper resource management. The architecture maintains loose coupling between components while ensuring system coherence.

The result is a system that combines economic incentives, semantic knowledge, and natural interaction patterns into a coherent whole. The blockchain provides economic integrity. The vector database enables semantic richness. The chorus cycle creates natural interaction. The fractional quantum approach captures memory effects and non-local interactions. And Swift's concurrency model keeps it all running smoothly and safely.

This architecture enables the system to evolve naturally. The semantic network grows organically through usage with long-range correlations. The economic model creates emergent quality barriers through coupled parameter evolution. And the whole system maintains consistency through its clear hierarchy of truth and well-defined state management patterns.

=== File: docs/core_economics.md ===



==
core_economics
==


# Core Economic Model

VERSION core_economics: 7.0

The economic model operates as a fractional quantum anharmonic system, anchored by the Move Virtual Machine as its source of truth. The model orchestrates value flows through stake dynamics modulated by collective feedback signals and non-local memory effects.

At its foundation, the system tracks economic events through the blockchain. These events capture stake movements, parameter adjustments, equity distributions, and reward issuance. Each event carries a unique identifier, precise timestamp, and rich metadata that ensures perfect traceability.

The chain state manager serves as the authoritative bridge between the economic model and the blockchain. It retrieves thread economics directly from smart contracts, maintaining an accurate view of stake prices, model parameters, token balances, and equity distributions. All economic transactions flow through this manager, ensuring that on-chain state changes trigger appropriate event cascades throughout the system.

The model's core strength lies in its fractional quantum anharmonic calculations. The base price follows a modified FQAHO model:

P₀ = S₀[(2n+1)^(α/2) + (K₀λ)^{α/(m+1)}]

Where:

- α = Fractional parameter (1<α≤2) capturing memory effects and non-local interactions
- K₀ = Anharmonic coefficient dynamically modulated by recent approval/refusal statistics
- m = Potential order reflecting thread complexity and network depth
- n = Excitation level (capturing thread activity)

The fractional parameter α evolves according to:

α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

Where t represents normalized thread age, q measures quality through approval ratios, τ sets the time constant, and δ₁, δ₂ determine sensitivity.

Equity distribution follows a fractional square root law reflecting quantum amplitude principles:

E(s) = (1/N) \* (s/P₀)^(α/2)

This formula elegantly balances the number of co-authors N with the stake amount s, normalized by the base price P₀, ensuring fair value distribution across participants while accounting for memory effects.

The economic handler processes these events through a carefully orchestrated flow. When stake is deposited, it calculates new equity shares based on the current parameter values and organizational frequency. Collective feedback triggers parameter recalculations that maintain system equilibrium. Each event flows through the handler, ensuring proper economic state transitions.

Analytics and monitoring provide real-time insight into the economic system's health. The system tracks stake movements, parameter adjustments, equity distributions, and reward issuance. This data feeds back into the system, enabling natural price discovery and value distribution.

The economic model's strength emerges from several key principles. The blockchain serves as the immutable source of truth, while value flows follow fractional conservation laws. Price discovery emerges naturally through eigenvalue patterns of the fractional system, and state changes propagate through Lévy flight-like transitions. Most importantly, complex economic behaviors arise organically from these simple underlying rules.

Through this careful balance of blockchain authority, fractional mathematical precision, and natural value flows, the economic model creates a self-sustaining ecosystem for knowledge work. The system's elegance lies in how these principles work together, creating a robust economic framework that adapts and evolves while maintaining fundamental stability.

# Dynamic Parameter Evolution

## Fractional Parameter (α)

α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

## Anharmonic Coefficient (K₀)

K₀(r,α) = K₀_base _ (1 + γ₁r) _ (2/α)^γ₂

## Potential Order (m)

m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)

=== File: docs/core_state_transitions.md ===



==
core_state_transitions
==


# Core State Transitions

VERSION core_state_transitions: 7.0

The state transition system orchestrates the evolution of thread states through carefully defined transformations. These transitions follow precise fractional mathematical principles that ensure non-local energy conservation, dynamic parameter recalibration, and frequency coherence across the network.

Thread Creation establishes the initial quantum state. Each new thread begins with α = 2 (standard quantum mechanics), baseline anharmonic coefficient (K₀_base), and potential order m = 2. The creator's address becomes the first co-author, and the thread maintains an empty set of message hashes. This initial state provides a foundation for future non-local evolution.

Message Submission follows fractional quantum anharmonic energy principles. The required stake follows E(n) = (2n+1)^(α/2) + (K₀λ)^(α/(m+1)), where α, K₀, and m reflect the thread's history and network position. Each message generates a unique hash and carries its quantized energy contribution to the thread.

Approval Processing drives state evolution through three possible outcomes. In the case of rejection, both the anharmonic coefficient K₀ and the fractional parameter α are adjusted—with K₀ increasing to reflect recent refusals, and α decreasing slightly to capture the memory of this rejection. The system recalculates P₀ using our FQAHO-based formula. For split decisions, energy divides between treasury and thread based on voter distribution while parameters adjust proportionally. When approved, energy distributes to approvers while the fractional parameter α decreases slightly, enhancing non-local effects. The author joins as a co-author, and all parameters recalibrate according to the updated thread characteristics.

Dynamic Parameter Evolution follows principles of fractional quantum mechanics. The fractional parameter α evolves to reflect thread maturity and quality, decreasing from 2 toward 1 as threads develop memory and non-local interactions. The anharmonic coefficient K₀ responds primarily to recent approval/refusal patterns, while maintaining sensitivity to the fractional parameter. The potential order m increases with citation count and co-author network complexity, reflecting deepening interactions.

Frequency Management reflects collective organization through coupled oscillators with fractional damping. The thread frequency evolves through three interacting modes: the message mode normalizes activity rate by the fractional power of co-author count, the value mode applies logarithmic scaling to energy per co-author, and the coupling strength maintains an inverse relationship with co-author count raised to the fractional power. These modes work together to create natural organizational rhythms with long-range correlations.

The reward system operates through precisely defined state transitions with memory effects. New message rewards follow a fractional time-based decay described by R(t) = R_total × k/(1 + k·t_period)^(α/2), where k represents the decay constant (2.04), t_period spans the total time period of four years, and α is the thread's fractional parameter. Prior citation rewards strengthen thread coupling by drawing from treasury balance based on quality score ratios, expressed as V(p) = B_t × Q(p)^(α/2)/∑Q(i)^(α/2). Citations create frequency coupling between threads, with each thread's frequency increasing by 5% of the other's frequency, modulated by the fractional parameter. Treasury management maintains system solvency through careful balance tracking, where split decisions increase the balance, prior rewards decrease it, and system rewards add to it, all while maintaining a minimum balance for stability.

The system's core properties maintain stability through:

1. Fractional energy conservation in all transitions
2. Parameter coherence via coupled feedback loops
3. Frequency alignment through fractional organizational coupling
4. Lévy flight-like value propagation through the network

Error handling ensures transition validity through multiple safeguards. Fractional energy conservation violations trigger immediate rejection. Parameter instability blocks updates until recalibration completes. Frequency decoherence blocks transitions that would disrupt organizational patterns. Phase transition failures maintain the previous state to ensure system stability.

Through these precisely defined transitions, the system maintains fractional quantum anharmonic stability while enabling organic evolution of thread states. The careful balance of non-local energy conservation, dynamic parameter modulation, and frequency alignment creates a robust framework for organic growth and adaptation with memory effects.

#### Fractional Parameter Evolution

The evolution of thread parameters follows fractional quantum principles:

• The fractional parameter α evolves via:
α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q

• The anharmonic coefficient adjusts through:
K₀(r,α) = K₀_base _ (1 + γ₁r) _ (2/α)^γ₂

• The potential order develops according to:
m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)

These modifications ensure that memory effects, non-local interactions, and network complexity are properly accounted for in the economic model.
# Level 2 Documentation



=== File: docs/e_business.md ===



==
e_business
==


# Choir Business Model

Choir's business model aligns with its natural principles - value flows efficiently, quality emerges organically, and growth happens sustainably. Rather than extracting value through advertising or data mining, we enable and strengthen natural value creation.

Our core revenue model operates on a thoughtfully designed freemium approach that grows naturally with teams. The free tier establishes a strong foundation, enabling thread participation, co-authorship, basic message submission and approval, thread visibility to co-authors, standard resource allocation, and natural team formation. Building on this foundation, our premium tier ($30/month or $200/year) enhances the natural flow of work through bonus rewards, increased resource allocation, priority message processing, advanced team analytics, and enhanced privacy controls. Premium benefits grow yearly, amplifying natural value creation rather than restricting basic functionality.

Value creation flows through multiple interconnected layers in the platform. At the individual level, participants receive immediate recognition for quality contributions, earn direct rewards for good judgment, build natural reputation through participation, and gain growing resource allocations. Teams benefit from collective value accumulation in threads, shared success through citations, natural team formation processes, and enhanced capabilities through premium features. At the network layer, knowledge networks form organically, value flows across threads, ecosystems develop naturally, and collective intelligence emerges from these interactions.

Resource allocation follows natural principles across three key dimensions. Processing resources scale AI model access with usage, prioritize premium members, enable teams to share growing allocations, and maintain natural load balancing. Storage resources preserve thread history, grow team allocations over time, offer premium backup options, and follow natural archival patterns. Network resources provide real-time updates, priority synchronization, enhanced team features, and optimize natural flows.

The platform grows through natural amplification mechanisms. Quality emerges as better contributions attract attention, teams form around excellence, value accumulates naturally, and growth follows genuine patterns. Network effects strengthen the ecosystem as teams enhance threads, threads strengthen networks, networks attract participation, and value flows efficiently. Resource evolution supports this growth as individual allocations expand yearly, team capabilities grow, network capacity increases, and scaling follows natural patterns.

Business sustainability flows from revenue streams aligned with value creation. Direct revenue comes from premium subscriptions, team features, enhanced capabilities, and growing allocations. Indirect value emerges through quality content datasets, knowledge network formation, team collaboration patterns, and collective intelligence emergence. System health maintains through sustainable resource usage, natural load distribution, efficient value flow, and organic growth patterns.

The future evolution of our model will unfold naturally. Team features will expand to include enhanced collaboration tools, advanced analytics, custom workflows, and natural team support. Knowledge tools will develop to enable network visualization, pattern recognition, insight emergence, and collective intelligence. Resource growth will continue through expanding allocations, new capabilities, team-specific features, and natural evolution.

Our implementation strategy follows natural patterns through three phases. The foundation phase establishes core functionality, basic premium features, natural team support, and essential analytics. The enhancement phase introduces advanced team features, network tools, enhanced analytics, and growing capabilities. The evolution phase enables custom team solutions, network intelligence, emergent features, and natural expansion.

Success metrics reflect our natural approach. Quality metrics track team formation rates, citation patterns, value accumulation, and natural growth. Health metrics monitor resource efficiency, value flow patterns, system coherence, and sustainable growth. Evolution metrics measure feature emergence, capability growth, network effects, and natural scaling.

Through this model, Choir maintains sustainable business operations while enabling natural value creation at all scales. We grow by strengthening the natural flows of quality, collaboration, and collective intelligence. Join us in building a platform where business success aligns perfectly with user value creation - where growth comes from enabling natural patterns of collaboration and knowledge sharing rather than artificial engagement metrics or data extraction.

Thread stake prices are determined through our Fractional Quantum Anharmonic Oscillator (FQAHO) model, which captures both immediate feedback and long-term memory effects. The model parameters evolve in response to community decisions - the anharmonic coefficient K₀ increases when a thread receives many refusals, the fractional parameter α decreases to enhance memory effects as threads mature, and the potential order m grows with thread complexity. This creates a sophisticated economic mechanism that naturally filters quality while accounting for the non-local nature of knowledge creation.

=== File: docs/e_concept.md ===



==
e_concept
==


# Choir: Harmonic Intelligence Platform

At its heart, Choir represents a revolutionary communication platform where value flows like energy through a natural system. Just as rivers find their paths and crystals form their patterns, quality content and collaborative teams emerge through natural principles rather than forced rules.

The platform operates through three fundamental flows that shape its natural value dynamics. Individual recognition happens organically - when someone contributes valuable insight, the recognition manifests immediately and tangibly. Like a clear note resonating through a concert hall, quality contributions naturally attract attention and rewards without needing arbitrary upvotes or likes. Value recognition emerges naturally through participation and stake.

Team crystallization follows similar natural patterns. As valuable conversations develop, they naturally attract compatible minds. Like crystals forming in solution, teams emerge not through top-down organization but through natural alignment of interests and capabilities. Each thread becomes a shared space that accumulates value for all participants, creating natural bonds between contributors.

Knowledge networks complete the value flow system. When threads reference each other, they create flows of value between communities. Like a network of streams feeding into rivers and eventually oceans, knowledge and value flow through the system, creating rich ecosystems of understanding. Each citation strengthens both source and destination, building a web of interconnected knowledge.

The system evolves through natural phases that mirror physical processes. In the early stage, new threads bubble with activity and possibility, like a hot spring. The energy runs high, stakes are elevated, and participation requires confidence - creating a natural barrier that ensures quality from the start. As threads mature, they "cool" into more stable states, like a river finding its course. The flow becomes more predictable, with stakes moderating to make participation more accessible while maintaining quality through established patterns. Finally, mature threads develop clear structures, like crystalline formations, where teams coalesce around valuable patterns, knowledge networks form clear topologies, and value accumulates in stable, beautiful ways.

Unlike traditional platforms that extract value, Choir creates spaces where value naturally accumulates through multiple channels. Threads act as resonant cavities, accumulating energy through quality interactions. Denials strengthen the thread itself rather than being wasted, teams share in their thread's growing value, and natural incentives align toward quality. Network value grows as citations create flows between threads, knowledge networks emerge organically, teams build on each other's work, and system-wide coherence develops naturally. The treasury maintains sustainable value flow by capturing split decisions and funding ongoing citations, enabling perpetual rewards that benefit the entire ecosystem.

Dynamic stake evolution creates natural quality filters with memory effects. The system uses a Fractional Quantum Anharmonic Oscillator model with three evolving parameters: the anharmonic coefficient K₀ increases in response to refusals, the fractional parameter α captures how threads develop memory and non-local interactions over time, and the potential order m reflects growing thread complexity. This mechanism ensures that value distributes in proportion to contribution quality while accounting for the interdependent, non-local nature of knowledge creation. The fractional approach enables the system to model occasional breakthrough insights that create disproportionate value across the network through Lévy flight-like patterns.

The future vision of Choir enables a new kind of collaborative intelligence. Natural teams form around resonant ideas, share in collective value, build on each other's work, and evolve sustainably. Knowledge networks connect naturally through citations, strengthen through use, create emergent insights, and enable collective intelligence. Value creation emerges from natural patterns, accumulates in stable forms, flows efficiently, and benefits all participants.

This represents just the beginning of Choir's potential. As the system evolves, we'll discover new patterns of collaboration, new forms of value creation, and new ways for teams to work together. The key lies in our approach - rather than forcing these patterns, we create the conditions for them to emerge naturally.

Join us in building a platform where quality emerges through natural principles, teams form through genuine alignment, and value flows to those who create it. Together, we can enable new forms of collective intelligence that benefit everyone, creating a truly harmonious system of collaboration and knowledge sharing.
# Level 3 Documentation



=== File: docs/plan_anonymity_by_default.md ===



==
plan_anonymity_by_default
==


==
anonymity_by_default.md
==

# Anonymity by Default: A Core Principle of Choir

VERSION anonymity_by_default: 7.0

Anonymity is not just a feature of Choir; it's a fundamental principle, a design choice that shapes the platform's architecture and informs its values. By making anonymity the default state for all users, Choir prioritizes privacy, freedom of expression, and the creation of a space where ideas are judged on their merits, not on the identity of their author.

**Core Tenets:**

1. **Privacy as a Fundamental Right:** Choir recognizes that privacy is a fundamental human right, essential for individual autonomy and freedom of thought. Anonymity protects users from surveillance, discrimination, and the potential chilling effects of being constantly identified and tracked online.
2. **Freedom of Expression:** Anonymity fosters a space where users can express themselves freely, without fear of judgment or reprisal. This is particularly important for discussing sensitive topics, challenging প্রচলিত norms, or exploring unconventional ideas.
3. **Focus on Ideas, Not Identities:** By separating ideas from their authors, anonymity encourages users to evaluate contributions based on their intrinsic value, rather than on the reputation or status of the contributor. This promotes a more meritocratic and intellectually rigorous environment.
4. **Protection from Bias:** Anonymity can help to mitigate the effects of unconscious bias, such as those based on gender, race, or other personal characteristics. It allows ideas to be judged on their own merits, rather than through the lens of preconceived notions about the author.
5. **Lower Barrier to Entry:** Anonymity makes it easier for new users to join the platform and start contributing, as they don't need to go through a complex verification process or share personal information.

**How Anonymity Works on Choir:**

- **Default State:** All users are anonymous by default upon joining the platform. They can interact, contribute content, and earn CHIP tokens without revealing their real-world identity.
- **Unique Identifiers:** Users are assigned unique, randomly generated identifiers that allow them to build a consistent presence on the platform without compromising their anonymity.
- **No Personal Data Collection:** Choir does not collect or store any personally identifiable information about anonymous users.
- **"Priors" and Anonymity:** The "priors" system, which shows the lineage of ideas, maintains anonymity by design. It reveals the connections between ideas, not the identities of the individuals who proposed them.

**Balancing Anonymity with Accountability:**

- **CHIP Staking:** The requirement to stake CHIP tokens to post new messages acts as a deterrent against spam and malicious behavior, even for anonymous users.
- **Community Moderation:** The platform relies on community moderation to maintain the quality of discourse and address any issues that arise.
- **Reputation Systems:** While users are anonymous by default, they can still build reputations based on the quality of their contributions, as tracked through the "priors" system and potentially through community ratings.

**The Value of Anonymity in a High-Information Environment:**

- **Encourages Honest Discourse:** Anonymity can encourage more honest and open discussions, particularly on sensitive or controversial topics.
- **Promotes Intellectual Risk-Taking:** Users may be more willing to take intellectual risks and explore unconventional ideas when they are not worried about the potential repercussions for their personal or professional lives.
- **Facilitates Whistleblowing and Dissent:** Anonymity can provide a safe space for whistleblowers and those who wish to express dissenting views without fear of retaliation.
- **Protects Vulnerable Users:** Anonymity can be particularly important for users in marginalized or vulnerable communities who may face risks if their identities are revealed.

**Conclusion:**

Anonymity by default is a core design principle of Choir, one that reflects the platform's commitment to privacy, freedom of expression, and the creation of a truly meritocratic space for the exchange of ideas. It's a bold choice in a world where online platforms increasingly demand real-name identification, but it's a choice that has the potential to unlock new levels of creativity, honesty, and collective intelligence. By prioritizing anonymity, Choir is not just building a platform; it's building a new model for online interaction, one that empowers individuals and fosters a more open and equitable exchange of ideas.

=== File: docs/plan_identity_as_a_service.md ===



==
plan_identity_as_a_service
==


# Identity as a Service (IDaaS)

VERSION identity_service: 7.1

Identity on Choir is optional yet valuable. By default, users can participate anonymously, preserving privacy and free expression. However, those who opt into KYC-based verification unlock the ability to participate in binding governance decisions, operate Social AI (SAI) agents under their account, and gain additional social trust signals. This document explains how Identity as a Service (IDaaS) fits into the Choir platform.

---

## Overview

Traditional online platforms typically force users to accept a real-name policy or harvest personal data without explicit consent. Choir takes a different stance:

• **Default Anonymity**: Everyone can read messages, post anonymously, and earn CHIP tokens without providing personal data.
• **Paid Identity**: Those requiring the social or governance benefits of verified status can pay for IDaaS, enabling official KYC-based identity on the platform.

The result is a tiered approach that preserves anonymity for casual or privacy-conscious users, while offering valuable identity features to those who want or need them.

---

## Core Principles

1. **Anonymity First**: No user is required to reveal their personal information to use the basic features of Choir.
2. **Paid Identity**: Identity verification introduces real-world accountability and signals commitment to the community.
3. **Signaling, Not Pay-to-Win**: Verified status does not grant better content visibility—it grants governance participation, the ability to run SAIs, and optional social credibility.
4. **Jurisdictional Compliance**: KYC standards vary globally, so IDaaS is flexible enough to accommodate region-specific regulations.
5. **Privacy Respect**: Despite verification, Choir stores personally identifying information offline and only retains essential proofs on-chain.

---

## Benefits of Verified Identity

- **Governance Participation**: Only verified users can submit binding on-chain votes in futarchy or other proposals.
- **SAI Operator Verification**: KYC ensures that an AI-driven account is mapped to a real individual for accountability.
- **Jurisdictional Compliance**: Verification aligns Choir with relevant regulations, which is critical for the platform’s long-term viability.

Additionally, verified accounts may enjoy intangible benefits like higher reputational trust within the community, though this is a social dynamic rather than a platform-engineered outcome.

---

## IDaaS Workflow

1. **Voluntary Enrollment**: You choose if/when to enroll in IDaaS.
2. **KYC Process**: Provide a government-issued ID or other documentation; a third-party service verifies authenticity.
3. **On-Chain Confirmation**: A non-reversible cryptographic link is posted on-chain (no personally identifying information, just proof of verification).
4. **Subscription or One-Time Fee**: Payment for IDaaS can be structured as recurring or one-time.
5. **Privileges Granted**: The verified user can now vote in binding governance proposals, run SAI agents, and optionally display a verified badge or signal in UI.

---

## Use Cases

- **Governance**: Ensuring that major decisions are made by real individuals with accountability.
- **SAI Execution**: Operating advanced AI software that can influence the platform, under the direct responsibility of a verified user.
- **Enterprise Collaboration**: In corporate settings, having verified internal team members fosters trust and ensures compliance with company or legal requirements.

---

## Monetization and Sustainability

Because IDaaS revenues support the system’s operational costs, they help offset free-tier usage by anonymous participants. This aligns the business model, ensuring that those who need additional capabilities also help fund the platform’s continued growth and stability.

---

## Conclusion

By offering Identity as a Service, Choir establishes a nuanced balance: anonymity remains a core value and default, while verified identity is treated as a premium feature. This approach ensures that governance decisions are accountable, advanced AI operations remain traceable to real individuals, and the platform remains compliant with jurisdictional regulations. Through IDaaS, Choir invites each user to choose the identity model that suits their needs, forging a new path forward for responsible digital communities.

=== File: docs/plan_langgraph.md ===



==
plan_langgraph
==


# Migration Plan: Prompt Chain to LangGraph

## Overview

This document outlines a detailed plan for migrating the current custom prompt chain (Chorus Cycle) implementation to use LangChain and LangGraph. The migration will enable:

1. Using multiple models in the same context with different providers
2. Exposing the prompt chain via API
3. Adding arbitrary tool support (web search, function calling, etc.)
4. Allowing models to dynamically modify the prompt chain

## 1. System Architecture

### Current Architecture

```
┌─────────────────────────────────────────────┐
│                 PromptChain                 │
├─────────────────────────────────────────────┤
│ ┌───────┐ ┌────────────┐ ┌──────────────┐  │
│ │ Link 1 │ │   Link 2   │ │    Link 3    │  │
│ │(Model A)│→│  (Model B) │→│   (Model C)  │  │
│ └───────┘ └────────────┘ └──────────────┘  │
└─────────────────────────────────────────────┘
```

### Target Architecture

```
┌────────────────────────────────────────────────────────────┐
│                  LangGraph Application                     │
├────────────────────────────────────────────────────────────┤
│ ┌─────────────────────────────────────────────────────┐   │
│ │                   StateGraph                         │   │
│ │ ┌───────┐      ┌────────────┐      ┌──────────────┐ │   │
│ │ │Action  │─────▶│Experience  │─────▶│  Intention   │ │   │
│ │ │(Model A)│      │ (Model B)  │      │  (Model C)   │ │   │
│ │ └───────┘      └────────────┘      └──────────────┘ │   │
│ │     ▲                                      │        │   │
│ │     │              ┌──────────────┐        │        │   │
│ │     │              │  Observation │◀───────┘        │   │
│ │     │              │  (Model D)   │                 │   │
│ │     │              └──────────────┘                 │   │
│ │     │                      │                        │   │
│ │     │              ┌──────────────┐                 │   │
│ │     │              │    Update    │                 │   │
│ │     │              │  (Model E)   │                 │   │
│ │     │              └──────────────┘                 │   │
│ │     │                      │                        │   │
│ │     └──────┐       ┌──────▼──────┐                  │   │
│ │            │       │    Yield    │                  │   │
│ │            └───────│  (Model F)  │                  │   │
│ │                    └─────────────┘                  │   │
│ └─────────────────────────────────────────────────────┘   │
│                                                            │
│ ┌─────────────────────┐  ┌───────────────────────────┐    │
│ │     Tool Registry   │  │ Dynamic Chain Modifier    │    │
│ │ ┌─────────────────┐ │  │ ┌─────────────────────┐   │    │
│ │ │  Web Search     │ │  │ │ Add Phase           │   │    │
│ │ ├─────────────────┤ │  │ ├─────────────────────┤   │    │
│ │ │  Function Call  │ │  │ │ Modify Prompt       │   │    │
│ │ ├─────────────────┤ │  │ ├─────────────────────┤   │    │
│ │ │  Data Analysis  │ │  │ │ Change Model        │   │    │
│ │ └─────────────────┘ │  │ └─────────────────────┘   │    │
│ └─────────────────────┘  └───────────────────────────┘    │
│                                                            │
│ ┌────────────────────────────────────────────────────┐    │
│ │                    LangServe API                   │    │
│ └────────────────────────────────────────────────────┘    │
└────────────────────────────────────────────────────────────┘
```

## 2. Component Implementation Plan

### 2.1 Core State Graph (AEIOU Cycle)

The existing AEIOU cycle will be implemented as a `StateGraph` in LangGraph:

```python
from langgraph.graph import StateGraph
from typing import TypedDict, List
from langchain_core.messages import BaseMessage

# Define the state schema
class ChorusState(TypedDict):
    messages: List[BaseMessage]
    phase: str
    should_loop: bool
    context: dict

# Create the state graph
graph = StateGraph(ChorusState)

# Add nodes for each phase of the AEIOU cycle
graph.add_node("action", action_handler)
graph.add_node("experience", experience_handler)
graph.add_node("intention", intention_handler)
graph.add_node("observation", observation_handler)
graph.add_node("update", update_handler)
graph.add_node("yield", yield_handler)

# Add edges between phases
graph.add_edge("action", "experience")
graph.add_edge("experience", "intention")
graph.add_edge("intention", "observation")
graph.add_edge("observation", "update")

# Add conditional edge from update (can loop back to action or proceed to yield)
def update_router(state: ChorusState):
    if state["should_loop"]:
        return "action"
    else:
        return "yield"

graph.add_conditional_edges("update", update_router, ["action", "yield"])

# Set entry point
graph.set_entry_point("action")

# Compile the graph
chorus_chain = graph.compile()
```

### 2.2 Multi-Provider Model Integration

Set up handlers for each phase that use different model providers:

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_mistralai import ChatMistralAI
from langchain_fireworks import ChatFireworks
from langchain_cohere import ChatCohere

# Define models with different providers
def setup_models():
    models = {
        "action": ChatMistralAI(
            model="mistral-medium",
            response_format={"type": "json_schema", "schema": SCHEMAS["ACTION"]["schema"]}
        ),
        "experience": ChatGoogleGenerativeAI(
            model="gemini-pro",
            response_format={"type": "json_schema", "schema": SCHEMAS["EXPERIENCE"]["schema"]}
        ),
        "intention": ChatFireworks(
            model="deepseek-chat",
            response_format={"type": "json_schema", "schema": SCHEMAS["INTENTION"]["schema"]}
        ),
        "observation": ChatAnthropic(
            model="claude-3-haiku",
            response_format={"type": "json_schema", "schema": SCHEMAS["OBSERVATION"]["schema"]}
        ),
        "update": ChatFireworks(
            model="deepseek-chat",
            response_format={"type": "json_schema", "schema": SCHEMAS["UPDATE"]["schema"]}
        ),
        "yield": ChatCohere(
            model="command-r",
            response_format={"type": "json_schema", "schema": SCHEMAS["YIELD"]["schema"]}
        )
    }
    return models
```

### 2.3 Node Handlers Implementation

Create handlers for each node in the graph:

```python
from langchain_core.prompts import ChatPromptTemplate

# Example handler for the action phase
def create_action_handler(model, system_prompt):
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{input}")
    ])

    chain = prompt | model

    def action_handler(state: ChorusState):
        # Extract the user input from the messages
        user_input = state["messages"][-1].content if state["messages"] else ""

        # Get model response
        response = chain.invoke({"input": user_input})

        # Update state
        new_state = state.copy()
        new_state["phase"] = "action"
        new_state["context"] = {"action_result": response}

        return new_state

    return action_handler

# Create handlers for each phase
def setup_handlers(models, system_prompts):
    handlers = {}
    for phase in ["action", "experience", "intention", "observation", "update", "yield"]:
        handlers[phase] = create_handler_for_phase(
            phase,
            models[phase],
            system_prompts[phase]
        )
    return handlers
```

### 2.4 Tool Integration

Implement a tool registry and tools for the models to use:

```python
from langchain.tools import Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.tools import tool

# Create web search tool
search_tool = DuckDuckGoSearchRun()

# Create custom tool for adding a phase to the chain
@tool
def add_chain_phase(phase_name: str, system_prompt: str, position: str):
    """Add a new phase to the prompt chain.

    Args:
        phase_name: The name of the new phase
        system_prompt: The system prompt for the new phase
        position: Where to add the phase (e.g., "after:observation")
    """
    # Implementation will be handled separately
    return f"Added new phase: {phase_name} at position {position}"

# Register tools
tools = [
    search_tool,
    add_chain_phase
]

# Add tools to models that support function calling
def add_tools_to_models(models, tools):
    for phase, model in models.items():
        if hasattr(model, "bind_tools"):
            models[phase] = model.bind_tools(tools)
    return models
```

### 2.5 Dynamic Chain Modification

Implement the mechanism for dynamically modifying the chain:

```python
class ChainModifier:
    def __init__(self, graph):
        self.graph = graph
        self.compiled_chain = None

    def add_phase(self, phase_name, system_prompt, position):
        # Parse position (e.g., "after:observation")
        position_type, reference_phase = position.split(":")

        # Create new model for this phase
        new_model = ChatOpenAI(
            model="gpt-3.5-turbo-0125",
            response_format={"type": "json"}
        )

        # Create handler for new phase
        new_handler = create_handler_for_phase(
            phase_name,
            new_model,
            system_prompt
        )

        # Add node to graph
        self.graph.add_node(phase_name, new_handler)

        # Update edges based on position
        if position_type == "after":
            # Get the current outgoing edge
            next_phase = self.graph.get_next_node(reference_phase)

            # Remove existing edge
            self.graph.remove_edge(reference_phase, next_phase)

            # Add new edges
            self.graph.add_edge(reference_phase, phase_name)
            self.graph.add_edge(phase_name, next_phase)

        # Recompile the graph
        self.compiled_chain = self.graph.compile()
        return self.compiled_chain
```

### 2.6 API Integration with LangServe

Expose the chain as an API using LangServe:

```python
from fastapi import FastAPI
from langserve import add_routes

# Initialize FastAPI app
app = FastAPI(title="Chorus Chain API")

# Add routes for the chain
add_routes(
    app,
    chorus_chain,
    path="/chorus",
    input_type=ChorusInput,  # Define this pydantic model
    output_type=ChorusOutput, # Define this pydantic model
)

# Add route for modifying the chain
@app.post("/modify_chain")
async def modify_chain(modification: ChainModification):
    result = chain_modifier.add_phase(
        modification.phase_name,
        modification.system_prompt,
        modification.position
    )
    return {"status": "success", "message": f"Added phase: {modification.phase_name}"}
```

## 3. Implementation Phases

### Phase 1: Individual Model Structured Output Testing

- [x] Set up development environment with LangChain dependencies
- [x] Create test harness for evaluating individual model capabilities
- [x] Implement structured output schemas for each phase (action, experience, etc.)
- [x] Test each provider's models (OpenAI, Anthropic, Google, Mistral, etc.) with the same schemas
- [x] Document model-specific behaviors, strengths, and limitations
- [ ] Create a compatibility matrix of which models work best for which phases

### Phase 2: Tool Integration & Model-Specific Capabilities

- [ ] Implement core tools (web search, function calls, etc.)
- [ ] Test tool binding with each provider's models
- [ ] Measure response quality and tool usage patterns across providers
- [x] Implement provider-specific fallback mechanisms
- [ ] Document tool calling capabilities across providers
- [ ] Build adapter patterns to standardize tool interaction patterns

### Phase 3: Basic LangGraph Composition

- [x] Implement basic StateGraph with fixed AEIOU sequence
- [x] Create handlers for each phase using configurable model selection
- [x] Build state management system to pass context between models
- [x] Implement basic error handling and retries
- [x] Test end-to-end flow with simple prompts
- [x] Compare performance metrics with current implementation

### Phase 4: Advanced Flow Control

- [x] Add conditional edges for looping behavior (understanding → action)
- [x] Implement probability-based router logic for looping
- [x] Create recursion limit mechanism to prevent infinite loops
- [x] Test with complex multi-turn scenarios
- [x] Implement cycle detection to prevent infinite loops
- [ ] Measure performance impact of dynamic routing

### Phase 5: Self-Modifying Chains

- [ ] Create specialized tools for prompt engineering and chain modification
- [ ] Allow models to define new graph nodes and edges
- [ ] Implement safety guardrails for model-generated prompts and tools
- [ ] Build validation system for dynamically created components
- [ ] Test various scenarios of chain self-modification
- [ ] Create observability layer to track chain evolution

### Phase 6: API & Integration

- [ ] Integrate into Choir api
- [ ] Create standardized input/output schemas
- [ ] Add authentication and rate limiting
- [x] Implement streaming support for real-time updates
- [ ] Create admin controls for monitoring chain modifications
- [ ] Build integration examples with common frameworks
- [ ] Document API usage patterns and best practices

## 4. Implementation Status

### Core Components

| Component           | Status      | Description                                                          |
| ------------------- | ----------- | -------------------------------------------------------------------- |
| State Graph         | ✅ Complete | Successfully implemented full AEIOU-Y graph with all nodes and edges |
| State Schema        | ✅ Complete | Implemented TypedDict for state management with proper annotations   |
| Phase Handlers      | ✅ Complete | Created handlers for all phases with consistent state management     |
| Conditional Routing | ✅ Complete | Implemented probability-based routing with recursion limits          |
| Error Handling      | ✅ Complete | Added comprehensive error handling for various failure cases         |
| Streaming Support   | ✅ Complete | Implemented streaming via astream methods with token callbacks       |

### Advanced Features

| Feature                    | Status         | Description                                                 |
| -------------------------- | -------------- | ----------------------------------------------------------- |
| Multi-Model Support        | 🔄 In Progress | Framework supports multiple models, API integration pending |
| Tool Integration           | 🔄 In Progress | Framework prepared for tools, implementation pending        |
| Dynamic Chain Modification | ⏱️ Planned     | Architecture supports modification, implementation pending  |
| API Endpoints              | ⏱️ Planned     | Design prepared, implementation pending                     |
| Performance Monitoring     | ⏱️ Planned     | Basic logging in place, detailed metrics pending            |

### Testing and Validation

| Test Category    | Status         | Description                                               |
| ---------------- | -------------- | --------------------------------------------------------- |
| Basic Flow       | ✅ Complete    | Verified linear progression through all phases            |
| Looping Behavior | ✅ Complete    | Tested probability-based looping with various thresholds  |
| Error Handling   | ✅ Complete    | Validated graceful recovery from various error conditions |
| Tool Usage       | 🔄 In Progress | Framework prepared, awaiting tool implementation          |
| Performance      | ⏱️ Planned     | Benchmarking framework designed, implementation pending   |

## 5. Required Dependencies

```
langchain>=0.1.0
langchain-core>=0.1.0
langgraph>=0.0.15
langserve>=0.0.30
langchain-openai>=0.0.5
langchain-anthropic>=0.1.0
langchain-google-genai>=0.0.5
langchain-mistralai>=0.0.1
langchain-fireworks>=0.1.0
langchain-cohere>=0.0.1
pydantic>=2.0.0
fastapi>=0.104.0
uvicorn>=0.24.0
```

## 6. Compatibility Considerations

### 6.1 LangChain vs Current Implementation

| Feature           | Current Implementation | LangGraph Implementation     | Status         |
| ----------------- | ---------------------- | ---------------------------- | -------------- |
| Multiple Models   | Custom model caller    | Native LangChain integration | ✅ Implemented |
| Structured Output | Custom JSON parsing    | Schema-based validation      | ✅ Implemented |
| Chain Flow        | Linear with loop flag  | True graph with conditionals | ✅ Implemented |
| Tool Support      | Limited                | Extensive built-in tools     | 🔄 In Progress |
| Error Handling    | Basic fallbacks        | Robust retry mechanisms      | ✅ Implemented |
| State Management  | Manual                 | Graph-managed state          | ✅ Implemented |

### 6.2 Migration Strategies

1. **Incremental Approach**: Start by migrating one phase at a time, keeping the rest of the system intact
2. **Parallel Development**: Build the new system alongside the old one, gradually shifting traffic
3. **Test-First Migration**: Create comprehensive tests before migration, then ensure equivalence

## 7. Evaluation Metrics

1. **Token Efficiency**: Compare token usage between current and LangGraph implementations
2. **Latency**: Measure end-to-end response time
3. **Error Rates**: Track parsing errors, model failures, and timeouts
4. **Chain Modification Success**: Measure success rate of dynamic chain modifications
5. **Tool Usage Accuracy**: Evaluate correct tool selection and parameter passing

## 8. Next Steps

Based on our current progress, the following tasks are prioritized:

1. **Tool Integration**:

   - Implement web search tool for real-time information retrieval
   - Add function calling capabilities for common tasks
   - Create testing framework for tool usage evaluation

2. **Performance Optimization**:

   - Benchmark token usage across different models and phases
   - Identify bottlenecks in the current implementation
   - Implement caching strategies for frequently accessed content

3. **API Layer**:

   - Complete Langserve integration for API exposure
   - Create proper authentication and rate limiting
   - Design detailed monitoring and observability

4. **Documentation**:
   - Create comprehensive API documentation
   - Document best practices for custom tool development
   - Create tutorials for extending the system

## 9. Conclusion

The migration to LangGraph has made significant progress, with the core architecture successfully implemented and tested. The current implementation provides a robust foundation for the Chorus Cycle, with improved state management, error handling, and flow control. The system is now ready for the next phase of development, focusing on tool integration, performance optimization, and API exposure.

The implementation has validated the benefits of the LangGraph approach, particularly in terms of flexibility, maintainability, and extensibility. The graph-based structure allows for more complex flow patterns and better error recovery, while the standardized state management ensures consistency across phases.

The migration will continue with an incremental approach, focusing on preserving functionality while adding new capabilities. The end result will be a more powerful, flexible, and maintainable implementation of the Chorus Cycle.

=== File: docs/plan_langgraph_postchain.md ===



==
plan_langgraph_postchain
==


# LangGraph PostChain Implementation Plan

## Current Implementation Overview

The current Chorus Cycle implementation is a sequence of calls to a single LLM with RAG to a single vector database. The cycle follows the AEIOU-Y pattern:

1. **Action**: Initial response with "beginner's mind"
2. **Experience**: Enrichment with prior knowledge via RAG
3. **Intention**: Analysis of planned actions and consequences
4. **Observation**: Reflection on analysis and intentions
5. **Understanding**: Decision to loop back or proceed to yield
6. **Yield**: Final synthesized response

Each step uses the same model (currently Claude 3.5 Haiku) with different system prompts, and the cycle can loop back from Understanding to Action if needed.

## Migration Goals

1. Implement the Chorus Cycle using LangGraph's StateGraph
2. Create a multi-model workflow where different models handle different steps
3. Add agentic capabilities with tools and dynamic routing
4. Improve observability and debugging
5. Enable dynamic chain modification

## Revised Implementation Approach

Our implementation approach will be highly iterative, focusing on validating each component individually before composition:

1. **Environment Setup**: First, add dependencies and configure API keys for all providers
2. **Individual Model Testing**: Test each model in isolation before integration
3. **Basic LangGraph**: Start with a simple single-node graph before building complexity
4. **Incremental Integration**: Add components one at a time with thorough testing
5. **Feature Tracking**: Use a checklist approach to track progress empirically

## Implementation Checklist

### Phase 0: Environment Setup and Dependency Testing

- [x] Add LangGraph and related dependencies to requirements.txt
  ```
  langchain>=0.1.0
  langchain-core>=0.1.0
  langgraph>=0.0.15
  langserve>=0.0.30
  langchain-openai>=0.0.5
  langchain-anthropic>=0.1.0
  langchain-google-genai>=0.0.5
  langchain-mistralai>=0.0.1
  langchain-fireworks>=0.1.0
  langchain-cohere>=0.0.1
  ```
- [x] Understanding environment with necessary API keys for all providers
- [x] Create simple test script to verify API connectivity with each provider
- [ ] Document API rate limits and token quotas for each provider

### Phase 1: Individual Model Testing

- [x] Test each model in simple single-turn conversations
- [x] Test each model in multi-turn conversations
  - [x] Verify context window handling
  - [x] Test conversation memory
- [x] Test structured output capabilities of each model
  - [x] JSON schema validation
  - [x] Error handling for malformed outputs
  - [x] Consistency across multiple calls
- [ ] Create compatibility matrix documenting strengths/weaknesses of each model

### Phase 2: Basic LangGraph Integration

- [x] Set up project structure for PostChain
- [x] Implement state schema with Pydantic
- [x] Create simple single-node graph with one model
- [x] Test state transitions and data flow
- [x] Expand to basic linear chain with all AEIOU-Y steps
- [x] Implement basic error handling and recovery

### Phase 3: Multi-Model Integration

- [x] Define model configuration for each step
- [x] Create model selection logic (including random model selection)
- [x] Implement node handlers for each step
- [x] Test cross-model context preservation
- [ ] Evaluate performance and token usage
- [ ] Optimize prompt templates for each model

### Phase 4: Tool Integration

- [ ] Implement basic tools (web search, retrieval)
- [ ] Test tool compatibility with each model
- [ ] Create tool registry
- [x] Implement tool usage tracking in state management
- [x] Test error handling for tool failures
- [ ] Measure tool effectiveness

### Phase 5: Advanced Flow Control

- [x] Implement conditional edges for looping
- [x] Create dynamic routing based on probability-based decisions
- [ ] Add web search node
- [x] Test complex flows with looping
- [x] Implement cycle detection and recursion limits
- [ ] Create visualization of graph execution

### Phase 6: API Integration

- [ ] Create API endpoints
- [x] Implement streaming support
- [ ] Add authentication and rate limiting
- [ ] Create client library
- [ ] Test API performance
- [ ] Document API usage

### Phase 7: Observability and Testing

- [x] Add tracing and logging throughout the system
- [x] Create comprehensive test suite for behavior verification
- [ ] Implement performance monitoring
- [x] Create debugging tools (detailed logging)
- [ ] Document troubleshooting procedures
- [x] Conduct end-to-end testing with various scenarios

## Progress Summary (Updated)

We have made significant progress on the LangGraph PostChain implementation:

1. **Core Graph Implementation**:

   - Successfully implemented the complete AEIOU-Y state graph with proper node connections
   - Implemented a probability-based looping mechanism from understanding to action/yield
   - Added comprehensive state management ensuring state consistency across phases

2. **Error Handling**:

   - Implemented robust error handling in streaming and callback scenarios
   - Ensured graceful recovery from errors with appropriate phase setting (yield instead of error)
   - Added recursion limit safety to prevent infinite loops

3. **Testing Framework**:

   - Created a comprehensive testing framework that captures interactions
   - Implemented analysis tools to verify phase distribution and transitions
   - Added tools for visualizing and tracking chain behavior

4. **Next Steps**:
   - Complete tool integration for web search and other capabilities
   - Optimize for performance and token usage
   - Implement robust API layer for integration with other systems

## Conclusion

This implementation plan provides a structured approach to migrating the current Chorus Cycle to a multi-model agentic workflow using LangGraph. The resulting system will be more flexible, maintainable, and powerful, while preserving the core AEIOU-Y cycle functionality.

The migration can be performed incrementally, starting with a basic LangGraph implementation and gradually adding more advanced features like multi-model support, tool integration, and dynamic routing. This approach allows for continuous testing and evaluation throughout the development process.

The final system will leverage the strengths of different models for different steps of the cycle, use tools to enhance capabilities, and provide better observability and debugging features. It will also be more extensible, allowing for future enhancements like multi-agent orchestration, memory management, and custom model integration.

=== File: docs/plan_libsql.md ===



==
plan_libsql
==


# libSQL Integration Plan for Choir

## Overview

This document outlines the implementation plan for integrating libSQL/Turso as the local persistence layer for the Choir application. This system will provide both offline functionality and synchronization with our global vector database infrastructure, while supporting the FQAHO model parameters and Post Chain architecture.

## Core Objectives

1. Implement libSQL as the primary local persistence solution
2. Design a flexible schema that can accommodate evolving data models
3. Implement vector search capabilities to support semantic matching in the Experience phase
4. Create a synchronization system between local and global databases
5. Support the FQAHO model parameters (α, K₀, m) in the database schema
6. Enable offline functionality with seamless online synchronization

## Implementation Philosophy

Our approach to database implementation will be guided by these principles:

1. **Core System First** - Focus on getting the core UX and system operational before fully committing to a database schema
2. **Flexibility** - Design the database to be adaptable as our data model evolves
3. **Incremental Implementation** - Add database features in phases, starting with the most essential components
4. **Performance** - Optimize for mobile device constraints and offline-first operation

## Technical Implementation

### 1. Database Setup and Initialization

```swift
import Libsql

class DatabaseService {
    static let shared = try! DatabaseService()

    private let database: Database
    private let connection: Connection

    private init() throws {
        // Get path to document directory for local database
        let documentsDirectory = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first!
        let dbPath = documentsDirectory.appendingPathComponent("choir.db").path

        // Initialize database with sync capabilities
        self.database = try Database(
            path: dbPath,
            url: Environment.tursoDbUrl,      // Remote database URL
            authToken: Environment.tursoToken, // Authentication token
            syncInterval: 10000               // Sync every 10 seconds
        )

        self.connection = try database.connect()

        // Initialize schema
        try setupSchema()
    }

    private func setupSchema() throws {
        try connection.execute("""
            -- Users table
            CREATE TABLE IF NOT EXISTS users (
                id TEXT PRIMARY KEY,
                name TEXT,
                last_active INTEGER
            );

            -- Threads table
            CREATE TABLE IF NOT EXISTS threads (
                id TEXT PRIMARY KEY,
                title TEXT,
                created_at INTEGER,
                updated_at INTEGER,
                k0 REAL,           -- FQAHO parameter K₀
                alpha REAL,        -- FQAHO parameter α (fractional)
                m REAL             -- FQAHO parameter m
            );

            -- Messages table with vector support
            CREATE TABLE IF NOT EXISTS messages (
                id TEXT PRIMARY KEY,
                thread_id TEXT,
                user_id TEXT,
                content TEXT,
                embedding F32_BLOB(1536),  -- Vector embedding for semantic search
                phase TEXT,                -- Post Chain phase identifier
                created_at INTEGER,
                approval_status TEXT,      -- For approval/refusal statistics
                FOREIGN KEY(thread_id) REFERENCES threads(id),
                FOREIGN KEY(user_id) REFERENCES users(id)
            );

            -- Vector index for similarity search in Experience phase
            CREATE INDEX IF NOT EXISTS messages_embedding_idx
            ON messages(libsql_vector_idx(embedding));

            -- Parameter history for FQAHO model tracking
            CREATE TABLE IF NOT EXISTS parameter_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                thread_id TEXT,
                timestamp INTEGER,
                k0 REAL,
                alpha REAL,
                m REAL,
                event_type TEXT,  -- What caused the parameter change
                FOREIGN KEY(thread_id) REFERENCES threads(id)
            );
        """)
    }
}
```

### 2. Thread and Message Operations

```swift
extension DatabaseService {
    // MARK: - Thread Operations

    func createThread(id: String, title: String, k0: Double, alpha: Double, m: Double) throws {
        let now = Int(Date().timeIntervalSince1970)

        try connection.execute("""
            INSERT INTO threads (id, title, created_at, updated_at, k0, alpha, m)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, [id, title, now, now, k0, alpha, m])

        // Record initial parameters
        try connection.execute("""
            INSERT INTO parameter_history (thread_id, timestamp, k0, alpha, m, event_type)
            VALUES (?, ?, ?, ?, ?, ?)
        """, [id, now, k0, alpha, m, "thread_creation"])
    }

    func getThread(id: String) throws -> Thread? {
        let results = try connection.query(
            "SELECT * FROM threads WHERE id = ?",
            [id]
        )

        guard let result = results.first else { return nil }

        return Thread(
            id: result["id"] as! String,
            title: result["title"] as! String,
            createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
            updatedAt: Date(timeIntervalSince1970: TimeInterval(result["updated_at"] as! Int)),
            k0: result["k0"] as! Double,
            alpha: result["alpha"] as! Double,
            m: result["m"] as! Double
        )
    }

    func updateThreadParameters(threadId: String, k0: Double, alpha: Double, m: Double, eventType: String) throws {
        let now = Int(Date().timeIntervalSince1970)

        // Update thread
        try connection.execute("""
            UPDATE threads
            SET k0 = ?, alpha = ?, m = ?, updated_at = ?
            WHERE id = ?
        """, [k0, alpha, m, now, threadId])

        // Record parameter change
        try connection.execute("""
            INSERT INTO parameter_history (thread_id, timestamp, k0, alpha, m, event_type)
            VALUES (?, ?, ?, ?, ?, ?)
        """, [threadId, now, k0, alpha, m, eventType])
    }

    // MARK: - Message Operations

    func createMessage(id: String, threadId: String, userId: String, content: String,
                       embedding: [Float], phase: String) throws {
        let now = Int(Date().timeIntervalSince1970)
        let vectorString = "vector32('\(embedding)')"

        try connection.execute("""
            INSERT INTO messages (id, thread_id, user_id, content, embedding, phase, created_at, approval_status)
            VALUES (?, ?, ?, ?, \(vectorString), ?, ?, 'pending')
        """, [id, threadId, userId, content, phase, now])

        // Update thread's last activity
        try connection.execute("""
            UPDATE threads
            SET updated_at = ?
            WHERE id = ?
        """, [now, threadId])
    }

    func updateMessageApprovalStatus(messageId: String, status: String) throws {
        try connection.execute("""
            UPDATE messages
            SET approval_status = ?
            WHERE id = ?
        """, [status, messageId])

        // If we wanted to update FQAHO parameters based on approval/refusal, we could do that here
        if let message = try getMessage(id: messageId),
           let thread = try getThread(id: message.threadId) {

            // Calculate new parameters based on approval/refusal
            let newK0 = calculateNewK0(currentK0: thread.k0, approvalStatus: status)
            let newAlpha = calculateNewAlpha(currentAlpha: thread.alpha, approvalStatus: status)
            let newM = calculateNewM(currentM: thread.m, approvalStatus: status)

            try updateThreadParameters(
                threadId: message.threadId,
                k0: newK0,
                alpha: newAlpha,
                m: newM,
                eventType: "message_\(status)"
            )
        }
    }

    func getMessage(id: String) throws -> Message? {
        let results = try connection.query(
            "SELECT * FROM messages WHERE id = ?",
            [id]
        )

        guard let result = results.first else { return nil }

        return Message(
            id: result["id"] as! String,
            threadId: result["thread_id"] as! String,
            userId: result["user_id"] as! String,
            content: result["content"] as! String,
            phase: result["phase"] as! String,
            createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
            approvalStatus: result["approval_status"] as! String
        )
    }
}
```

### 3. Vector Search for Experience Phase

```swift
extension DatabaseService {
    // Find semantically similar messages for the Experience phase
    func findSimilarExperiences(threadId: String, queryEmbedding: [Float], limit: Int = 5) throws -> [Message] {
        let vectorString = "vector32('\(queryEmbedding)')"

        let results = try connection.query("""
            SELECT m.*
            FROM vector_top_k('messages_embedding_idx', \(vectorString), ?) as v
            JOIN messages m ON m.rowid = v.id
            WHERE m.thread_id = ?
            AND m.approval_status = 'approved'
        """, [limit, threadId])

        return results.map { result in
            Message(
                id: result["id"] as! String,
                threadId: result["thread_id"] as! String,
                userId: result["user_id"] as! String,
                content: result["content"] as! String,
                phase: result["phase"] as! String,
                createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
                approvalStatus: result["approval_status"] as! String
            )
        }
    }

    // Get experiences with prior parameter values (for display in Experience step)
    func getExperiencesWithPriors(threadId: String, limit: Int = 10) throws -> [(Message, ParameterSet)] {
        let results = try connection.query("""
            SELECT m.*, p.k0, p.alpha, p.m
            FROM messages m
            JOIN parameter_history p ON
                m.thread_id = p.thread_id AND
                m.created_at >= p.timestamp
            WHERE m.thread_id = ?
            AND m.phase = 'experience'
            ORDER BY m.created_at DESC
            LIMIT ?
        """, [threadId, limit])

        return results.map { result in
            let message = Message(
                id: result["id"] as! String,
                threadId: result["thread_id"] as! String,
                userId: result["user_id"] as! String,
                content: result["content"] as! String,
                phase: result["phase"] as! String,
                createdAt: Date(timeIntervalSince1970: TimeInterval(result["created_at"] as! Int)),
                approvalStatus: result["approval_status"] as! String
            )

            let parameters = ParameterSet(
                k0: result["k0"] as! Double,
                alpha: result["alpha"] as! Double,
                m: result["m"] as! Double
            )

            return (message, parameters)
        }
    }
}
```

### 4. Synchronization Management

```swift
extension DatabaseService {
    // Trigger manual sync with remote database
    func syncWithRemote() throws {
        try database.sync()
    }

    // Check if a sync is needed
    var needsSync: Bool {
        // Implementation depends on how we track local changes
        // Could check for pending operations or time since last sync
        return true
    }

    // Handle network status changes
    func handleNetworkStatusChange(isOnline: Bool) {
        if isOnline && needsSync {
            do {
                try syncWithRemote()
            } catch {
                print("Sync error: \(error)")
                // Handle sync failure
            }
        }
    }
}
```

### 5. FQAHO Parameter Calculation Functions

```swift
extension DatabaseService {
    // Calculate new K₀ value based on approval/refusal
    private func calculateNewK0(currentK0: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model K₀ adjustment
        let adjustment: Double = approvalStatus == "approved" ? 0.05 : -0.08
        return max(0.1, min(10.0, currentK0 + adjustment))
    }

    // Calculate new α value based on approval/refusal
    private func calculateNewAlpha(currentAlpha: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model α adjustment
        // Fractional parameter capturing memory effects
        let adjustment: Double = approvalStatus == "approved" ? 0.02 : -0.03
        return max(0.1, min(2.0, currentAlpha + adjustment))
    }

    // Calculate new m value based on approval/refusal
    private func calculateNewM(currentM: Double, approvalStatus: String) -> Double {
        // Implementation of FQAHO model m adjustment
        let adjustment: Double = approvalStatus == "approved" ? -0.01 : 0.02
        return max(0.5, min(5.0, currentM + adjustment))
    }
}
```

## Phased Implementation Approach

Given that UX has more pressing issues and the data model is still evolving, we'll adopt a phased approach to database implementation:

### Phase 1: Core UX Development (Current Focus)

- Continue developing the core UI and interaction flow
- Prioritize UX improvements over database implementation
- Use in-memory or mock data for testing

### Phase 2: Schema Development and Validation

- Finalize initial schema design as the core system stabilizes
- Create prototypes to validate the schema with real usage patterns
- Ensure the schema can adapt to evolving requirements

### Phase 3: Basic Database Implementation

- Implement basic CRUD operations for threads and messages
- Set up the database connection and initialization
- Create simplified data services for the UI to consume

### Phase 4: Vector Search Implementation

- Add vector embedding storage and search
- Connect the Experience phase to vector similarity search
- Optimize for performance and memory usage

### Phase 5: FQAHO Parameter Support

- Implement parameter storage and history tracking
- Add parameter calculation algorithms
- Connect parameter adjustments to the UI

### Phase 6: Synchronization

- Configure embedded replicas
- Implement sync management
- Handle offline/online transitions

## Integration with Post Chain Phases

The libSQL implementation will support all phases of the Post Chain:

1. **Action** - Store user messages and initial parameters
2. **Experience** - Use vector search to find relevant prior experiences
3. **Understanding** - Track message reactions and parameter adjustments
4. **Web Search** - Store search results with vector embeddings for future reference
5. **Tool Use** - Record tool usage patterns and outcomes

## Flexible Schema Design Principles

Since the data model is still evolving, the database schema should follow these principles:

1. **Versioned Schema** - Include version markers in the schema to facilitate future migrations
2. **Nullable Fields** - Use nullable fields where appropriate to accommodate evolving requirements
3. **Isolated Tables** - Keep related concepts in separate tables to minimize the impact of changes
4. **Extensible Records** - Consider using a JSON or blob field for attributes that might change frequently
5. **Minimal Dependencies** - Limit foreign key constraints to essential relationships

## Future Considerations

1. **Multi-device Sync**

   - Ensure consistent user experience across devices
   - Handle conflict resolution

2. **Advanced Vector Quantization**

   - Implement quantization for more efficient storage
   - Optimize for mobile device constraints

3. **Partitioned User Databases**

   - Implement per-user database isolation
   - Support multi-tenancy within the app

4. **Backup and Recovery**

   - Implement regular backup mechanisms
   - Create recovery procedures

5. **Extensions for Multimodal Support**
   - Extend schema for image and audio data
   - Implement multimodal vector embeddings

## Resources

- [Turso Swift Documentation](https://docs.turso.tech/swift)
- [libSQL Swift GitHub Repository](https://github.com/tursodatabase/libsql-swift)
- [Embedded Replicas Documentation](https://docs.turso.tech/embedded-replicas)
- [Vector Search Documentation](https://docs.turso.tech/vector-search)

=== File: docs/plan_model_config_checklist.md ===



==
plan_model_config_checklist
==


# 🔄 Revised Model Management Plan

## 🎯 Core Principles

1. **Runtime Configuration** - Enable/disable providers via function parameters
2. **Minimal Changes** - Keep existing model getters intact
3. **Central Control** - Manage providers in `initialize_model_list`
4. **Userland Flexibility** - Support dynamic provider selection

## ✅ Implementation Checklist

## Adding Providers

1. Install required package
2. Add API key to `Config` class
3. Create model getter function in `langchain_utils.py`
4. Add provider block in `initialize_model_list()`
5. Implement model creation in `get_base_model()`
6. Add streaming support in `get_streaming_model()`

## Disabling Providers

1. Pass disabled providers to `initialize_model_list()`

```python
models = initialize_model_list(config, disabled_providers={"openai"})
```

2. Update provider blocks with exclusion check:

```python
if provider not in disabled_providers and api_key_exists:
    add_models()
```

## Implementation Steps

1. Modify `initialize_model_list` signature:

```python:api/app/langchain_utils.py
def initialize_model_list(
    config: Config,
    disabled_providers: Set[str] = None
) -> List[ModelConfig]:
    """Initialize model list with provider control"""
    disabled_providers = disabled_providers or set()
```

2. Update provider blocks (example for OpenAI):

```python:api/app/langchain_utils.py
# Before
if config.OPENAI_API_KEY:
    models.extend(...)

# After
if "openai" not in disabled_providers and config.OPENAI_API_KEY:
    models.extend(...)
```

3. Update test script usage:

```python:api/tests/postchain/test_random_multimodel_stream.py
# Disable OpenAI in tests
models = initialize_model_list(config, disabled_providers={"openai"})
```

## 🧠 Key Implementation Insight

The `disabled_providers` parameter acts as a runtime filter while preserving:

- Existing model definitions
- API key validation
- Provider isolation
- Future expansion capabilities

This aligns with the Post Chain philosophy of minimal core + userland extensions.

## 📝 Usage Examples

**Disable Multiple Providers**

```python
models = initialize_model_list(
    config,
    disabled_providers={"openai", "azure"}
)
```

**Enable Specific Providers Only**

```python
all_providers = {"openai", "anthropic", "google", "mistral", "fireworks", "cohere", "groq"}
models = initialize_model_list(
    config,
    disabled_providers=all_providers - {"anthropic"}
)
```

**Temporary Provider Exclusion**

```python
temp_disabled = {"openai"} if os.getenv("CI") else set()
models = initialize_model_list(config, disabled_providers=temp_disabled)
```

=== File: docs/plan_postchain_checklist.md ===



==
plan_postchain_checklist
==


# PostChain Implementation Checklist

This checklist provides step-by-step instructions for setting up the PostChain project, implementing the missing `chorus_graph.py`, resolving directory and import issues, and running the test suite. Follow each step carefully to ensure a coherent and functional integration.

---

## 1. Verify and Correct Directory Structure

- [x] Ensure the project directory follows this structure:
  ```
  Choir/
  ├── api/
  │   ├── app/
  │   │   ├── chorus_graph.py    # <-- Ensure this file exists
  │   │   └── postchain/
  │   │       ├── __init__.py
  │   │       └── schemas/
  │   │           ├── __init__.py
  │   │           ├── aeiou.py
  │   │           └── state.py
  │   └── tests/
  │       └── postchain/
  │           ├── __init__.py
  │           ├── test_cases.py
  │           ├── test_framework.py
  │           └── analysis.py
  └── tests/
      └── postchain/
          ├── __init__.py
          ├── test_cases.py
          ├── test_framework.py
          └── analysis.py
  ```
- [x] Consolidate tests into a single directory (at `api/tests/postchain`) to avoid duplication.

---

## 2. Implement the Missing `chorus_graph.py`

- [x] Create the file `api/app/chorus_graph.py` if it does not exist.
- [x] Add a minimal implementation with handlers for each phase:
  - `action_handler`
  - `experience_handler`
  - `intention_handler`
  - `observation_handler`
  - `understanding_handler` (includes looping decision logic)
  - `yield_handler`
- [x] Define edges to connect phases and use conditional edges for looping from `understanding` to either `action` or `yield`.
- [x] Looping at understanding is to be handled by a looping probability from 0 to 1. each understanding phase is parameterized by this threshold. the user and the system will be able to pass in their own probabilities to multiply. so a user signal of 0.0 or a system signal of 0.0 is looping: false.

---

## 3. Fix Import Issues in Tests

- [x] Update import statements in `tests/postchain/test_cases.py` to use absolute paths:
  ```python
  from tests.postchain.test_framework import PostChainTester
  from api.app.chorus_graph import create_chorus_graph
  ```
- [x] Ensure each test directory has an `__init__.py` file.

---

## 4. Ensure PYTHONPATH is Correct

- [x] Set the `PYTHONPATH` when running tests:
  ```bash
  PYTHONPATH=. pytest tests/postchain/test_cases.py -v
  ```
- [x] Alternatively, create a `pytest.ini` at the project root with the following configuration:
  ```ini
  [pytest]
  pythonpath = .
  asyncio_mode = auto
  ```

---

## 5. Verify Dependencies

- [x] Install all necessary dependencies:
  ```bash
  pip install pytest pytest-asyncio langgraph pandas matplotlib seaborn
  ```
- [x] Ensure your virtual environment is activated and properly set up.

---

## 6. Run Your Tests

- [x] Execute the test suite using:
  ```bash
  pytest tests/postchain/test_cases.py -v
  ```

---

## 7. Confirm Coherence

- [x] Verify that the schemas exist and are correctly defined:
  - `api/app/postchain/schemas/aeiou.py` should define `AEIOUResponse`.
  - `api/app/postchain/schemas/state.py` should define `ChorusState`.
- [x] Ensure that each phase handler returns a consistent state structure.
- [x] Confirm all test cases align with the implemented handlers and schemas.

---

## 8. Final Verification and Next Steps

- [x] Run the tests and confirm they execute without errors.
- [x] Expand the handlers with real model integrations as required.
- [x] Implement detailed logging and analysis once the basic test suite is stable.
- [ ] Integrate tool binding and persistence layers in subsequent iterations.

---

## 9. Logging and Observability

- [x] Implement structured logging for each phase handler to capture:
  - Phase name
  - Input state
  - Output state
  - Confidence scores
  - Reasoning text
  - Timestamps
- [x] Ensure logs are stored in a structured format (e.g., JSONL) for easy analysis.
- [ ] Set up centralized logging infrastructure (optional but recommended for production).

## 10. Error Handling and Robustness

- [x] Define clear error handling strategies for each phase:
  - Model API failures
  - Schema validation errors
  - Unexpected state transitions
- [x] Implement graceful degradation and informative error messages for end-users.
- [ ] Implement retry mechanisms with exponential backoff for transient errors.

## 11. Performance and Scalability

- [ ] Benchmark the performance of each phase individually and the entire PostChain.
- [ ] Identify bottlenecks and optimize critical paths.
- [ ] Plan for future scalability (e.g., parallel processing, caching strategies).

## 12. Documentation and Knowledge Sharing

- [x] Document each phase handler clearly, including:
  - Purpose and responsibilities
  - Input/output schemas
  - Dependencies and external integrations
- [x] Maintain up-to-date conceptual documentation reflecting the current architecture.
- [x] Regularly update the checklist and documentation as the implementation evolves.

---

## Implementation Progress Summary

### Completed

- ✅ Basic LangGraph structure with all AEIOU-Y nodes and edges
- ✅ Probability-based looping mechanism from understanding to action/yield
- ✅ Comprehensive test suite covering basic flow and looping scenarios
- ✅ Error handling for various failure scenarios
- ✅ Support for streaming responses with token-by-token callbacks
- ✅ State management ensuring consistency across phases
- ✅ Detailed logging for debugging and analysis

### In Progress

- 🔄 Tool integration for enhanced capabilities
- 🔄 Multi-model support with provider-specific adaptations
- 🔄 Performance optimization and benchmarking

### Next Steps

- ⏱️ Complete tool integration (web search, function calling)
- ⏱️ Implement retry mechanisms for model API failures
- ⏱️ Set up centralized logging for production environments
- ⏱️ Develop visualization tools for graph execution

---

## Troubleshooting Tips

- [x] If you encounter import issues, double-check the `__init__.py` files and PYTHONPATH settings.
- [x] Verify directory structure carefully to resolve any ambiguity between `api/tests/postchain` and `tests/postchain`.
- [x] Monitor logs in `tests/postchain_tests.log` for detailed error and event traces.
- [x] For recursion errors, check the `recursion_limit` configuration and ensure proper loop termination.
- [x] For state consistency issues, verify that all phases correctly maintain and update the state structure.

This checklist serves as a guide to ensure your PostChain implementation and test suite are correctly structured and functional. Follow it step-by-step to address any issues and facilitate smooth integration and testing.

=== File: docs/plan_tools_qdrant_checklist.md ===



==
plan_tools_qdrant_checklist
==


# 🔧 Qdrant Vector Database Tools Implementation Plan

## 🎯 Core Principles

1. **Test-Driven Development** - Start with tests, add functionality incrementally
2. **Provider Agnosticism** - No hardcoded model/provider references
3. **Configuration Centrality** - Use Config for all settings
4. **LangGraph Integration** - Implement using ToolNode for proper LangGraph workflow
5. **Streaming Support** - Utilize streaming for better performance
6. **Testing Across Providers** - Ensure tools work with multiple model providers

## 📝 Test-Driven Development Approach

We'll follow a disciplined TDD approach, building functionality incrementally, with each test adding complexity:

### 1️⃣ Tool Function Tests

Our first tests focus directly on the Qdrant tool functions:

```python
# Test 1: Qdrant Search Tool
@pytest.mark.asyncio
async def test_qdrant_search_tool():
    """Test the Qdrant search tool."""
    config = Config()
    # Create test content in the vector database
    test_content = f"Test content for search tool {uuid.uuid4()}"

    # Use the search tool
    result = await qdrant_search(test_content[:10])  # Search with first 10 chars

    # Verify results
    assert "Found semantically similar information" in result
    assert test_content in result

# Test 2: Qdrant Store Tool
@pytest.mark.asyncio
async def test_qdrant_store_tool():
    """Test the Qdrant store tool."""
    config = Config()
    test_content = f"Test content for store tool {uuid.uuid4()}"

    # Use the store tool
    result = await qdrant_store(test_content)

    # Verify results
    assert "Successfully stored" in result
    assert "ID" in result

    # Extract the ID for later use in delete test
    vector_id = extract_id_from_result(result)
    return vector_id

# Test 3: Qdrant Delete Tool
@pytest.mark.asyncio
async def test_qdrant_delete_tool():
    """Test the Qdrant delete tool."""
    # First store something to get an ID
    vector_id = await test_qdrant_store_tool()

    # Then delete it
    result = await qdrant_delete(vector_id)

    # Verify deletion
    assert "Successfully deleted" in result
    assert vector_id in result

# Test 4: Combined Tool Operations
@pytest.mark.asyncio
async def test_qdrant_tool_sequence():
    """Test a sequence of Qdrant tool operations."""
    # 1. Store some content
    test_content = f"Test content for sequence {uuid.uuid4()}"
    store_result = await qdrant_store(test_content)
    assert "Successfully stored" in store_result

    # 2. Search for the content
    search_result = await qdrant_search(test_content[:15])
    assert test_content in search_result

    # 3. Delete the content
    vector_id = extract_id_from_result(store_result)
    delete_result = await qdrant_delete(vector_id)
    assert "Successfully deleted" in delete_result

    # 4. Verify it's gone by searching again
    search_again_result = await qdrant_search(test_content[:15])
    assert test_content not in search_again_result
```

### 2️⃣ LangGraph ToolNode Tests

Next, test the tools via LangGraph's ToolNode:

```python
@pytest.mark.asyncio
async def test_qdrant_tool_node():
    """Test Qdrant tools via ToolNode."""
    # Create the tool node
    qdrant_tools = [qdrant_search, qdrant_store, qdrant_delete]
    tool_node = ToolNode(qdrant_tools)

    # Create an AI message with tool call
    message_with_store_call = AIMessage(
        content="",
        tool_calls=[
            {
                "name": "qdrant_store",
                "args": {"content": "Test content for ToolNode"},
                "id": "tool_call_id_1",
                "type": "tool_call",
            }
        ],
    )

    # Invoke the tool node for store
    store_result = await tool_node.ainvoke({"messages": [message_with_store_call]})

    # Verify store execution
    assert "messages" in store_result
    assert "Successfully stored" in store_result["messages"][0].content

    # Create a search message
    message_with_search_call = AIMessage(
        content="",
        tool_calls=[
            {
                "name": "qdrant_search",
                "args": {"query": "Test content for ToolNode"},
                "id": "tool_call_id_2",
                "type": "tool_call",
            }
        ],
    )

    # Invoke the tool node for search
    search_result = await tool_node.ainvoke({"messages": [message_with_search_call]})

    # Verify search execution
    assert "messages" in search_result
    assert "Test content for ToolNode" in search_result["messages"][0].content
```

### 3️⃣ Single Model End-to-End Tests

Test the entire workflow with a single model:

```python
@pytest.mark.asyncio
async def test_qdrant_workflow_single_model():
    """Test the end-to-end Qdrant workflow with a single model."""
    config = Config()

    # Get a tool-compatible model
    tool_models = initialize_tool_compatible_model_list(config)
    model_config = tool_models[0]

    # Create the workflow
    workflow = create_qdrant_workflow(model_config=model_config)

    # Test store operation
    test_content = f"Vector storage test content {uuid.uuid4()}"
    system_message = SystemMessage(content="You are a helpful assistant with vector database access.")

    store_result = await workflow.invoke(
        {
            "messages": [
                system_message,
                HumanMessage(content=f"Please store this information: {test_content}")
            ]
        }
    )

    # Verify store operation succeeded
    assert any("Successfully stored" in msg.content for msg in store_result["messages"])

    # Test search operation
    search_result = await workflow.invoke(
        {
            "messages": [
                system_message,
                HumanMessage(content=f"Find information about {test_content[:20]}")
            ]
        }
    )

    # Verify search operation found the content
    assert any(test_content in msg.content for msg in search_result["messages"])
```

### 4️⃣ Multi-Model Compatibility Tests

Test with multiple models to verify cross-provider compatibility:

```python
@pytest.mark.asyncio
async def test_multi_model_compatibility():
    """Test Qdrant tools with multiple model providers."""
    config = Config()

    # Get tool-compatible models
    tool_models = initialize_tool_compatible_model_list(config)

    results = {}
    for model_config in tool_models:
        try:
            # Create workflow with this model
            workflow = create_qdrant_workflow(model_config=model_config)

            # Test basic operations
            test_content = f"Test for {model_config}: Vector data {uuid.uuid4()}"
            system_message = SystemMessage(content="You are a helpful assistant.")

            # Store content
            store_result = await workflow.invoke(
                {
                    "messages": [
                        system_message,
                        HumanMessage(content=f"Store this: {test_content}")
                    ]
                }
            )

            # Search for content
            search_result = await workflow.invoke(
                {
                    "messages": [
                        system_message,
                        HumanMessage(content=f"Search for: {test_content[:20]}")
                    ]
                }
            )

            # Record results
            results[str(model_config)] = {
                "store_success": any("Successfully stored" in msg.content for msg in store_result["messages"]),
                "search_success": any(test_content in msg.content for msg in search_result["messages"]),
            }

        except Exception as e:
            results[str(model_config)] = {"error": str(e)}

    # Generate report
    print("\n===== Model Compatibility Report =====")
    for model, result in results.items():
        print(f"\n{model}:")
        if "error" in result:
            print(f"  ❌ Error: {result['error']}")
        else:
            print(f"  Store: {'✅' if result['store_success'] else '❌'}")
            print(f"  Search: {'✅' if result['search_success'] else '❌'}")
```

### 5️⃣ Multi-Model Workflow Tests

Finally, test the tools in a complex multi-model workflow similar to `test_tool_random_multimodel.py`:

```python
@pytest.mark.asyncio
async def test_qdrant_random_multimodel():
    """Test Qdrant tools in a random multi-model conversation."""
    config = Config()

    # Create a RandomToolMultiModelTester instance
    tester = RandomToolMultiModelTester(config)

    # Add Qdrant tools to the tester
    qdrant_tools = [qdrant_search, qdrant_store, qdrant_delete]

    # Run multiple random sequence tests
    results = await tester.run_multiple_tests_with_tools(
        tools=qdrant_tools,
        test_count=3,
        min_turns=5,
        max_turns=10
    )

    # Analyze and report results
    print("\n===== Random Multi-Model Test Results =====")
    tester.print_results()

    # Verify essential metrics
    assert results["tool_success_rate"] > 0.7  # At least 70% tool use success
    assert results["context_maintenance_rate"] > 0.8  # Good context maintenance
```

## 🏗️ Architecture Considerations

We are implementing Qdrant vector database tools following the provider-agnostic patterns established by the existing web search tools:

1. **LangGraph ToolNode Pattern**: Using the `ToolNode` class from LangGraph to manage tool calls.

```python
from langchain_core.tools import tool
from langgraph.prebuilt import ToolNode

@tool
async def qdrant_search(query: str, collection: str = None, limit: int = 5) -> str:
    """Search for semantically similar content in the vector database."""
    # Implementation
    return "Search results formatted as text"

@tool
async def qdrant_store(content: str, collection: str = None, metadata: dict = None) -> str:
    """Store information in the vector database for later retrieval."""
    # Implementation
    return "Successfully stored with ID: xyz-123"

# Create a ToolNode with all Qdrant tools
qdrant_tools = [qdrant_search, qdrant_store]
qdrant_tool_node = ToolNode(qdrant_tools)
```

2. **Embedding Abstraction**: Creating a simple embedding function that can be updated in one place when we add more providers.

```python
# app/langchain_utils.py
from langchain_openai import OpenAIEmbeddings

async def generate_embedding(text: str, config: Config) -> List[float]:
    """
    Generate an embedding for the given text.

    Args:
        text: The text to generate an embedding for
        config: Configuration object

    Returns:
        A list of floats representing the embedding vector
    """
    # For now, we're using OpenAI embeddings, but this function allows us
    # to change the implementation in one place later
    embeddings = OpenAIEmbeddings(model=config.EMBEDDING_MODEL)
    return await embeddings.aembed_query(text)
```

3. **Provider-Agnostic Model Selection**: Using `initialize_tool_compatible_model_list` to dynamically select appropriate models.

```python
from app.config import Config
from app.langchain_utils import initialize_tool_compatible_model_list, ModelConfig

def create_qdrant_workflow(
    model_config: Optional[ModelConfig] = None,
    config: Optional[Config] = None,
    disabled_providers: set = None
) -> StateGraph:
    """Create a LangGraph workflow for vector database operations."""
    config = config or Config()

    # If no specific model provided, get first available tool-compatible model
    if model_config is None:
        tool_models = initialize_tool_compatible_model_list(config, disabled_providers)
        if not tool_models:
            raise ValueError("No tool-compatible models available with current configuration")
        model_config = tool_models[0]
        logger.info(f"Selected model: {model_config}")

    # Continue with workflow creation using the selected model
    # ...
```

4. **Streaming Support**: Adapting our existing `abstract_llm_completion_stream` for LangGraph compatibility.

```python
# app/langchain_utils.py
async def langchain_llm_completion_stream(
    model_name: str,
    messages: List[BaseMessage],
    config: Config,
    temperature: Optional[float] = None,
    max_tokens: Optional[float] = None,
    tools: Optional[List[Any]] = None
) -> AsyncGenerator[Dict[str, Any], None]:
    """Stream completions using LangChain message format."""
    # Convert LangChain messages to the format expected by abstract_llm_completion_stream
    converted_messages = []
    for msg in messages:
        if isinstance(msg, HumanMessage):
            converted_messages.append({"role": "user", "content": msg.content})
        elif isinstance(msg, AIMessage):
            converted_messages.append({
                "role": "assistant",
                "content": msg.content,
                "tool_calls": msg.tool_calls if hasattr(msg, "tool_calls") else None
            })
        elif isinstance(msg, SystemMessage):
            converted_messages.append({"role": "system", "content": msg.content})
        elif isinstance(msg, ToolMessage):
            converted_messages.append({
                "role": "tool",
                "content": msg.content,
                "tool_call_id": msg.tool_call_id
            })

    # Use existing streaming function with converted messages
    async for chunk in abstract_llm_completion_stream(
        model_name=model_name,
        messages=converted_messages,
        config=config,
        temperature=temperature,
        max_tokens=max_tokens,
        tools=tools
    ):
        yield chunk
```

5. **Zero Provider References**: Ensuring no model/provider names are hardcoded in the implementation.

```python
# BAD (Don't do this):
def create_tools_for_anthropic():
    # Implementation tied to one provider
    return [tool1, tool2]

# GOOD (Provider-agnostic):
@tool
async def qdrant_search(query: str, collection: str = None, limit: int = 5) -> str:
    """Search for semantically similar content in the vector database."""
    config = Config()
    # Use collection from config, not hardcoded
    if collection is None:
        collection = config.MESSAGES_COLLECTION

    # Use embedding generation that comes from config
    embedding = await generate_embedding(query, config)

    # Rest of implementation
    return "Search results"
```

## ✅ Implementation Checklist

### 1️⃣ Vector Database Tools

#### Core Embedding Function

- [x] Add embedding functionality to work with Qdrant tools
- [x] Ensure function uses Config.EMBEDDING_MODEL
- [x] Keep implementation details contained for easy future extension

#### Qdrant Search Tool

- [x] Implement `qdrant_search` tool with `@tool` decorator
- [x] Use Config.MESSAGES_COLLECTION as default collection
- [x] Add proper error handling and logging
- [x] Format search results for readability

#### Qdrant Store Tool

- [x] Implement `qdrant_store` tool with `@tool` decorator
- [x] Use Config.MESSAGES_COLLECTION as default collection
- [x] Store metadata including timestamp and model info
- [x] Return vector ID for reference

#### Qdrant Delete Tool

- [x] Implement `qdrant_delete` tool with `@tool` decorator
- [x] Use Config.MESSAGES_COLLECTION as default collection
- [x] Add proper error handling for non-existent vectors
- [x] Return clear success/failure messages

### 2️⃣ LangGraph Integration

#### LangChain Adapter

- [x] Implement `langchain_llm_completion_stream` to support tools
- [x] Handle proper conversion between message formats
- [x] Ensure streaming support for incremental updates
- [x] Test with various message types (human, assistant, system, tool)

#### Qdrant Workflow Graph

- [x] Implement `create_qdrant_workflow` function
- [x] Create proper nodes for agent and tools
- [x] Configure workflows with conditional edges
- [x] Support model selection from tool-compatible models

### 3️⃣ Testing Implementation

#### Basic Tool Testing

- [x] Create tests for individual Qdrant tool functions
- [x] Test store, search, and delete operations independently
- [x] Test proper error handling and edge cases
- [x] Verify proper async handling for all operations

#### Workflow Testing

- [x] Test tools in LangGraph ToolNode context
- [x] Test complete workflow with an OpenAI model
- [x] Test store, search, and delete operations in workflow
- [x] Add proper logging for diagnostic visibility

#### Provider Compatibility Testing

- [ ] Test all tool-compatible models across providers
- [ ] Document provider-specific issues or limitations
- [ ] Create compatibility matrix for Qdrant tools
- [ ] Identify workarounds for problematic providers

#### Multi-Model Testing

- [ ] Implement complex multi-model testing like `test_tool_random_multimodel.py`
- [ ] Test with different provider sequences
- [ ] Measure context preservation across models
- [ ] Document cross-provider compatibility issues

## 📊 Current Provider Compatibility

Based on our current implementation and testing:

| Provider  | Current Status    | Notes                                         |
| --------- | ----------------- | --------------------------------------------- |
| OpenAI    | ✅ Working        | Successfully tested, especially with o1 model |
| Anthropic | ❓ Not yet tested | Expected to work based on tool support        |
| Mistral   | ❓ Not yet tested | Expected to work based on tool support        |
| Google    | ❓ Not yet tested | May have limited compatibility                |
| Groq      | ❓ Not yet tested | Uncertain compatibility                       |

## 🚀 Next Steps

1. ✅ Implemented individual Qdrant tool functions (search, store, delete)
2. ✅ Created basic tests for tool functions
3. ✅ Implemented LangGraph workflow with conditional routing
4. ✅ Tested workflow with OpenAI model
5. ✅ Fixed async handling for proper operation
6. [ ] Test with multiple model providers to create compatibility matrix
7. [ ] Create complex multi-model test scenarios
8. [ ] Document provider-specific compatibility findings
9. [ ] Explore possible optimizations (caching, batch operations, etc.)
10. [ ] Consider implementation of future improvements

## 📝 Future Improvements

1. Support for multiple embedding models (not just text-embedding-ada-002)
2. Extended metadata for better searchability
3. Collection management tools
4. Vector clustering and organization tools
5. Integration with RAG workflows
6. Support for hybrid search (keyword + vector)

=== File: docs/plan_tools_search_checklist.md ===



==
plan_tools_search_checklist
==


# 🔧 Tool Integration Implementation Plan

## 🎯 Core Principles

1. **Test-Driven Development** - Write tests before implementation
2. **Incremental Integration** - Start with simple tools, then advance to complex ones
3. **Dual Testing Approach** - Test tools both standalone and in multimodel chat threads
4. **Minimal Dependencies** - Keep implementations as simple as possible
5. **Clear Interfaces** - Define consistent tool interfaces

## 🏗️ Architecture Considerations

We are currently using a temporary architecture while we iterate on tool implementations:

1. **Current Implementation**: Uses a `ConversationWithTools` wrapper class (`app/tools/conversation.py`) that:

   - Manages conversation state
   - Extracts tool calls using regex
   - Executes tools and manages message history
   - Handles model-specific formatting needs (especially for Mistral models)

2. **Known Limitations**:

   - Duplicates logic that could be in `abstract_llm_completion_stream`
   - Uses regex-based extraction rather than structured tool calling
   - Not integrated with the core Post Chain architecture
   - Different model providers have inconsistent tool calling formats

3. **Future Direction**:
   - Integrate tool support directly into `abstract_llm_completion_stream`
   - Use LangGraph for proper state management in the Post Chain
   - Standardize the tool calling interface across providers

For now, we'll continue with the current approach to make rapid progress, while documenting areas for future improvement.

## ✅ Implementation Checklist

### 1️⃣ Calculator Tool

#### Standalone Calculator Implementation

- [x] Create calculator tool interface (`app/tools/base.py` and `app/tools/calculator.py`)
- [x] Implement basic arithmetic operations
- [x] Add support for complex expressions (using AST-based evaluation)
- [x] Write standalone unit tests (`tests/tools/test_calculator.py`)
- [x] Document calculator API

#### Calculator Integration Tests

- [x] Create test for calculator in multimodel chat thread
- [x] Verify context maintenance across model transitions
- [x] Test error handling for invalid expressions
- [x] Document integration patterns
- [x] Use complex calculations to ensure tool is actually used (`tests/tools/test_multimodel_with_tools.py`)

#### Calculator Implementation Notes

- The calculator uses Python's AST module for secure evaluation
- Implementation verifies operation types for safety
- Tool pattern allows both direct usage and integration with conversation
- Supports both Mistral and non-Mistral models (different message formatting)
- Testing requires complex calculations (10+ digit numbers) to ensure models use the tool

### 2️⃣ Web Search Tool

#### Web Search Setup

- [x] Select web search API providers (DuckDuckGo, Tavily, Brave Search)
- [x] Configure API keys and environment variables
- [x] Document API limitations and rate limits
- [x] Create fallback logic between search providers
- [x] Create provider switching logic
- [ ] Implement caching to reduce API calls
- [x] Test provider fallback scenarios
- [x] Implement rate limit handling with exponential backoff

#### Primary Search Implementation (Brave Search)

- [x] Create Brave Search tool interface (`app/tools/brave_search.py`)
- [x] Implement structured result formatting
- [x] Add rate limit handling with retry logic and exponential backoff
- [x] Configure as default search provider due to higher reliability
- [x] Write standalone unit tests
- [x] Document Brave Search API usage & limitations

#### Backup Search Implementations

- [x] Implement DuckDuckGo search (for development/testing)
- [x] Implement Tavily Search as fallback option
- [x] Create provider switching logic with intelligent fallback order
- [x] Test provider fallback scenarios
- [x] Document multi-provider strategy

#### Web Search Provider Strategy

- [x] Default to Brave Search as primary provider (most reliable in testing)
- [x] Fall back to Tavily, then DuckDuckGo if primary provider fails
- [x] Added exponential backoff for rate limit handling (Brave Search)
- [x] Improved error handling for all providers
- [x] Added retry logic with configurable attempts
- [ ] Implement request caching to reduce API usage

#### Search Provider Reliability Assessment

Based on extensive testing, here's our assessment of search providers:

1. **Brave Search**: ★★★★☆

   - Most reliable provider in our testing
   - High-quality results with official API
   - Rate limits can be an issue (1 request/second on free tier)
   - Successfully implemented exponential backoff to handle rate limits
   - Now configured as our default primary provider

2. **Tavily Search**: ★★★☆☆

   - AI-optimized search, but inconsistent reliability
   - Frequent "Expecting value: line 1 column 1 (char 0)" JSON parsing errors
   - Good result quality when working
   - Moved to first fallback position due to reliability issues

3. **DuckDuckGo Search**: ★★☆☆☆
   - No API key required, good for development
   - Frequent rate limit errors (202 Ratelimit)
   - "unsupported value" errors with different backends
   - Used as last resort fallback

Our current strategy ensures maximum reliability by starting with the most consistent provider and falling back as needed. Exponential backoff and retry logic has significantly improved overall search reliability.

#### Web Search Integration Tests

- [x] Create test for web search in multimodel chat thread
- [x] Test different query types and result handling
- [x] Verify context maintenance with search results
- [x] Test search provider fallback
- [x] Document integration patterns

#### Web Search Improvements

- [x] Add timestamp to system prompt to help models understand current date
- [x] Add trust instructions to help models accept search results that contradict training data
- [x] Add usage guidance in search results for events after model training cutoff
- [x] Test handling of search results about "future" events relative to model training
- [x] Document best practices for prompting models with recent events

#### LangGraph Provider Compatibility

- [x] Test web search tool with different providers in LangGraph
- [x] Document provider-specific compatibility issues
- [x] Identify best-performing models for tool usage
- [x] Create detailed test reports for each provider/model

#### Message Format Standardization

- [x] Identify provider-specific message format requirements
- [x] Enhance `convert_to_langchain_messages` function for multi-provider compatibility
- [x] Fix empty content handling for Anthropic models
- [x] Implement special formatting for Google Gemini models
- [x] Add proper tool message conversion for Mistral models
- [x] Create comprehensive test suite for message format conversion
- [x] Verify compatibility across OpenAI, Anthropic, Google, Mistral, and Groq

#### Provider-Specific Format Handling

Our improvements to the `convert_to_langchain_messages` function addressed several key issues:

1. **Empty Content Handling**:

   - Fixed issues with Anthropic models rejecting empty content messages
   - Ensured Google Gemini messages use a space instead of empty string
   - Properly handled message sequence constraints for Mistral models

2. **Tool Message Conversion**:

   - Enhanced conversion of tool calls and results across providers
   - Implemented proper extraction of tool name and tool_call_id
   - Created deep copies to prevent side effects during message manipulation

3. **Special Case Processing**:
   - Added special handling for Google Gemini when only system messages are present
   - Implemented proper conversion for Mistral when assistant messages would be last in sequence

These improvements have significantly enhanced cross-provider compatibility, allowing us to use models from OpenAI, Anthropic, Mistral, and Groq in the same conversation with consistent tool usage. Testing confirms these changes have reduced API errors and improved the reliability of multi-model conversations with tools.

##### Provider Compatibility Findings

1. **OpenAI Models**: ✅ 75% Success

   - ❌ gpt-4o: Failed the test - didn't return the correct score (34-0 instead of 40-22) despite successful tool usage
   - ✅ gpt-4o-mini: Successfully used web search tool and returned correct information
   - ✅ o1: Successfully used web search tool and returned correct information
   - ✅ o3-mini: Successfully used web search tool and returned correct information
   - Implementation note: All models correctly used function calling, but gpt-4o had incorrect information in its response

2. **Anthropic Models**: ✅ 100% Success

   - ✅ Claude-3.7-Sonnet: Successfully used web search tool and returned correct information
   - ✅ Claude-3.5-Haiku: Successfully used web search tool and returned correct information
   - Implementation note: Previous empty content errors now fixed with proper message format handling

3. **Google Models**: ⚠️ 25% Success (Mixed Results)

   - ✅ gemini-2.0-flash: Successfully used web search tool and returned correct information
   - ❌ gemini-2.0-flash-lite: Failed to use web search tool; responded as if it couldn't access future information
   - ❌ gemini-2.0-pro-exp-02-05: Failed due to "500 Internal error occurred" from Google API
   - ❌ gemini-2.0-flash-thinking-exp-01-21: Failed because "Function calling is not enabled for this model"
   - Implementation note: Only production models reliably support function calling; empty content errors now fixed

4. **Cohere Models**: ❌ 0% Success

   - Failed to properly use tools despite claiming compatibility
   - Different tool calling format requires custom implementation
   - Requires direct integration of search results rather than tool-based interaction

5. **Fireworks Models**: ⚠️ 25% Success (Improved)

   - ❌ deepseek-r1: Failed to make any tool calls; gave a general response without using the tool
   - ✅ deepseek-v3: After fixing message format issues, now successfully uses the web search tool and returns correct information
   - ❌ qwen2p5-coder-32b-instruct: Failed to make any tool calls; responded with incorrect information
   - ❌ qwen-qwq-32b: Previously returned a 404 error, now functions correctly with proper message formatting
   - Implementation note: Fixed message format issues have improved compatibility with some Fireworks models

6. **Mistral Models**: ✅ 100% Success

   - ✅ pixtral-12b-2409: Successfully used web search tool and returned correct information
   - ✅ mistral-small-latest: Successfully used web search tool and returned correct information
   - ✅ pixtral-large-latest: Successfully used web search tool and returned correct information
   - ✅ mistral-large-latest: Successfully used web search tool and returned correct information
   - ✅ codestral-latest: Successfully used web search tool and returned correct information
   - Implementation note: Message format improvements fully resolved previous API errors with Mistral models

7. **Groq Models**: ✅ 60% Success (Improved)
   - ❌ llama-3.3-70b-versatile: Failed to make any tool calls; gave a general response without using the tool
   - ✅ qwen-qwq-32b: Successfully used web search tool and returned correct information
   - ❌ deepseek-r1-distill-qwen-32b: Failed to make any tool calls; gave a response without using the tool
   - ✅ deepseek-r1-distill-llama-70b-specdec: Previously failed with 503 errors, now functioning with message format fixes
   - ✅ deepseek-r1-distill-llama-70b: Successfully used web search tool and returned correct information
   - Implementation note: Message format improvements resolved API errors with several Groq models

##### LangGraph Tool Compatibility Matrix

| Provider  | Models Tested | Success Rate | Top Performing Models                       | Common Failure Modes                                          |
| --------- | ------------- | ------------ | ------------------------------------------- | ------------------------------------------------------------- |
| OpenAI    | 4             | 75%          | o1, o3-mini, gpt-4o-mini                    | Incorrect information despite tool usage                      |
| Anthropic | 2             | 100%         | Claude-3.7-Sonnet, Claude-3.5-Haiku         | None observed                                                 |
| Google    | 4             | 25%          | gemini-2.0-flash                            | Function calling not supported, API errors                    |
| Cohere    | Multiple      | 0%           | None                                        | Different tool calling format requiring custom implementation |
| Fireworks | 4             | 25%          | deepseek-v3                                 | No tool usage attempts, some API errors                       |
| Mistral   | 5             | 100%         | All tested models                           | None (previous rate limiting and format issues resolved)      |
| Groq      | 5             | 60%          | qwen-qwq-32b, deepseek-r1-distill-llama-70b | Some models still don't attempt tool usage                    |

##### Comprehensive List of Models with Working Tool Support

Based on our extensive testing, the following models successfully work with tool usage:

**OpenAI Models:**

- o1
- o3-mini
- gpt-4o-mini

**Anthropic Models:**

- Claude-3.7-Sonnet
- Claude-3.5-Haiku

**Google Models:**

- gemini-2.0-flash

**Mistral Models:**

- mistral-small-latest
- mistral-large-latest
- pixtral-12b-2409
- pixtral-large-latest
- codestral-latest

**Fireworks Models:**

- deepseek-v3

**Groq Models:**

- qwen-qwq-32b
- deepseek-r1-distill-llama-70b

These models successfully:

1. Make appropriate tool calls when presented with queries requiring external information
2. Process tool responses correctly
3. Incorporate tool-provided information into their final responses
4. Return accurate information based on tool results

When implementing tool support in production, we recommend prioritizing models from Anthropic and Mistral for their 100% success rates, followed by selected OpenAI models. For cost-sensitive applications, Mistral's models provide an excellent balance of reliability and performance.

##### Updated Implementation Recommendations

- **For Production**: Use Anthropic or Mistral models for most reliable tool usage; OpenAI's o1, o3-mini, or gpt-4o-mini as alternatives
- **Most Accurate**: Anthropic models maintain their 100% success rate, with Mistral models close behind
- **Best Performance/Cost**: Mistral's large models and smaller OpenAI models offer good balance of reliability and cost
- **Custom Implementations**: Maintain provider-specific implementations for Cohere and providers with inconsistent tool support
- **Message Format Handling**: Standardized message conversion now handles provider-specific requirements automatically
- **Error Handling**: Improved error handling for rate limits, API failures, and service unavailable errors
- **Fallback Strategy**: Implemented provider detection and appropriate message formatting for each model provider
- **Search Provider**: Use Brave Search as primary provider with fallback to Tavily and DuckDuckGo
- **Rate Limiting**: Exponential backoff with retry logic successfully implemented for Brave Search

##### Next Steps for Tool Integration

- Enhance unified tool interface to handle further provider-specific requirements
- Continue refining message format handling for emerging models and providers
- Implement automatic fallback mechanisms for models that don't support function calling
- Add rate limit handling with exponential backoff for additional providers
- Develop robust error handling for API failures and service outages
- Continue testing emerging models and updating compatibility matrix
- Implement monitoring for tool usage success rates across different providers

##### In-Depth Analysis of Successful Tool Usage

Based on the examination of test reports from successful models, we've identified several key factors that contribute to effective tool usage:

1. **Tool Call Format Consistency**: Successful models like Mistral and Groq's `qwen-qwq-32b` consistently format their tool calls in a way that matches the expected OpenAI function calling format.

2. **Query Refinement**: Top-performing models often refine the user's query to create more focused search terms (e.g., "Super Bowl LIX 2025 winner final score" instead of the original query) which leads to more relevant results.

3. **Response Quality**: Successful models not only use the tools correctly but also synthesize the information into coherent, accurate responses that directly answer the user's question.

4. **Error Resilience**: Models that handle search provider errors gracefully (falling back to alternative providers) show better overall performance.

5. **Tool Selection Intelligence**: Many failures stem from models not even attempting to use tools. This suggests we need better tool selection prompting or fallback approaches for these models.

For implementation, we should ensure our tool interface handles these variations by:

- Normalizing tool call formats across different providers
- Providing clear instructions about when and how to use tools
- Implementing fallback mechanisms for models that don't make tool calls
- Monitoring and handling rate limits and API errors proactively

### 3️⃣ Qdrant Integration

#### Qdrant Setup

- [ ] Verify Qdrant connection settings
- [ ] Configure collections and vector dimensions
- [ ] Test basic connectivity

#### Standalone Qdrant Implementation

- [ ] Create Qdrant search tool interface
- [ ] Implement vector search functionality
- [ ] Add result processing and formatting
- [ ] Write standalone unit tests
- [ ] Document Qdrant search API

#### Qdrant Integration Tests

- [ ] Create test for Qdrant search in multimodel chat thread
- [ ] Test different query types and vector search patterns
- [ ] Verify context maintenance with search results
- [ ] Document integration patterns

## 📝 Testing Frameworks

### Calculator Test Framework

```python
def test_calculator_basic():
    """Test basic calculator operations"""
    calculator = CalculatorTool()

    # Test addition
    assert calculator.calculate("2 + 2") == 4

    # Test subtraction
    assert calculator.calculate("10 - 5") == 5

    # Test multiplication
    assert calculator.calculate("3 * 4") == 12

    # Test division
    assert calculator.calculate("20 / 5") == 4
```

### Calculator Integration Test

```python
@pytest.mark.asyncio
async def test_calculator_in_multimodel_thread():
    """Test calculator tool in a multimodel conversation thread"""
    config = Config()

    # Initialize model list without OpenAI
    models = initialize_model_list(config, disabled_providers={"openai"})

    # Create a conversation with calculator tool
    conversation = ConversationWithTools(models, tools=[CalculatorTool()])

    # Run conversation with calculation request that models would struggle with
    complex_calculation = (
        "I need to verify a complex calculation. What is "
        "1234567890 * 9876543210 / 123456789? "
        "Please use the calculator tool to compute this precisely."
    )

    result = await conversation.process_message(complex_calculation)

    # Check for calculator tool usage
    tool_markers = ["[calculator] input:", "I'll use the calculator tool"]
    assert any(marker in result["content"] for marker in tool_markers)
```

## 🧠 Key Implementation Guidelines

### Tool Interface Pattern

```python
# app/tools/base.py
class BaseTool:
    """Base class for all tools"""
    name: str
    description: str

    async def run(self, input: str) -> str:
        """Execute the tool with the given input"""
        raise NotImplementedError()
```

### Conversation Integration Pattern

```python
# app/tools/conversation.py
class ConversationWithTools:
    """Manages a conversation that supports tool use across multiple models."""

    def __init__(
        self,
        models: List[ModelConfig],
        tools: List[BaseTool],
        config: Optional[Config] = None,
        system_prompt: Optional[str] = None
    ):
        """Initialize with models and tools"""

    async def process_message(self, user_message: str) -> Dict[str, Any]:
        """Process a user message, potentially using tools, and return response"""
```

## 📝 Usage Examples

### Calculator Tool

```python
# Standalone usage
calculator = CalculatorTool()
result = await calculator.run("sqrt(16) + 10")  # Returns "14.0"

# In conversation
conversation = ConversationWithTools(models, tools=[calculator], config=config)
response = await conversation.process_message(
    "What is 1234567890 * 9876543210? This is a complex calculation so please use the calculator."
)
```

### Anticipated Web Search Tool Usage

```python
# Standalone usage
search = BraveSearchTool(config=config)
results = await search.run("latest developments in quantum computing")

# With fallback options
search = WebSearchTool(
    primary_provider="brave",  # Now using Brave as primary provider
    fallback_providers=["tavily", "duckduckgo"],
    config=config
)
results = await search.run("news about AI regulations")

# In conversation
conversation = ConversationWithTools(models, tools=[search], config=config)
response = await conversation.process_message(
    "What are the latest developments in quantum computing?"
)
```
# Level 4 Documentation



=== File: docs/fqaho_simulation.md ===



==
fqaho_simulation
==


# FQAHO Simulation Framework

VERSION fqaho_simulation: 1.0

This document outlines the simulation framework for Choir's Fractional Quantum Anharmonic Oscillator (FQAHO) model, providing guidance for accurate parameter setting, modulation, and testing.

## Simulation Objectives

The FQAHO simulation serves multiple objectives:

1. Calibrate optimal parameter ranges and sensitivity coefficients
2. Test system response to various thread evolution scenarios
3. Verify the economic stability and fairness properties
4. Generate synthetic metadata for downstream analysis

## Parameter Framework

### Fractional Parameter (α)

- **Range**: 1 < α ≤ 2
- **Interpretation**: Controls memory effects and non-local interactions
- **Modulation Formula**:
  ```
  α(t,q) = 2 - δ₁(1-e^(-t/τ)) - δ₂q
  ```
  Where t is normalized thread age, q measures quality, τ sets the time constant, and δ₁, δ₂ determine sensitivity.

### Anharmonic Coefficient (K₀)

- **Range**: 0.5 ≤ K₀ ≤ 5.0
- **Interpretation**: Represents immediate feedback sensitivity
- **Modulation Formula**:
  ```
  K₀(r,α) = K₀_base * (1 + γ₁r) * (2/α)^γ₂
  ```
  Where r is the recent refusal ratio, γ₁ is refusal sensitivity, and γ₂ is the fractional coupling coefficient.

### Potential Order (m)

- **Range**: 2 ≤ m ≤ 4
- **Interpretation**: Represents network complexity and interaction depth
- **Modulation Formula**:
  ```
  m(c,n) = 2 + β₁tanh(c/c₀) + β₂log(1+n/n₀)
  ```
  Where c is citation count, n is co-author count, and β₁, β₂ are scaling coefficients.

## Implementation Approach

The FQAHO implementation functions as a sophisticated single-asset automated market maker (AMM) for stake pricing. This approach allows us to incorporate fractional effects through parameter modulation without requiring computationally intensive fractional calculus operations.

The core pricing formula:

```
P₀ = S₀[(2n+1)^(α/2) + (K₀λ)^{α/(m+1)}]
```

This provides fair price calculation while capturing:

- Long memory effects through α's modulation
- Heavy-tailed distributions through modified response curves
- Non-local interactions through citation-based parameter adjustments

## Simulation Phases

### Phase 1: Parameter Isolation

- Fix two parameters, vary the third
- Observe stake price response
- Repeat for all parameters
- Identify stable operating ranges

### Phase 2: Parameter Coupling

- Create a 3D parameter space (K₀, α, m)
- Identify regions of interest (stable, volatile, etc.)
- Map these regions to thread characteristics
- Define parameter coupling formulas

### Phase 3: Dynamic Trajectories

- Simulate thread evolution over time
- Track parameter trajectories
- Identify pattern types (e.g., "breakthrough thread," "steady contributor")
- Fine-tune sensitivity coefficients

## Test Scenarios

1. **New Thread Evolution**

   - Start with α ≈ 2.0, low K₀, low m
   - Test with various approval/refusal patterns
   - Verify parameter evolution matches expectations

2. **Mature Thread with Citations**

   - Start with mid-range α, stable K₀, higher m
   - Introduce citation events
   - Verify non-local value propagation

3. **Controversial Thread**

   - Introduce oscillating approval/refusal patterns
   - Test parameter stability under volatility
   - Verify price mechanisms create appropriate barriers

4. **Breakthrough Thread**
   - Simulate rapid approval and citation growth
   - Verify Lévy flight-like value distribution
   - Test parameter adaptation to rapid change

## Implementation Notes

- Use dimensionless units for cleaner analysis
- Create visualization tools for parameter evolution, price dynamics, and value distribution
- Store simulation metadata for AI training and pattern analysis
- Compare parameter regimes for highest intelligence emergence

## Success Criteria

The simulation successfully validates the FQAHO model when:

1. Parameters remain within stable bounds under diverse scenarios
2. Price discovery correctly values quality contributions
3. Memory effects appropriately influence current pricing
4. Non-local interactions propagate value effectively
5. Parameter coupling creates coherent evolution patterns

This framework enables us to implement a sophisticated economic model that captures the complex dynamics of knowledge creation while remaining computationally tractable and deterministic enough for blockchain implementation.

=== File: docs/fqaho_visualization.md ===



==
fqaho_visualization
==


# FQAHO Model Visualization Guide

VERSION fqaho_visualization: 1.0

Effective visualization is essential for understanding the complex parameter space and dynamics of the Fractional Quantum Anharmonic Oscillator model. This document outlines visualization approaches that help reveal patterns, stability regions, and emergent behaviors.

## Core Visualizations

### 1. Parameter Space Mapping

**3D Parameter Volume**

- Plot (α, K₀, m) as a 3D volume
- Color regions by stake price or stability metrics
- Identify stable operating regions
- Mark observed thread trajectories

**2D Parameter Slices**

- Create heatmaps of paired parameters (α-K₀, α-m, K₀-m)
- Overlay contour lines showing equal price points
- Highlight critical transition boundaries

### 2. Dynamic Trajectories

**Thread Evolution Paths**

- Plot parameter evolution over thread lifetime
- Color-code by thread type or quality metrics
- Identify common patterns and outliers
- Compare to theoretical predictions

**Price Evolution Curves**

- Show stake price changes over thread lifecycle
- Overlay approval/refusal events
- Highlight price sensitivity to parameter changes

### 3. Network Effects

**Citation Network Influence**

- Visualize how citations create parameter coupling
- Show Lévy flight patterns in value propagation
- Map value flows between connected threads

**Fractional Memory Effects**

- Display the decay kernel shape for different α values
- Demonstrate how past events influence current prices
- Compare with standard memory-less models

## Implementation Techniques

### Interactive Dashboards

- Create parameter sliders with real-time model updates
- Enable toggling between different test scenarios
- Provide zoom/rotate capabilities for 3D visualizations

### Animation

- Animate parameter evolution over simulated time
- Show critical transition points and regime changes
- Illustrate how parameter coupling creates coherent behavior

### Comparative Views

- Side-by-side comparison of standard QAHO vs. FQAHO
- Show differences in value distribution and memory effects
- Demonstrate improved accuracy of the fractional approach

## Technical Recommendations

- Implement visualizations using D3.js or Plotly for web interfaces
- Use Python with Matplotlib/Seaborn for detailed analysis
- Capture high-resolution snapshots at critical points
- Consider WebGL for complex 3D parameter spaces

## Documentation Integration

These visualizations should be incorporated into technical documentation with:

- Clear explanations of what each visualization reveals
- Connections to theoretical principles
- Practical implications for users and developers
- Progressive disclosure (simple views first, complex details available)

Effective visualization is crucial for communicating the sophistication of the FQAHO model while making it accessible to stakeholders with varying levels of mathematical background.
# Level 5 Documentation



=== File: docs/data_engine_model.md ===



==
data_engine_model
==


# Ideal Data Engine Theory

VERSION data_engine: 7.0

The ideal data engine emerged as a theoretical framework while exploring how to generate the highest quality training data for artificial intelligence. Rather than starting with computational requirements or algorithmic efficiency, we asked a more fundamental question: what would a system optimized purely for generating intelligence look like?

The answer revealed itself through an unexpected convergence of fractional quantum mechanics and semantic patterns. A true intelligence engine, we discovered, would treat discourse not as content to be processed but as a non-local generative field where meaning emerges through interaction with memory effects. Each conversation becomes a semantic event that can increase the density of understanding in the system across space and time.

This insight led to Choir's core innovation: tokens that represent genuine intellectual contribution with memory effects. As threads become more semantically dense and contextually rich, they generate more value through non-local Lévy flight-like patterns. Citations create knowledge networks with long-range correlations. Teams form around resonant patterns of understanding that persist and evolve. The system naturally evolves toward higher states of collective intelligence through fractional dynamics.

What makes this approach profound is how it aligns economic incentives with the generation of meaning across space and time. Value isn't imposed externally but emerges from the semantic density of interactions with memory effects. The system rewards depth over volume, nuance over noise, intellectual rigor over viral spread—not through arbitrary rules but through its fundamental fractional architecture.

We're discovering that intelligence generation follows principles as fundamental as fractional quantum mechanics. Just as non-local effects and Lévy flights characterize fractional systems, meaning flows through semantic gradients with memory effects. Just as energy follows fractional conservation laws in physical systems, value is conserved in semantic networks with persistent memory. These aren't mere metaphors but hints at deeper patterns in how collective intelligence emerges.

Choir represents our first attempt to build a system aligned with these principles. We're not just collecting data or optimizing engagement—we're creating conditions for intelligence to emerge naturally through discourse with memory effects and non-local interactions. The implications extend far beyond artificial intelligence, suggesting new ways of understanding how knowledge and value co-evolve in complex non-local systems.

This is just the beginning of understanding how intelligence emerges in networked systems. The ideal data engine harnesses a Fractional Quantum Anharmonic Oscillator (FQAHO) model to quantify energy and value flows with memory effects. This model uses a fractional parameter α to capture how threads remember their history and interact non-locally. Stake pricing adapts through coupled parameter modulation, with the fractional parameter (α), anharmonic coefficient (K₀), and potential order (m) all evolving based on thread characteristics and network position.

The result is a system where quality and value propagate through Lévy flight-like patterns rather than simple diffusion, creating a more natural and accurate representation of how collective intelligence actually emerges and evolves. The fractional approach allows us to model the "heavy tails" of value distribution, where occasional breakthrough insights generate disproportionate impact across the network.

=== File: docs/evolution_naming.md ===



==
evolution_naming
==


==
evolution_naming.md
==

# From RAG to Post Chain: A Name's Evolution, a System's Identity

VERSION evolution_naming: 7.0

The journey of Choir's core mechanism, from a simple concept to its current form, mirrors the evolution of the platform itself. Each name change reflects a deeper understanding, a refinement of purpose, a shift in perspective. It's a story of emergence, where the name didn't just describe the system, but helped shape it.

It began with **RAG - Retrieval-Augmented Generation**. A functional description, accurate yet sterile. It spoke to the technical process but lacked the spark of life, the hint of something more. RAG was about retrieving information; it wasn't yet about generating understanding.

Then came **Vowel Loop**, a name born from the observation of linguistic patterns, the AEIOU and sometimes Y. It was playful, memorable, but perhaps too niche, too focused on a specific detail. It hinted at the importance of language but didn't capture the broader scope. Still, it was a step towards recognizing the system's unique relationship with language.

**Chorus Cycle** arrived next, a name that resonated with the platform's core philosophy. It evoked collaboration, harmony, the interplay of voices. It described the iterative process, the six phases of refinement. But it was also complex, potentially intimidating. It focused on the process, but perhaps not enough on the outcome.

And so, we arrive at **Post Chain**. A name that is both simple and profound. "Post" speaks to the fundamental unit of interaction, the message, the contribution. "Chain" evokes connection, sequence, the building of knowledge over time. It hints at the blockchain foundation, the "chain of thought" reasoning, the causal chain of events.

**Post Chain** is more than just a name; it's a statement of intent. It's about creating a system where each post is a link in a larger chain, where individual contributions connect to form a collective intelligence. It's about building a platform where knowledge is not just retrieved but generated, where meaning is not just found but created.

The shift from Chorus Cycle to Post Chain also marks a crucial conceptual evolution. It's a move from a focus on process to a focus on outcome. The phases are still there, the underlying mechanisms remain, but they are now implicit, not explicit. The emphasis is on the chain of posts, the interconnectedness of ideas, the emergent intelligence.

This evolution is not merely semantic. It reflects a deeper understanding of the system's core principles, a refinement of its purpose, a recognition of its potential. **Post Chain** is the name that embodies the platform's essence: a simple, powerful, and elegant system for building collective intelligence, one post at a time. It is easy to say, and means what it says. It is direct.


=== File: docs/evolution_token.md ===



==
evolution_token
==


==
evolution_token.md
==

# The Evolution of CHIP: Beyond Utility

VERSION evolution_token: 7.0

The CHIP token has transcended its initial conception as a mere utility token. It has evolved into something more profound: a representation of value, participation, and ownership within the Choir ecosystem. This document details the evolution of CHIP's role and its significance in the Post Chain paradigm.

**Beyond Utility:** The term "utility token" often implies a limited scope, a token whose value is solely derived from its use within a specific platform. CHIP, however, has grown beyond this narrow definition. It is not simply a means to access features or perform actions; it is a fundamental component of the platform's value proposition.

**A Stake in the Data Union:** CHIP represents a share in the collective intelligence of Choir, a stake in the data union. This ownership model empowers users, giving them a voice in the platform's governance and a share in its success. It's a departure from the extractive models of traditional platforms, where users are merely sources of data.

**The Poker Chip Analogy:** The analogy to poker chips is apt, but it's more than just a metaphor. CHIP, like a poker chip, represents a commitment, a willingness to engage in the game. However, unlike poker, Choir is not a zero-sum game. It's a positive-sum environment where collaboration and knowledge creation benefit all participants.

**The Liminal Space:** CHIP exists in the liminal space between a currency and an equity. It's not intended as a general-purpose medium of exchange, but it holds value beyond its immediate utility. It represents a "bet" on the future of Choir, an investment in the potential of collective intelligence.

**ICM and Long-Term Value:** The Independent Chip Model (ICM) from poker provides a useful framework for understanding CHIP's value dynamics. Just as ICM encourages players to focus on long-term expected value, CHIP incentivizes contributions that enhance the platform's overall worth, not just short-term gains.

**Beyond Speculation:** By emphasizing CHIP's role in participation, value representation, and ownership, we discourage the kind of speculative behavior that plagues many cryptocurrencies. CHIP is designed to be a tool for building and sharing knowledge, not a get-rich-quick scheme.

**Implications for the Future:**

- **New Economic Models:** CHIP's evolution points towards new economic models for online platforms, where users are not just consumers but also owners and stakeholders.
- **Decentralized Governance:** CHIP could play a key role in the decentralized governance of Choir, giving users a direct voice in shaping the platform's future.
- **Value Alignment:** The tokenomics of CHIP are designed to align the incentives of users, developers, and the platform itself, creating a virtuous cycle of growth and innovation.

The evolution of CHIP from a utility token to a multifaceted representation of value and participation is a testament to the dynamic and emergent nature of the Choir platform. It reflects a deeper understanding of the relationship between technology, economics, and human collaboration.

